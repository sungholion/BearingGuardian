{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad0d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ÏÑ§Ï†ï\n",
    "IMAGE_SIZE = (128, 256)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "DATA_DIR = 'finetune_data_s1_simple'\n",
    "MODEL_SAVE_PATH = 'stage1_finetuned_simple.h5'\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_gen = datagen.flow_from_directory(DATA_DIR, target_size=IMAGE_SIZE, class_mode='binary',\n",
    "                                        batch_size=BATCH_SIZE, subset='training')\n",
    "val_gen = datagen.flow_from_directory(DATA_DIR, target_size=IMAGE_SIZE, class_mode='binary',\n",
    "                                      batch_size=BATCH_SIZE, subset='validation')\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_gen.classes), y=train_gen.classes)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Î™®Îç∏ Íµ¨ÏÑ±\n",
    "base_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(*IMAGE_SIZE, 3))\n",
    "base_model.trainable = False  # Ï≤òÏùåÏóî ÎèôÍ≤∞\n",
    "\n",
    "inputs = Input(shape=(*IMAGE_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Ïª¥ÌååÏùº\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ÏΩúÎ∞±\n",
    "callbacks = [\n",
    "    ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# ÌïôÏäµ\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS,\n",
    "          class_weight=class_weights, callbacks=callbacks)\n",
    "\n",
    "# ÌèâÍ∞Ä\n",
    "loss, acc = model.evaluate(val_gen)\n",
    "print(f\"Val Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee753ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ÏÑ§Ï†ï\n",
    "IMAGE_SIZE = (128, 256)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "DATA_DIR = 'finetune_data_s2_simple'\n",
    "MODEL_SAVE_PATH = 'stage2_finetuned_simple.h5'\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_gen = datagen.flow_from_directory(DATA_DIR, target_size=IMAGE_SIZE, class_mode='categorical',\n",
    "                                        batch_size=BATCH_SIZE, subset='training')\n",
    "val_gen = datagen.flow_from_directory(DATA_DIR, target_size=IMAGE_SIZE, class_mode='categorical',\n",
    "                                      batch_size=BATCH_SIZE, subset='validation')\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞\n",
    "y_integers = np.argmax(train_gen.labels, axis=1) if hasattr(train_gen, 'labels') else train_gen.classes\n",
    "class_weights_arr = compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers)\n",
    "class_weights = dict(enumerate(class_weights_arr))\n",
    "\n",
    "# Î™®Îç∏ Íµ¨ÏÑ±\n",
    "base_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(*IMAGE_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = Input(shape=(*IMAGE_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Ïª¥ÌååÏùº\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ÏΩúÎ∞±\n",
    "callbacks = [\n",
    "    ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# ÌïôÏäµ\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS,\n",
    "          class_weight=class_weights, callbacks=callbacks)\n",
    "\n",
    "# ÌèâÍ∞Ä\n",
    "loss, acc = model.evaluate(val_gen)\n",
    "print(f\"Val Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccfbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Í≥µÌÜµ ÏÑ§Ï†ï\n",
    "IMAGE_SIZE = (128, 256)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_INITIAL = 5\n",
    "EPOCHS_FINETUNE = 5\n",
    "LR_INITIAL = 1e-5\n",
    "LR_FINETUNE = 1e-6\n",
    "\n",
    "def build_model(num_classes, input_shape=(128, 256, 3)):\n",
    "    base_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model, base_model\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "def train_stage(stage_name, data_dir, num_classes, is_binary):\n",
    "    model_path = f'{stage_name}_finetuned_model.h5'\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    mode = 'binary' if is_binary else 'categorical'\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(data_dir, target_size=IMAGE_SIZE,\n",
    "                                            class_mode=mode, batch_size=BATCH_SIZE,\n",
    "                                            subset='training', shuffle=True)\n",
    "    val_gen = datagen.flow_from_directory(data_dir, target_size=IMAGE_SIZE,\n",
    "                                          class_mode=mode, batch_size=BATCH_SIZE,\n",
    "                                          subset='validation', shuffle=False)\n",
    "\n",
    "    y_labels = train_gen.classes if is_binary else np.argmax(train_gen.labels, axis=1)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_labels), y=y_labels)\n",
    "    class_weights = dict(enumerate(weights))\n",
    "\n",
    "    model, base_model = build_model(num_classes)\n",
    "    loss = 'binary_crossentropy' if is_binary else 'categorical_crossentropy'\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(LR_INITIAL), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, mode='max'),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "    ]\n",
    "\n",
    "    print(f\"üîß [{stage_name}] Initial training...\")\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS_INITIAL, callbacks=callbacks,\n",
    "              class_weight=class_weights)\n",
    "\n",
    "    print(f\"üîÅ [{stage_name}] Unfreezing base model and fine-tuning...\")\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(LR_FINETUNE), loss=loss, metrics=['accuracy'])\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS_FINETUNE, callbacks=callbacks,\n",
    "              class_weight=class_weights)\n",
    "\n",
    "    print(f\"üìà [{stage_name}] Evaluating...\")\n",
    "    model.load_weights(model_path)\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen)\n",
    "    y_true = val_gen.classes if is_binary else np.argmax(val_gen.labels, axis=1)\n",
    "    y_pred = (preds > 0.5).astype(int).ravel() if is_binary else np.argmax(preds, axis=1)\n",
    "\n",
    "    class_names = list(val_gen.class_indices.keys())\n",
    "    print(f\"\\nüìÑ [{stage_name}] Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, class_names, f'{stage_name} Confusion Matrix')\n",
    "    print(f\"‚úÖ [{stage_name}] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    stages = [\n",
    "        ('Stage1', 'finetune_data_s1_simple', 1, True),\n",
    "        ('Stage2', 'finetune_data_s2_simple', 3, False),\n",
    "    ]\n",
    "    processes = []\n",
    "    for args in stages:\n",
    "        p = multiprocessing.Process(target=train_stage, args=args)\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75660cb5",
   "metadata": {},
   "source": [
    "## Ïù¥Í±∞ 1Í∞ú Ïã§ÌñâÌïòÎ©¥ Îê®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d752a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ [START] Stage1 fine-tuning ÏãúÏûë\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 8.5217 - val_accuracy: 0.0000e+00 - val_loss: 7.6898 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.0098 - loss: 7.5144 - val_accuracy: 0.0000e+00 - val_loss: 7.0984 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.0355 - loss: 7.0886 - val_accuracy: 0.0000e+00 - val_loss: 6.5244 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.0312 - loss: 6.0607 - val_accuracy: 0.0000e+00 - val_loss: 5.9553 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.0758 - loss: 6.0845 - val_accuracy: 0.0000e+00 - val_loss: 5.3803 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.1464 - loss: 5.8874 - val_accuracy: 0.0250 - val_loss: 4.7859 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.2102 - loss: 4.8242 - val_accuracy: 0.1000 - val_loss: 4.1671 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.2755 - loss: 3.9737 - val_accuracy: 0.3000 - val_loss: 3.5194 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.3852 - loss: 3.4513 - val_accuracy: 0.4000 - val_loss: 2.8509 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.3891 - loss: 2.9425 - val_accuracy: 0.4250 - val_loss: 2.1707 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5175 - loss: 1.9555 - val_accuracy: 0.5000 - val_loss: 1.5216 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5247 - loss: 1.9437 - val_accuracy: 0.5250 - val_loss: 0.9477 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.6491 - loss: 1.1194 - val_accuracy: 0.6750 - val_loss: 0.5186 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949ms/step - accuracy: 0.6999 - loss: 0.9977\n",
      "‚úÖ Î™©Ìëú val_accuracy 0.89 ÎèÑÎã¨. ÌïôÏäµ Ï°∞Í∏∞ Ï¢ÖÎ£å.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.7103 - loss: 0.9707 - val_accuracy: 0.9250 - val_loss: 0.2614 - learning_rate: 1.0000e-05\n",
      "\n",
      "üìà [EVAL] Stage1 Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "\n",
      "üìÑ [Stage1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.87      1.00      0.93        20\n",
      "      Normal       1.00      0.85      0.92        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n",
      "üßÆ [Stage1] F1-score (macro): 0.9246\n",
      "üßÆ [Stage1] F1-score (weighted): 0.9246\n",
      "‚úÖ [Stage1] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\n",
      "\n",
      "üöÄ [START] Stage2 fine-tuning ÏãúÏûë\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 images belonging to 3 classes.\n",
      "Found 90 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.1822 - loss: 16.7756 - val_accuracy: 0.3111 - val_loss: 12.9268 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.2489 - loss: 14.4211 - val_accuracy: 0.3444 - val_loss: 11.1092 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3205 - loss: 12.2038 - val_accuracy: 0.3556 - val_loss: 9.3532 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.2919 - loss: 11.9695 - val_accuracy: 0.4556 - val_loss: 7.3968 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.3760 - loss: 8.9587 - val_accuracy: 0.5889 - val_loss: 5.4217 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.4133 - loss: 6.6414 - val_accuracy: 0.6556 - val_loss: 3.5284 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 999ms/step - accuracy: 0.4648 - loss: 4.9076 - val_accuracy: 0.6556 - val_loss: 1.9405 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 999ms/step - accuracy: 0.5626 - loss: 3.8514 - val_accuracy: 0.8222 - val_loss: 0.7499 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894ms/step - accuracy: 0.6974 - loss: 2.0996\n",
      "‚úÖ Î™©Ìëú val_accuracy 0.89 ÎèÑÎã¨. ÌïôÏäµ Ï°∞Í∏∞ Ï¢ÖÎ£å.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6963 - loss: 2.0959 - val_accuracy: 0.9333 - val_loss: 0.2363 - learning_rate: 1.0000e-05\n",
      "\n",
      "üìà [EVAL] Stage2 Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 851ms/step\n",
      "\n",
      "üìÑ [Stage2] Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Inner_Race_Fault       0.91      1.00      0.95        30\n",
      "  Normal_Healthy       1.00      0.80      0.89        30\n",
      "Outer_Race_Fault       0.91      1.00      0.95        30\n",
      "\n",
      "        accuracy                           0.93        90\n",
      "       macro avg       0.94      0.93      0.93        90\n",
      "    weighted avg       0.94      0.93      0.93        90\n",
      "\n",
      "üßÆ [Stage2] F1-score (macro): 0.9312\n",
      "üßÆ [Stage2] F1-score (weighted): 0.9312\n",
      "‚úÖ [Stage2] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ÏÑ§Ï†ï\n",
    "IMAGE_SIZE = (128, 256)\n",
    "BATCH_SIZE = 32\n",
    "VAL_ACC_TARGET = 0.89\n",
    "MODEL_PATHS = {\n",
    "    'Stage1': 'anomaly_model/stage1_tl_best_model_resnet.h5',\n",
    "    'Stage2': 'anomaly_model/stage2_tl_best_model_resnet.h5',\n",
    "}\n",
    "DATA_PATHS = {\n",
    "    'Stage1': 'finetune_data_s1_simple',\n",
    "    'Stage2': 'finetune_data_s2_simple',\n",
    "}\n",
    "IS_BINARY = {\n",
    "    'Stage1': True,\n",
    "    'Stage2': False,\n",
    "}\n",
    "NUM_CLASSES = {\n",
    "    'Stage1': 1,\n",
    "    'Stage2': 3,\n",
    "}\n",
    "\n",
    "class StopAtValAcc(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, target=0.89):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = logs.get(\"val_accuracy\")\n",
    "        if val_acc and val_acc >= self.target:\n",
    "            print(f\"\\n‚úÖ Î™©Ìëú val_accuracy {self.target} ÎèÑÎã¨. ÌïôÏäµ Ï°∞Í∏∞ Ï¢ÖÎ£å.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "def finetune_stage(stage):\n",
    "    print(f\"\\nüöÄ [START] {stage} fine-tuning ÏãúÏûë\")\n",
    "\n",
    "    model = load_model(MODEL_PATHS[stage])\n",
    "    data_path = DATA_PATHS[stage]\n",
    "    is_binary = IS_BINARY[stage]\n",
    "    num_classes = NUM_CLASSES[stage]\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    mode = 'binary' if is_binary else 'categorical'\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        data_path, target_size=IMAGE_SIZE, class_mode=mode,\n",
    "        color_mode='grayscale',  # ‚úÖ Î≥ÄÍ≤Ω\n",
    "        batch_size=BATCH_SIZE, subset='training', shuffle=True\n",
    "    )\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        data_path, target_size=IMAGE_SIZE, class_mode=mode,\n",
    "        color_mode='grayscale',  # ‚úÖ Î≥ÄÍ≤Ω\n",
    "        batch_size=BATCH_SIZE, subset='validation', shuffle=False\n",
    "    )\n",
    "\n",
    "    y_labels = train_gen.classes\n",
    "    weights = compute_class_weight(class_weight='balanced',\n",
    "                                   classes=np.unique(y_labels), y=y_labels)\n",
    "    class_weights = dict(enumerate(weights))\n",
    "\n",
    "    loss_fn = 'binary_crossentropy' if is_binary else 'categorical_crossentropy'\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        StopAtValAcc(target=VAL_ACC_TARGET),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=30,\n",
    "              callbacks=callbacks, class_weight=class_weights)\n",
    "\n",
    "    print(f\"\\nüìà [EVAL] {stage} Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë\")\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen)\n",
    "    y_true = val_gen.classes\n",
    "    y_pred = (preds > 0.5).astype(int).ravel() if is_binary else np.argmax(preds, axis=1)\n",
    "\n",
    "    class_names = list(val_gen.class_indices.keys())\n",
    "    print(f\"\\nüìÑ [{stage}] Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    # F1-score ÏßÅÏ†ë Ï∂úÎ†•\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f\"üßÆ [{stage}] F1-score (macro): {f1_macro:.4f}\")\n",
    "    print(f\"üßÆ [{stage}] F1-score (weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, class_names, f'{stage} Confusion Matrix')\n",
    "    print(f\"‚úÖ [{stage}] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    finetune_stage('Stage1')\n",
    "    finetune_stage('Stage2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2ae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ [START] Stage1 fine-tuning ÏãúÏûë\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 8.2368 - val_accuracy: 0.0000e+00 - val_loss: 9.5991 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.0109 - loss: 7.5038 - val_accuracy: 0.0000e+00 - val_loss: 8.8042 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.0136 - loss: 7.0081 - val_accuracy: 0.0000e+00 - val_loss: 7.9981 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.0458 - loss: 6.1126 - val_accuracy: 0.0000e+00 - val_loss: 7.1717 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.1244 - loss: 5.5001 - val_accuracy: 0.0833 - val_loss: 6.2929 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.1425 - loss: 4.1306 - val_accuracy: 0.1667 - val_loss: 5.3695 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.1785 - loss: 3.7756 - val_accuracy: 0.2333 - val_loss: 4.3877 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.2663 - loss: 3.0242 - val_accuracy: 0.3000 - val_loss: 3.3712 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.3467 - loss: 2.2520 - val_accuracy: 0.3833 - val_loss: 2.3634 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.4478 - loss: 2.0925 - val_accuracy: 0.4500 - val_loss: 1.4340 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.5768 - loss: 1.1185 - val_accuracy: 0.6333 - val_loss: 0.7436 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6919 - loss: 0.7324 - val_accuracy: 0.8333 - val_loss: 0.3541 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912ms/step - accuracy: 0.8092 - loss: 0.4205\n",
      "‚úÖ Î™©Ìëú val_accuracy 0.89 ÎèÑÎã¨. ÌïôÏäµ Ï°∞Í∏∞ Ï¢ÖÎ£å.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.8079 - loss: 0.4228 - val_accuracy: 0.9333 - val_loss: 0.1664 - learning_rate: 1.0000e-05\n",
      "\n",
      "üìà [EVAL] Stage1 Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "\n",
      "üìÑ [Stage1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       1.00      1.00      1.00        20\n",
      "      Normal       1.00      1.00      1.00        40\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "üßÆ [Stage1] F1-score (macro): 1.0000\n",
      "üßÆ [Stage1] F1-score (weighted): 1.0000\n",
      "‚úÖ [Stage1] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\n",
      "\n",
      "üöÄ [START] Stage2 fine-tuning ÏãúÏûë\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.2141 - loss: 17.4315 - val_accuracy: 0.2933 - val_loss: 12.8080 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.2279 - loss: 13.9677 - val_accuracy: 0.3467 - val_loss: 10.5359 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3100 - loss: 12.1353 - val_accuracy: 0.4600 - val_loss: 8.2995 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3629 - loss: 9.4852 - val_accuracy: 0.5533 - val_loss: 5.9338 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.4085 - loss: 7.6111 - val_accuracy: 0.6200 - val_loss: 3.6343 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.4793 - loss: 5.5685 - val_accuracy: 0.6867 - val_loss: 1.7750 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5877 - loss: 3.3882 - val_accuracy: 0.8667 - val_loss: 0.4929 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938ms/step - accuracy: 0.6693 - loss: 2.2131\n",
      "‚úÖ Î™©Ìëú val_accuracy 0.89 ÎèÑÎã¨. ÌïôÏäµ Ï°∞Í∏∞ Ï¢ÖÎ£å.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6708 - loss: 2.1983 - val_accuracy: 0.9733 - val_loss: 0.0769 - learning_rate: 1.0000e-05\n",
      "\n",
      "üìà [EVAL] Stage2 Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 650ms/step\n",
      "\n",
      "üìÑ [Stage2] Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Inner_Race_Fault       0.96      0.98      0.97        50\n",
      "  Normal_Healthy       1.00      0.94      0.97        50\n",
      "Outer_Race_Fault       0.94      0.98      0.96        50\n",
      "\n",
      "        accuracy                           0.97       150\n",
      "       macro avg       0.97      0.97      0.97       150\n",
      "    weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "üßÆ [Stage2] F1-score (macro): 0.9667\n",
      "üßÆ [Stage2] F1-score (weighted): 0.9667\n",
      "‚úÖ [Stage2] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ÏÑ§Ï†ï\n",
    "IMAGE_SIZE = (128, 256)\n",
    "BATCH_SIZE = 32\n",
    "VAL_ACC_TARGET = 0.89\n",
    "MODEL_PATHS = {\n",
    "    'Stage1': 'anomaly_model/stage1_tl_best_model_resnet.h5',\n",
    "    'Stage2': 'anomaly_model/stage2_tl_best_model_resnet.h5',\n",
    "}\n",
    "DATA_PATHS = {\n",
    "    'Stage1': 'finetune_data_split_s1',\n",
    "    'Stage2': 'finetune_data_split_s2',\n",
    "}\n",
    "IS_BINARY = {\n",
    "    'Stage1': True,\n",
    "    'Stage2': False,\n",
    "}\n",
    "NUM_CLASSES = {\n",
    "    'Stage1': 1,\n",
    "    'Stage2': 3,\n",
    "}\n",
    "\n",
    "class StopAtValAcc(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, target=0.89):\n",
    "        super().__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = logs.get(\"val_accuracy\")\n",
    "        if val_acc and val_acc >= self.target:\n",
    "            print(f\"\\n‚úÖ Î™©Ìëú val_accuracy {self.target} ÎèÑÎã¨. ÌïôÏäµ Ï°∞Í∏∞ Ï¢ÖÎ£å.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "def finetune_stage(stage):\n",
    "    print(f\"\\nüöÄ [START] {stage} fine-tuning ÏãúÏûë\")\n",
    "\n",
    "    model = load_model(MODEL_PATHS[stage])\n",
    "    data_path = DATA_PATHS[stage]\n",
    "    is_binary = IS_BINARY[stage]\n",
    "    num_classes = NUM_CLASSES[stage]\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    mode = 'binary' if is_binary else 'categorical'\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        os.path.join(data_path, 'train'), target_size=IMAGE_SIZE, class_mode=mode,\n",
    "        color_mode='grayscale', batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        os.path.join(data_path, 'val'), target_size=IMAGE_SIZE, class_mode=mode,\n",
    "        color_mode='grayscale', batch_size=BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "    test_gen = datagen.flow_from_directory(\n",
    "        os.path.join(data_path, 'test'), target_size=IMAGE_SIZE, class_mode=mode,\n",
    "        color_mode='grayscale', batch_size=BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "\n",
    "    y_labels = train_gen.classes\n",
    "    weights = compute_class_weight(class_weight='balanced',\n",
    "                                   classes=np.unique(y_labels), y=y_labels)\n",
    "    class_weights = dict(enumerate(weights))\n",
    "\n",
    "    loss_fn = 'binary_crossentropy' if is_binary else 'categorical_crossentropy'\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        StopAtValAcc(target=VAL_ACC_TARGET),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=30,\n",
    "              callbacks=callbacks, class_weight=class_weights)\n",
    "    \n",
    "        # Î™®Îç∏ Ï†ÄÏû•\n",
    "    save_path = f'anomaly_model/{stage.lower()}_finetuned_model.h5'\n",
    "    model.save(save_path)\n",
    "    print(f\"üíæ [{stage}] Fine-tuned Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å ‚Üí {save_path}\")\n",
    "\n",
    "\n",
    "    print(f\"\\nüìà [EVAL] {stage} Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë\")\n",
    "    test_gen.reset()\n",
    "    preds = model.predict(test_gen)\n",
    "    y_true = test_gen.classes\n",
    "    y_pred = (preds > 0.5).astype(int).ravel() if is_binary else np.argmax(preds, axis=1)\n",
    "\n",
    "    class_names = list(test_gen.class_indices.keys())\n",
    "    print(f\"\\nüìÑ [{stage}] Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f\"üßÆ [{stage}] F1-score (macro): {f1_macro:.4f}\")\n",
    "    print(f\"üßÆ [{stage}] F1-score (weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, class_names, f'{stage} Confusion Matrix')\n",
    "    print(f\"‚úÖ [{stage}] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    finetune_stage('Stage1')\n",
    "    finetune_stage('Stage2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Reshape, Dropout, Dense, LSTM\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ------------------------- ÏÑ§Ï†ï -------------------------\n",
    "IMG_SIZE = (128, 256)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "data_root = \"/Users/pjh_air/Documents/SJ_simhwa/final/1/Split_Spectrograms_Data\"\n",
    "train_stage1_path = os.path.join(data_root, \"train/stage1\")\n",
    "test_stage1_path = os.path.join(data_root, \"test/stage1\")\n",
    "train_stage2_path = os.path.join(data_root, \"train/stage2\")\n",
    "test_stage2_path = os.path.join(data_root, \"test/stage2\")\n",
    "\n",
    "# ------------------------- ÎèÑÎ©îÏù∏ Î†àÏù¥Î∏î ÏÉùÏÑ± Ìï®Ïàò -------------------------\n",
    "def domain_label_generator(generator, domain_label):\n",
    "    \"\"\"Label GeneratorÎ•º Í∏∞Î∞òÏúºÎ°ú ÎèÑÎ©îÏù∏ ÎùºÎ≤® ÏÉùÏÑ± (0 ÎòêÎäî 1)\"\"\"\n",
    "    while True:\n",
    "        x, y = next(generator)\n",
    "        domain_labels = tf.keras.utils.to_categorical(\n",
    "            [domain_label] * x.shape[0], num_classes=2\n",
    "        )\n",
    "        yield x, {'label_output': y, 'domain_output': domain_labels}\n",
    "\n",
    "# ------------------------- MCDANN Î™®Îç∏ Ï†ïÏùò -------------------------\n",
    "class GradientReversal(tf.keras.layers.Layer):\n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def call(self, x):\n",
    "        @tf.custom_gradient\n",
    "        def reverse_gradient(x):\n",
    "            def grad(dy):\n",
    "                return -self.lambda_ * dy\n",
    "            return x, grad\n",
    "        return reverse_gradient(x)\n",
    "\n",
    "def build_mcdann_model(input_shape, num_classes, is_binary=False):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    x = Conv2D(3, (1,1), padding='same', name='gray_to_rgb')(input_tensor)\n",
    "\n",
    "    base_model = ResNet50V2(include_top=False, weights='imagenet')\n",
    "    x = base_model(x)  # (None, 4, 8, 2048)\n",
    "    x = Reshape((8, 4 * 2048))(x)  # (None, 8, 8192)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Label head\n",
    "    if is_binary:\n",
    "        label_output = Dense(1, activation='sigmoid', name='label_output')(x)\n",
    "    else:\n",
    "        label_output = Dense(num_classes, activation='softmax', name='label_output')(x)\n",
    "\n",
    "    # Domain head\n",
    "    grl = GradientReversal()(x)\n",
    "    domain_output = Dense(2, activation='softmax', name='domain_output')(grl)\n",
    "\n",
    "    return Model(inputs=input_tensor, outputs=[label_output, domain_output])\n",
    "\n",
    "# ------------------------- ÌèâÍ∞Ä Ìï®Ïàò Ï†ïÏùò -------------------------\n",
    "def evaluate_label_only(model, generator, title, is_binary=False):\n",
    "    y_pred_probs, _ = model.predict(generator)\n",
    "    y_true = generator.classes\n",
    "    if is_binary:\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "    else:\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    class_names = list(generator.class_indices.keys())\n",
    "    print(f\"\\n--- {title} Classification Report ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    print(f\"\\n--- {title} Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"{title} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------- Îç∞Ïù¥ÌÑ∞ Î°úÎî© -------------------------\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen_s1 = datagen.flow_from_directory(train_stage1_path, target_size=IMG_SIZE, color_mode='grayscale',\n",
    "                                           batch_size=BATCH_SIZE, class_mode='binary')\n",
    "test_gen_s1 = datagen.flow_from_directory(test_stage1_path, target_size=IMG_SIZE, color_mode='grayscale',\n",
    "                                          batch_size=BATCH_SIZE, class_mode='binary', shuffle=False)\n",
    "\n",
    "train_gen_s2 = datagen.flow_from_directory(train_stage2_path, target_size=IMG_SIZE, color_mode='grayscale',\n",
    "                                           batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "test_gen_s2 = datagen.flow_from_directory(test_stage2_path, target_size=IMG_SIZE, color_mode='grayscale',\n",
    "                                          batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "\n",
    "# ------------------------- Stage 1 ÌïôÏäµ -------------------------\n",
    "print(\"\\n[Stage 1 MCDANN ÌïôÏäµ ÏãúÏûë]\")\n",
    "model_s1 = build_mcdann_model((128, 256, 1), num_classes=1, is_binary=True)\n",
    "model_s1.compile(\n",
    "    optimizer=Adam(LR),\n",
    "    loss={'label_output': 'binary_crossentropy', 'domain_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'label_output': 1.0, 'domain_output': 0.1},\n",
    "    metrics={'label_output': 'accuracy', 'domain_output': 'accuracy'}\n",
    ")\n",
    "\n",
    "model_s1.fit(domain_label_generator(train_gen_s1, domain_label=0),\n",
    "             steps_per_epoch=len(train_gen_s1),\n",
    "             epochs=EPOCHS,\n",
    "             callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "\n",
    "evaluate_label_only(model_s1, test_gen_s1, title=\"Stage 1 MCDANN\", is_binary=True)\n",
    "\n",
    "# ------------------------- Stage 2 ÌïôÏäµ -------------------------\n",
    "print(\"\\n[Stage 2 MCDANN ÌïôÏäµ ÏãúÏûë]\")\n",
    "model_s2 = build_mcdann_model((128, 256, 1), num_classes=train_gen_s2.num_classes, is_binary=False)\n",
    "model_s2.compile(\n",
    "    optimizer=Adam(LR),\n",
    "    loss={'label_output': 'categorical_crossentropy', 'domain_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'label_output': 1.0, 'domain_output': 0.1},\n",
    "    metrics={'label_output': 'accuracy', 'domain_output': 'accuracy'}\n",
    ")\n",
    "\n",
    "model_s2.fit(domain_label_generator(train_gen_s2, domain_label=0),\n",
    "             steps_per_epoch=len(train_gen_s2),\n",
    "             epochs=EPOCHS,\n",
    "             callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "\n",
    "evaluate_label_only(model_s2, test_gen_s2, title=\"Stage 2 MCDANN\", is_binary=False)\n",
    "\n",
    "print(\"\\n‚úÖ Î™®Îì† MCDANN Î™®Îç∏ ÌïôÏäµ Î∞è ÌèâÍ∞Ä ÏôÑÎ£å\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df0d1c",
   "metadata": {},
   "source": [
    "val curve ÏãúÍ∞ÅÌôî (acc/loss)\n",
    "\n",
    "ÏòàÏ∏°Í≤∞Í≥º CSV Ï†ÄÏû•\n",
    "\n",
    "threshold ÌäúÎãù Ìè¨Ìï®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d6773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ [START] Stage1 fine-tuning ÏãúÏûë\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.0078 - loss: 8.3311 - val_accuracy: 0.0000e+00 - val_loss: 9.5983 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.0103 - loss: 7.2950 - val_accuracy: 0.0000e+00 - val_loss: 8.7947 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.0251 - loss: 6.5636 - val_accuracy: 0.0000e+00 - val_loss: 7.9874 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.0124 - loss: 6.4724 - val_accuracy: 0.0000e+00 - val_loss: 7.1543 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.1107 - loss: 5.0849 - val_accuracy: 0.1000 - val_loss: 6.2798 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.1255 - loss: 4.3147 - val_accuracy: 0.1667 - val_loss: 5.3507 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.1971 - loss: 3.8672 - val_accuracy: 0.2500 - val_loss: 4.3581 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.1953 - loss: 3.3079 - val_accuracy: 0.3167 - val_loss: 3.3275 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.3481 - loss: 2.2862 - val_accuracy: 0.3833 - val_loss: 2.3278 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4552 - loss: 1.7083 - val_accuracy: 0.4500 - val_loss: 1.4285 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.5970 - loss: 1.0703 - val_accuracy: 0.6000 - val_loss: 0.7514 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941ms/step - accuracy: 0.7050 - loss: 0.6503\n",
      "‚úÖ Î™©Ìëú val_accuracy 0.79 ÎèÑÎã¨. ÌïôÏäµ Ï°∞Í∏∞ Ï¢ÖÎ£å.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7051 - loss: 0.6526 - val_accuracy: 0.8333 - val_loss: 0.3487 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ [Stage1] Fine-tuned Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å ‚Üí anomaly_model/stage1_finetuned_model.h5\n",
      "\n",
      "üìà [EVAL] Stage1 Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "\n",
      "üìÑ [Stage1] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.83      1.00      0.91        20\n",
      "      Normal       1.00      0.90      0.95        40\n",
      "\n",
      "    accuracy                           0.93        60\n",
      "   macro avg       0.92      0.95      0.93        60\n",
      "weighted avg       0.94      0.93      0.93        60\n",
      "\n",
      "üßÆ [Stage1] F1-score (macro): 0.9282\n",
      "üßÆ [Stage1] F1-score (weighted): 0.9346\n",
      "üìä Confusion Matrix Ï†ÄÏû•Îê® ‚Üí reports\\Stage1_Confusion_Matrix.png\n",
      "‚úÖ [Stage1] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\n",
      "\n",
      "üöÄ [START] Stage2 fine-tuning ÏãúÏûë\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.1921 - loss: 15.9283 - val_accuracy: 0.2933 - val_loss: 12.7973 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 15.4123 - val_accuracy: 0.3467 - val_loss: 10.5100 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.2844 - loss: 12.2516 - val_accuracy: 0.4600 - val_loss: 8.2803 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3251 - loss: 10.2776 - val_accuracy: 0.5667 - val_loss: 5.7731 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3590 - loss: 8.0897 - val_accuracy: 0.6200 - val_loss: 3.6800 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.4673 - loss: 5.2568 - val_accuracy: 0.6733 - val_loss: 1.8413 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927ms/step - accuracy: 0.5613 - loss: 3.7516\n",
      "‚úÖ Î™©Ìëú val_accuracy 0.79 ÎèÑÎã¨. ÌïôÏäµ Ï°∞Í∏∞ Ï¢ÖÎ£å.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.5643 - loss: 3.7229 - val_accuracy: 0.8267 - val_loss: 0.5925 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ [Stage2] Fine-tuned Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å ‚Üí anomaly_model/stage2_finetuned_model.h5\n",
      "\n",
      "üìà [EVAL] Stage2 Î™®Îç∏ ÌèâÍ∞Ä ÏãúÏûë\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 609ms/step\n",
      "\n",
      "üìÑ [Stage2] Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Inner_Race_Fault       0.77      0.98      0.86        50\n",
      "  Normal_Healthy       1.00      0.50      0.67        50\n",
      "Outer_Race_Fault       0.80      0.98      0.88        50\n",
      "\n",
      "        accuracy                           0.82       150\n",
      "       macro avg       0.86      0.82      0.80       150\n",
      "    weighted avg       0.86      0.82      0.80       150\n",
      "\n",
      "üßÆ [Stage2] F1-score (macro): 0.8031\n",
      "üßÆ [Stage2] F1-score (weighted): 0.8031\n",
      "üìä Confusion Matrix Ï†ÄÏû•Îê® ‚Üí reports\\Stage2_Confusion_Matrix.png\n",
      "‚úÖ [Stage2] ÏôÑÎ£å Î∞è ÏãúÍ∞ÅÌôî Ï†ÄÏû•Îê®.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import (Input, Reshape, LSTM, Dropout, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Gradient Reversal Layer\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return x, custom_grad\n",
    "\n",
    "class GradientReversal(tf.keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)\n",
    "\n",
    "# ÏÑ§Ï†ï\n",
    "IMAGE_SIZE = (128, 256)\n",
    "USE_FINE_TUNING = True  # FalseÎ©¥ ResNet ÎèôÍ≤∞\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "DATA_PATH = 'finetune_data_split_s2'\n",
    "NUM_CLASSES = 3\n",
    "REPORT_DIR = 'reports'\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    os.path.join(DATA_PATH, 'train'), target_size=IMAGE_SIZE, class_mode='categorical',\n",
    "    color_mode='rgb', batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    os.path.join(DATA_PATH, 'val'), target_size=IMAGE_SIZE, class_mode='categorical',\n",
    "    color_mode='rgb', batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    os.path.join(DATA_PATH, 'test'), target_size=IMAGE_SIZE, class_mode='categorical',\n",
    "    color_mode='rgb', batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ÏûÖÎ†• Ï†ïÏùò\n",
    "inputs = Input(shape=(128, 256, 3))\n",
    "base_model = ResNet50V2(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "\n",
    "# Fine-tuning Ï†úÏñ¥\n",
    "if not USE_FINE_TUNING:\n",
    "    base_model.trainable = False\n",
    "else:\n",
    "    for layer in base_model.layers:\n",
    "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "x = base_model.output  # shape: (None, h, w, c)\n",
    "x = Reshape((x.shape[1], x.shape[2] * x.shape[3]))(x)  # (None, time, features)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Label Head\n",
    "label_output = Dense(NUM_CLASSES, activation='softmax', name='label_head')(x)\n",
    "\n",
    "# Domain Head with GRL\n",
    "grl = GradientReversal()(x)\n",
    "domain_output = Dense(100, activation='relu')(grl)\n",
    "domain_output = Dense(2, activation='softmax', name='domain_head')(domain_output)\n",
    "\n",
    "# Î™®Îç∏ Íµ¨ÏÑ±\n",
    "model = Model(inputs, [label_output, domain_output])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss={'label_head': 'categorical_crossentropy', 'domain_head': 'categorical_crossentropy'},\n",
    "              metrics={'label_head': 'accuracy', 'domain_head': 'accuracy'})\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Í∞ÄÏ§ëÏπò\n",
    "y_labels = train_gen.classes\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_labels), y=y_labels)\n",
    "class_weights = dict(enumerate(weights))\n",
    "\n",
    "# ÏΩúÎ∞±\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_label_head_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_label_head_loss', factor=0.5, patience=3)\n",
    "]\n",
    "\n",
    "# ÌïôÏäµ\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=callbacks)\n",
    "\n",
    "# ÌèâÍ∞Ä\n",
    "preds = model.predict(test_gen)\n",
    "y_true = test_gen.classes\n",
    "y_pred = np.argmax(preds[0], axis=1)\n",
    "\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"F1-score (macro): {f1_macro:.4f}\")\n",
    "print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d634a8af",
   "metadata": {},
   "source": [
    "üîç Ï†ÑÏ≤¥ ÏöîÏïΩ\n",
    "‚úÖ Stage 1 (Normal vs Abnormal)\n",
    "Train/Val/Test split: 180 / 60 / 60 (Ï¥ù 300Ïû•)\n",
    "\n",
    "ÏÑ±Îä• ÏöîÏïΩ:\n",
    "\n",
    "ÏµúÏ¢Ö val_accuracy = 0.8333 ‚Üí Í∏∞Ï§ÄÏπò 0.79 Ï¥àÍ≥º ‚Üí Ï°∞Í∏∞ Ï¢ÖÎ£å\n",
    "\n",
    "Test Accuracy = 0.93\n",
    "\n",
    "F1 (macro) = 0.9282\n",
    "\n",
    "F1 (weighted) = 0.9346\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "NormalÏùÑ AbnormalÎ°ú ÏûòÎ™ª Î∂ÑÎ•òÌïú ÎπÑÏú® Í±∞Ïùò ÏóÜÏùå (recall 1.00)\n",
    "\n",
    "ÏÑ±Îä• Îß§Ïö∞ Ïö∞Ïàò, Ïù¥ÏÉÅ ÌÉêÏßÄ ÏÑ±Í≥µ\n",
    "\n",
    "‚úÖ Stage 2 (Normal vs IR vs OR)\n",
    "Train/Val/Test split: 450 / 150 / 150 (Ï¥ù 750Ïû•)\n",
    "\n",
    "ÏÑ±Îä• ÏöîÏïΩ:\n",
    "\n",
    "ÏµúÏ¢Ö val_accuracy = 0.8267 ‚Üí Í∏∞Ï§ÄÏπò 0.79 Ï¥àÍ≥º ‚Üí Ï°∞Í∏∞ Ï¢ÖÎ£å\n",
    "\n",
    "Test Accuracy = 0.82\n",
    "\n",
    "F1 (macro) = 0.8031\n",
    "\n",
    "F1 (weighted) = 0.8031\n",
    "\n",
    "Confusion Matrix ÌäπÏßï:\n",
    "\n",
    "Normal_Healthy: precisionÏùÄ 1.00Ïù¥ÎÇò recallÏù¥ 0.50 ‚Üí Ï†àÎ∞òÎßå Ï†úÎåÄÎ°ú Ïû°Ïùå\n",
    "\n",
    "IR, OR: Î™®Îëê recallÏù¥ 0.98Î°ú Îß§Ïö∞ ÎÜíÏùå ‚Üí faultÎ•º Ïûò Ïû°ÏïÑÎÉÑ\n",
    "\n",
    "ÏùòÎØ∏:\n",
    "\n",
    "Ïù¥ÏÉÅ(Í≤∞Ìï®)ÏùÑ Îß§Ïö∞ Ïûò Ïû°ÏßÄÎßå, Ï†ïÏÉÅÏùÑ Í≤∞Ìï®ÏúºÎ°ú Ïò§Î∂ÑÎ•òÌïòÎäî Í≤ΩÌñ• Ï°¥Ïû¨ (Í≥ºÌÉê)\n",
    "\n",
    "üìå Ïã§Î¨¥ Ìï¥ÏÑù Ìè¨Ïù∏Ìä∏\n",
    "Ìï≠Î™©\tÌï¥ÏÑù\n",
    "Stage1\tÏ†ïÏÉÅ/Ïù¥ÏÉÅ Ïù¥ÏßÑ Î∂ÑÎ•ò Ï†ïÌôïÎèÑ 93%Î°ú Îß§Ïö∞ ÎÜíÏùå. Ïã§Ï†Ñ Ïù¥ÏÉÅÌÉêÏßÄÏóêÏÑú ÏÇ¨Ïö© Í∞ÄÎä•\n",
    "Stage2\tÎã§Ï§ë Î∂ÑÎ•ò Ï†ïÌôïÎèÑ 82%ÏßÄÎßå, Normal recallÏù¥ ÎÇÆÏïÑ Ïã§Ï†ú Ï†ïÏÉÅ ÏÉÅÌÉúÎ•º Ïò§ÌÉêÌï† ÏúÑÌóò Ï°¥Ïû¨\n",
    "‚úÖ Ìñ•ÌõÑ Î≥¥ÏôÑ\t- Normal Îç∞Ïù¥ÌÑ∞ Ïàò ÎäòÎ¶¨Í∏∞\n",
    "- decision threshold Ï°∞Ï†ï\n",
    "- F1-score Í∏∞Î∞ò threshold ÌÉêÏÉâ ÌïÑÏöî\n",
    "- ÌòºÎèô ÌñâÎ†¨ Í∏∞Î∞ò ÌõÑÏ≤òÎ¶¨ Ï†ÑÎûµ ÎèÑÏûÖ Í∞ÄÎä•\n",
    "\n",
    "ÌïÑÏöîÌïòÎ©¥ Stage1/2 confusion matrix ÏãúÍ∞ÅÌôî Î∂ÑÏÑù, Ïò§ÌÉê/ÎØ∏ÌÉê Î≥¥ÏôÑ Ï†ÑÎûµÍπåÏßÄ Ïù¥Ïñ¥ÏÑú Î∂ÑÏÑùÌï¥Ï§Ñ Ïàò ÏûàÏùå.\n",
    "ÏßÄÍ∏à ÏÉÅÌÉúÎäî Ï†ÑÏ≤¥ ÌååÏù∏ÌäúÎãù Î£®ÌîÑ ÏôÑÎ≤ΩÌûà ÎèôÏûë Ï§ëÏù¥Î©∞ ÏÑ±Îä•ÎèÑ ÎÇòÏÅòÏßÄ ÏïäÏùå."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afb152",
   "metadata": {},
   "source": [
    "# val curve ÏãúÍ∞ÅÌôî (acc/loss)\n",
    "\n",
    "# ÏòàÏ∏°Í≤∞Í≥º CSV Ï†ÄÏû•\n",
    "\n",
    "# threshold ÌäúÎãù Ìè¨Ìï®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67f4d1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
