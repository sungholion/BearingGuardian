{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b888d40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정된 기본 데이터 경로: C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3\n",
      "설정된 스펙트로그램 저장 경로: C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3\\spectrograms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image # For image processing\n",
    "\n",
    "# Keras/TensorFlow 관련 라이브러리\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0 # ResNet, EfficientNet 사전학습 모델\n",
    "\n",
    "# pydub 라이브러리 (MP3 to WAV 변환용)\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# 새로운 데이터셋 기본 경로 설정 (MP3 파일이 있는 곳)\n",
    "base_data_path = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3'\n",
    "\n",
    "# 스펙트로그램 이미지를 저장할 경로 설정\n",
    "output_spectrogram_dir = os.path.join(base_data_path, 'spectrograms')\n",
    "\n",
    "# 필요한 하위 디렉토리 미리 생성\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'train', 'normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'test', 'normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'test', 'anomaly'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'val', 'normal'), exist_ok=True) # Keras ImageDataGenerator용\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'val', 'anomaly'), exist_ok=True) # Keras ImageDataGenerator용\n",
    "\n",
    "print(f\"설정된 기본 데이터 경로: {base_data_path}\")\n",
    "print(f\"설정된 스펙트로그램 저장 경로: {output_spectrogram_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d67c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WAV 기반 메타데이터 (df_meta.head()) ---\n",
      "                                           file_name  \\\n",
      "0  bearing/test/section_00_source_test_anomaly_00...   \n",
      "1  bearing/test/section_00_source_test_anomaly_00...   \n",
      "2  bearing/test/section_00_source_test_anomaly_00...   \n",
      "3  bearing/test/section_00_source_test_anomaly_00...   \n",
      "4  bearing/test/section_00_source_test_anomaly_00...   \n",
      "\n",
      "                                   relative_wav_path parsed_label  \\\n",
      "0  test/section_00_source_test_anomaly_0000_noAtt...      anomaly   \n",
      "1  test/section_00_source_test_anomaly_0001_noAtt...      anomaly   \n",
      "2  test/section_00_source_test_anomaly_0002_noAtt...      anomaly   \n",
      "3  test/section_00_source_test_anomaly_0003_noAtt...      anomaly   \n",
      "4  test/section_00_source_test_anomaly_0004_noAtt...      anomaly   \n",
      "\n",
      "  parsed_subset machine_id  \n",
      "0          test    bearing  \n",
      "1          test    bearing  \n",
      "2          test    bearing  \n",
      "3          test    bearing  \n",
      "4          test    bearing  \n",
      "\n",
      "총 파일 수: 1200\n",
      "\n",
      "'parsed_label' (정상/이상)별 데이터 개수:\n",
      "parsed_label\n",
      "normal     1100\n",
      "anomaly     100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "'parsed_subset' (훈련/테스트)별 데이터 개수:\n",
      "parsed_subset\n",
      "train    1000\n",
      "test      200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "'parsed_subset'와 'parsed_label' 조합별 데이터 개수:\n",
      "parsed_label   anomaly  normal\n",
      "parsed_subset                 \n",
      "test               100     100\n",
      "train                0    1000\n"
     ]
    }
   ],
   "source": [
    "# 'attributes_00.csv' 파일은 'base_data_path'의 상위 폴더인 'Dataset' 아래 'bearing' 폴더에 있을 수 있습니다.\n",
    "# 사용자께서 이전에 '/Users/pjh_air/Documents/SJ_simhwa/final/dcase/bearing/attributes_00.csv'에서 로드했습니다.\n",
    "# 따라서, 현재 'base_data_path'는 'bearing-raw-mp3'이므로, 'bearing' 폴더 경로를 명확히 해야 합니다.\n",
    "\n",
    "# DCASE 데이터셋의 'bearing' 폴더 경로를 가정합니다.\n",
    "# 'base_data_path'와 같은 레벨에 'bearing' 폴더가 있을 수 있습니다.\n",
    "# 예를 들어, 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing\\attributes_00.csv'\n",
    "dcase_bearing_folder_path = os.path.join(os.path.dirname(base_data_path), 'bearing-raw-mp3')\n",
    "meta_file_path = os.path.join(dcase_bearing_folder_path, 'attributes_00.csv')\n",
    "\n",
    "try:\n",
    "    df_meta_original = pd.read_csv(meta_file_path)\n",
    "\n",
    "    # 기존 file_name 컬럼에서 'bearing/' 접두사 제거 (WAV 파일 경로 맞추기 위함)\n",
    "    # df_meta_original['file_name'] 컬럼의 값이 'bearing/train/...' 형태라고 가정\n",
    "    df_meta_original['relative_wav_path'] = df_meta_original['file_name'].apply(lambda x: x.replace('bearing/', '', 1))\n",
    "    \n",
    "    # parsed_label, parsed_subset 등 파싱된 정보도 그대로 사용\n",
    "    df_meta_original['parsed_label'] = df_meta_original['relative_wav_path'].apply(lambda x: 'normal' if 'normal' in x else ('anomaly' if 'anomaly' in x else 'unknown'))\n",
    "    df_meta_original['parsed_subset'] = df_meta_original['relative_wav_path'].apply(lambda x: 'train' if 'train' in x else ('test' if 'test' in x else 'unknown'))\n",
    "    df_meta_original['machine_id'] = 'bearing' # DCASE bearing 데이터이므로 고정\n",
    "\n",
    "    df_meta = df_meta_original # 최종적으로 사용할 메타데이터 DataFrame\n",
    "\n",
    "    print(\"\\n--- WAV 기반 메타데이터 (df_meta.head()) ---\")\n",
    "    print(df_meta.head())\n",
    "    print(f\"\\n총 파일 수: {len(df_meta)}\")\n",
    "    print(f\"\\n'parsed_label' (정상/이상)별 데이터 개수:\\n{df_meta['parsed_label'].value_counts()}\")\n",
    "    print(f\"\\n'parsed_subset' (훈련/테스트)별 데이터 개수:\\n{df_meta['parsed_subset'].value_counts()}\")\n",
    "    print(f\"\\n'parsed_subset'와 'parsed_label' 조합별 데이터 개수:\\n{df_meta.groupby(['parsed_subset', 'parsed_label']).size().unstack(fill_value=0)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: 원본 메타데이터 파일을 찾을 수 없습니다. 경로를 다시 확인해주세요: {meta_file_path}\")\n",
    "    print(\"attributes_00.csv 파일이 올바른 위치에 있는지 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"WAV 기반 메타데이터 로드 및 파싱 중 오류 발생: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168c7a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "스펙트로그램 저장 경로: C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3\\spectrograms\n",
      "\n",
      "--- WAV 기반 스펙트로그램 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Spectrograms: 100%|██████████| 1200/1200 [00:32<00:00, 36.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WAV 기반 스펙트로그램 생성 완료 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 스펙트로그램 생성 파라미터\n",
    "sr_target = 16000\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "\n",
    "print(f\"\\n스펙트로그램 저장 경로: {output_spectrogram_dir}\")\n",
    "\n",
    "def create_and_save_spectrogram_from_wav(row):\n",
    "    try:\n",
    "        # WAV 파일의 실제 경로 구성\n",
    "        # 'base_data_path' (C:\\Users\\...\\Dataset\\bearing-raw-mp3)와\n",
    "        # 'row['relative_wav_path']' (test/section_00_...wav)를 결합합니다.\n",
    "        # 'relative_wav_path'는 이미 'bearing/' 접두사가 제거된 상태입니다.\n",
    "        full_wav_file_path = os.path.join(base_data_path, row['relative_wav_path'])\n",
    "\n",
    "        # 디버깅을 위해 로드하려는 최종 경로 출력 (필요시 주석 해제)\n",
    "        # print(f\"DEBUG: Attempting to load WAV from: {full_wav_file_path}\")\n",
    "        # if not os.path.exists(full_wav_file_path):\n",
    "        #     print(f\"DEBUG: WAV file NOT FOUND at: {full_wav_file_path}\")\n",
    "        #     raise FileNotFoundError(f\"WAV file not found: {full_wav_file_path}\")\n",
    "\n",
    "        # librosa.load: 오디오 파일 로드. sr_target으로 리샘플링됩니다.\n",
    "        y, sr = librosa.load(full_wav_file_path, sr=sr_target)\n",
    "\n",
    "        # Mel 스펙트로그램 생성\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "        # dB 스케일로 변환 (이미지 시각화 및 딥러닝 입력에 적합)\n",
    "        S_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        # 스펙트로그램 이미지 저장 경로 구성: output_spectrogram_dir / subset / label / base_filename_png\n",
    "        \n",
    "        # 순수한 파일명 추출 (확장자 포함). file_name 컬럼은 'bearing/test/section_00...wav' 형태\n",
    "        base_filename_wav = os.path.basename(os.path.normpath(row['file_name'])) \n",
    "        base_filename_png = base_filename_wav.replace('.wav', '.png') # '.png'로 변경\n",
    "        \n",
    "        subset = row['parsed_subset'] # 'train' 또는 'test'\n",
    "        label = row['parsed_label']   # 'normal' 또는 'anomaly'\n",
    "        \n",
    "        save_path = os.path.join(output_spectrogram_dir, subset, label, base_filename_png)\n",
    "        \n",
    "        # 저장할 상위 디렉토리가 없으면 생성 (예: spectrograms_from_wav/train/normal)\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "        # Matplotlib을 사용하여 스펙트로그램 이미지를 생성하고 저장\n",
    "        # 축, 여백 없이 순수 이미지 데이터만 저장하여 딥러닝 모델 입력에 적합하도록 함\n",
    "        fig = plt.figure(figsize=(S_db.shape[1]/100, S_db.shape[0]/100), dpi=100) # 이미지 해상도 조절\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.]) # figure 전체를 차지하는 축 생성\n",
    "        ax.set_axis_off() # 축 제거\n",
    "        fig.add_axes(ax) # 축을 figure에 추가\n",
    "        \n",
    "        ax.imshow(S_db, origin='lower', aspect='auto', cmap=cm.magma) # 이미지 데이터 플로팅\n",
    "        plt.savefig(save_path) # 파일로 저장\n",
    "        plt.close(fig) # 메모리 누수 방지\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"오류: '{row['file_name']}' 파일 처리 중 오류 발생: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"\\n--- WAV 기반 스펙트로그램 생성 시작 ---\")\n",
    "# df_meta DataFrame을 사용하여 모든 파일에 대해 스펙트로그램 생성\n",
    "for idx, row in tqdm(df_meta.iterrows(), total=len(df_meta), desc=\"Generating Spectrograms\"):\n",
    "    create_and_save_spectrogram_from_wav(row)\n",
    "\n",
    "print(\"--- WAV 기반 스펙트로그램 생성 완료 ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83eb043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0 # ResNet, EfficientNet 사전학습 모델\n",
    "\n",
    "# 이전 단계에서 설정된 이미지 크기 및 클래스 수 변수 사용:\n",
    "# img_height, img_width = n_mels, int(sr_target * 10 / hop_length) \n",
    "# input_shape = (img_height, img_width, 3) \n",
    "# num_classes = 2 # normal, anomaly\n",
    "\n",
    "def build_keras_model(model_name, input_shape, num_classes=2):\n",
    "    model = Sequential()\n",
    "\n",
    "    if model_name == 'custom_cnn':\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5)) # 과적합 방지: 훈련 시 50%의 뉴런을 무작위로 비활성화\n",
    "        model.add(Dense(num_classes, activation='sigmoid' if num_classes == 2 else 'softmax')) \n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5)) # 과적합 방지\n",
    "        model.add(Dense(num_classes, activation='sigmoid' if num_classes == 2 else 'softmax'))\n",
    "        \n",
    "        base_model.trainable = False # 사전 학습된 레이어는 훈련 동결 (전이 학습)\n",
    "\n",
    "    elif model_name == 'efficientnetb0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5)) # 과적합 방지\n",
    "        model.add(Dense(num_classes, activation='sigmoid' if num_classes == 2 else 'softmax'))\n",
    "        \n",
    "        base_model.trainable = False # 사전 학습된 레이어는 훈련 동결\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55ec5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 단계에서 설정된 train_generator, validation_generator, test_generator 사용\n",
    "\n",
    "def train_and_evaluate_keras_model(model, train_gen, val_gen, test_gen, model_name, epochs=10):\n",
    "    print(f\"\\n--- {model_name} 학습 시작 ---\")\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), # Adam 옵티마이저, 학습률 0.001\n",
    "                  loss='binary_crossentropy' if num_classes == 2 else 'categorical_crossentropy', # 이진 분류 손실 함수\n",
    "                  metrics=['accuracy']) # 정확도 지표 사용\n",
    "    \n",
    "    # 모델 구조 요약 출력\n",
    "    model.summary()\n",
    "\n",
    "    # 콜백 (Early Stopping): 과적합 방지를 위해 사용\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        train_gen, # 훈련 데이터 제너레이터\n",
    "        epochs=epochs, # 학습 에포크 수\n",
    "        validation_data=val_gen, # 검증 데이터 제너레이터\n",
    "        callbacks=callbacks # 콜백 적용\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- {model_name} 학습 완료 ---\")\n",
    "\n",
    "    # 모델 평가 (테스트 셋)\n",
    "    print(f\"\\n--- {model_name} 테스트 셋 평가 ---\")\n",
    "    loss, accuracy = model.evaluate(test_gen) # 테스트 셋으로 손실과 정확도 계산\n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model, history # 학습된 모델과 학습 이력 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2871eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Custom CNN 모델 학습 시작 =====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# ===== Custom CNN 모델 학습 시작 =====\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===== Custom CNN 모델 학습 시작 =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m custom_cnn_model \u001b[38;5;241m=\u001b[39m build_keras_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_cnn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43minput_shape\u001b[49m, num_classes)\n\u001b[0;32m     12\u001b[0m trained_custom_cnn_model, history_cnn \u001b[38;5;241m=\u001b[39m train_and_evaluate_keras_model(\n\u001b[0;32m     13\u001b[0m     custom_cnn_model, train_generator, validation_generator, test_generator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustom CNN\u001b[39m\u001b[38;5;124m\"\u001b[39m, epochs\u001b[38;5;241m=\u001b[39mepochs_to_train\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# ===== ResNet50 모델 학습 시작 =====\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "# # 이전 단계에서 설정된 이미지 크기 및 클래스 수 변수들:\n",
    "# img_height, img_width #(스펙트로그램 높이, 너비)\n",
    "# input_shape (img_height, img_width, 3)\n",
    "# num_classes #(현재 2: normal, anomaly)\n",
    "\n",
    "# 에포크 수 설정 (실제 학습 시 더 높게 설정할 수 있음)\n",
    "epochs_to_train = 10 \n",
    "\n",
    "# ===== Custom CNN 모델 학습 시작 =====\n",
    "print(\"===== Custom CNN 모델 학습 시작 =====\")\n",
    "custom_cnn_model = build_keras_model('custom_cnn', input_shape, num_classes)\n",
    "trained_custom_cnn_model, history_cnn = train_and_evaluate_keras_model(\n",
    "    custom_cnn_model, train_generator, validation_generator, test_generator, \"Custom CNN\", epochs=epochs_to_train\n",
    ")\n",
    "\n",
    "# ===== ResNet50 모델 학습 시작 =====\n",
    "print(\"\\n===== ResNet50 모델 학습 시작 =====\")\n",
    "resnet50_model = build_keras_model('resnet50', input_shape, num_classes)\n",
    "trained_resnet50_model, history_resnet50 = train_and_evaluate_keras_model(\n",
    "    resnet50_model, train_generator, validation_generator, test_generator, \"ResNet50\", epochs=epochs_to_train\n",
    ")\n",
    "\n",
    "# ===== EfficientNetB0 모델 학습 시작 =====\n",
    "print(\"\\n===== EfficientNetB0 모델 학습 시작 =====\")\n",
    "efficientnetb0_model = build_keras_model('efficientnetb0', input_shape, num_classes)\n",
    "trained_efficientnetb0_model, history_efficientnetb0 = train_and_evaluate_keras_model(\n",
    "    efficientnetb0_model, train_generator, validation_generator, test_generator, \"EfficientNetB0\", epochs=epochs_to_train\n",
    ")\n",
    "\n",
    "print(\"\\n모든 Keras 모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf643c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정된 기본 데이터 경로 (원본 WAV): C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3\n",
      "설정된 스펙트로그램 저장 경로: C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\spectrograms_from_wav\n",
      "\n",
      "--- WAV 기반 메타데이터 (df_meta.head()) ---\n",
      "                                           file_name  \\\n",
      "0  bearing/test/section_00_source_test_anomaly_00...   \n",
      "1  bearing/test/section_00_source_test_anomaly_00...   \n",
      "2  bearing/test/section_00_source_test_anomaly_00...   \n",
      "3  bearing/test/section_00_source_test_anomaly_00...   \n",
      "4  bearing/test/section_00_source_test_anomaly_00...   \n",
      "\n",
      "                                   relative_wav_path parsed_label  \\\n",
      "0  test/section_00_source_test_anomaly_0000_noAtt...      anomaly   \n",
      "1  test/section_00_source_test_anomaly_0001_noAtt...      anomaly   \n",
      "2  test/section_00_source_test_anomaly_0002_noAtt...      anomaly   \n",
      "3  test/section_00_source_test_anomaly_0003_noAtt...      anomaly   \n",
      "4  test/section_00_source_test_anomaly_0004_noAtt...      anomaly   \n",
      "\n",
      "  parsed_subset machine_id  \n",
      "0          test    bearing  \n",
      "1          test    bearing  \n",
      "2          test    bearing  \n",
      "3          test    bearing  \n",
      "4          test    bearing  \n",
      "\n",
      "총 파일 수: 1200\n",
      "\n",
      "'parsed_label' (정상/이상)별 데이터 개수:\n",
      "parsed_label\n",
      "normal     1100\n",
      "anomaly     100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "'parsed_subset' (훈련/테스트)별 데이터 개수:\n",
      "parsed_subset\n",
      "train    1000\n",
      "test      200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "'parsed_subset'와 'parsed_label' 조합별 데이터 개수:\n",
      "parsed_label   anomaly  normal\n",
      "parsed_subset                 \n",
      "test               100     100\n",
      "train                0    1000\n",
      "\n",
      "스펙트로그램 저장 경로: C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\spectrograms_from_wav\n",
      "\n",
      "--- WAV 기반 스펙트로그램 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Spectrograms: 100%|██████████| 1200/1200 [00:31<00:00, 38.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WAV 기반 스펙트로그램 생성 완료 ---\n",
      "Found 800 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 validated image filenames belonging to 2 classes.\n",
      "Found 200 validated image filenames belonging to 2 classes.\n",
      "\n",
      "--- ImageDataGenerator 설정 완료 ---\n",
      "훈련 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n",
      "검증 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n",
      "테스트 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n",
      "===== Custom CNN 모델 학습 시작 =====\n",
      "\n",
      "--- Custom CNN 학습 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">155</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66304</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,487,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m310\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m155\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m153\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66304\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m8,487,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,580,417</span> (32.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,580,417\u001b[0m (32.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,580,417</span> (32.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,580,417\u001b[0m (32.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 578ms/step - accuracy: 0.9537 - loss: 0.1000 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 378ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 374ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\n",
      "--- Custom CNN 학습 완료 ---\n",
      "\n",
      "--- Custom CNN 테스트 셋 평가 ---\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.3678 - loss: 164.7746\n",
      "Test Loss: 130.4562\n",
      "Test Accuracy: 0.5000\n",
      "\n",
      "===== ResNet50 모델 학습 시작 =====\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "\n",
      "--- ResNet50 학습 시작 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81920</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,485,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2048\u001b[0m)    │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81920\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m10,485,888\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,073,729</span> (129.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,073,729\u001b[0m (129.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,486,017</span> (40.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,486,017\u001b[0m (40.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 860ms/step - accuracy: 0.8610 - loss: 0.2171 - val_accuracy: 1.0000 - val_loss: 3.1927e-37\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 811ms/step - accuracy: 1.0000 - loss: 5.8564e-19 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 823ms/step - accuracy: 1.0000 - loss: 2.8675e-21 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 818ms/step - accuracy: 1.0000 - loss: 7.2098e-21 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 799ms/step - accuracy: 1.0000 - loss: 9.1889e-18 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\n",
      "--- ResNet50 학습 완료 ---\n",
      "\n",
      "--- ResNet50 테스트 셋 평가 ---\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 466ms/step - accuracy: 0.3678 - loss: 57.4667\n",
      "Test Loss: 45.4337\n",
      "Test Accuracy: 0.5000\n",
      "\n",
      "===== EfficientNetB0 모델 학습 시작 =====\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "\n",
      "--- EfficientNetB0 학습 시작 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,553,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1280\u001b[0m)    │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51200\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m6,553,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,603,428</span> (40.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,603,428\u001b[0m (40.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,553,857</span> (25.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,553,857\u001b[0m (25.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 547ms/step - accuracy: 0.8888 - loss: 0.1401 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 476ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "\n",
      "--- EfficientNetB0 학습 완료 ---\n",
      "\n",
      "--- EfficientNetB0 테스트 셋 평가 ---\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - accuracy: 0.3678 - loss: 168.4320\n",
      "Test Loss: 133.2191\n",
      "Test Accuracy: 0.5000\n",
      "\n",
      "모든 Keras 모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "\n",
    "\n",
    "# --- 1. 경로 및 기본 설정 (이전과 동일) ---\n",
    "base_data_path = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3'\n",
    "output_spectrogram_dir = os.path.join(os.path.dirname(base_data_path), 'spectrograms_from_wav')\n",
    "\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'train', 'normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'train', 'anomaly'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'val', 'normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'val', 'anomaly'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'test', 'normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'test', 'anomaly'), exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"설정된 기본 데이터 경로 (원본 WAV): {base_data_path}\")\n",
    "print(f\"설정된 스펙트로그램 저장 경로: {output_spectrogram_dir}\")\n",
    "\n",
    "# --- 2. 메타데이터 로드 및 파싱 (이전과 동일) ---\n",
    "meta_file_path = os.path.join(os.path.dirname(base_data_path), 'bearing', 'attributes_00.csv')\n",
    "\n",
    "try:\n",
    "    df_meta_original = pd.read_csv(meta_file_path)\n",
    "    df_meta_original['relative_wav_path'] = df_meta_original['file_name'].apply(lambda x: x.replace('bearing/', '', 1))\n",
    "    df_meta_original['parsed_label'] = df_meta_original['relative_wav_path'].apply(lambda x: 'normal' if 'normal' in x else ('anomaly' if 'anomaly' in x else 'unknown'))\n",
    "    df_meta_original['parsed_subset'] = df_meta_original['relative_wav_path'].apply(lambda x: 'train' if 'train' in x else ('test' if 'test' in x else 'unknown'))\n",
    "    df_meta_original['machine_id'] = 'bearing'\n",
    "    df_meta = df_meta_original\n",
    "    \n",
    "    print(\"\\n--- WAV 기반 메타데이터 (df_meta.head()) ---\")\n",
    "    print(df_meta.head())\n",
    "    print(f\"\\n총 파일 수: {len(df_meta)}\")\n",
    "    print(f\"\\n'parsed_label' (정상/이상)별 데이터 개수:\\n{df_meta['parsed_label'].value_counts()}\")\n",
    "    print(f\"\\n'parsed_subset' (훈련/테스트)별 데이터 개수:\\n{df_meta['parsed_subset'].value_counts()}\")\n",
    "    print(f\"\\n'parsed_subset'와 'parsed_label' 조합별 데이터 개수:\\n{df_meta.groupby(['parsed_subset', 'parsed_label']).size().unstack(fill_value=0)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: 원본 메타데이터 파일을 찾을 수 없습니다. 경로를 다시 확인해주세요: {meta_file_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"WAV 기반 메타데이터 로드 및 파싱 중 오류 발생: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 3. 스펙트로그램 생성 및 저장 (이전과 동일) ---\n",
    "sr_target = 16000\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "\n",
    "print(f\"\\n스펙트로그램 저장 경로: {output_spectrogram_dir}\")\n",
    "\n",
    "def create_and_save_spectrogram_from_wav(row):\n",
    "    try:\n",
    "        full_wav_file_path = os.path.join(base_data_path, row['relative_wav_path'])\n",
    "        y, sr = librosa.load(full_wav_file_path, sr=sr_target)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "        S_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        base_filename_wav = os.path.basename(os.path.normpath(row['file_name'])) \n",
    "        base_filename_png = base_filename_wav.replace('.wav', '.png')\n",
    "        \n",
    "        subset = row['parsed_subset']\n",
    "        label = row['parsed_label']\n",
    "        \n",
    "        save_path = os.path.join(output_spectrogram_dir, subset, label, base_filename_png)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "        fig = plt.figure(figsize=(S_db.shape[1]/100, S_db.shape[0]/100), dpi=100)\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        \n",
    "        ax.imshow(S_db, origin='lower', aspect='auto', cmap=cm.magma) \n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig) \n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"오류: '{row['file_name']}' 파일 처리 중 오류 발생: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"\\n--- WAV 기반 스펙트로그램 생성 시작 ---\")\n",
    "for idx, row in tqdm(df_meta.iterrows(), total=len(df_meta), desc=\"Generating Spectrograms\"):\n",
    "    create_and_save_spectrogram_from_wav(row)\n",
    "\n",
    "print(\"--- WAV 기반 스펙트로그램 생성 완료 ---\")\n",
    "\n",
    "# --- 4. Keras 모델 선정 및 구축: ImageDataGenerator 설정 및 데이터 분할 수정 (이전과 동일) ---\n",
    "img_height, img_width = n_mels, int(sr_target * 10 / hop_length) \n",
    "input_shape = (img_height, img_width, 3) \n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2 # normal, anomaly (이진 분류)\n",
    "\n",
    "train_val_df = df_meta[df_meta['parsed_subset'] == 'train'].copy()\n",
    "test_df_keras = df_meta[df_meta['parsed_subset'] == 'test'].copy()\n",
    "\n",
    "train_df_keras, val_df_keras = train_test_split(train_val_df, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_spectrogram_filepath_for_keras(row, base_spectrogram_dir):\n",
    "    base_filename_wav = os.path.basename(os.path.normpath(row['file_name']))\n",
    "    base_filename_png = base_filename_wav.replace('.wav', '.png')\n",
    "    \n",
    "    subset_folder = row['parsed_subset']\n",
    "    label_folder = row['parsed_label']\n",
    "    \n",
    "    return os.path.join(base_spectrogram_dir, subset_folder, label_folder, base_filename_png)\n",
    "\n",
    "train_df_keras['filepath'] = train_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "train_df_keras['class'] = train_df_keras['parsed_label']\n",
    "\n",
    "val_df_keras['filepath'] = val_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "val_df_keras['class'] = val_df_keras['parsed_label']\n",
    "\n",
    "test_df_keras['filepath'] = test_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "test_df_keras['class'] = test_df_keras['parsed_label']\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "keras_class_names = ['anomaly', 'normal'] # 클래스 순서 (알파벳 순서에 따름)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary', # 이진 분류 (출력 뉴런 1개)\n",
    "    classes=keras_class_names, # 클래스 라벨 명시\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=keras_class_names,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=keras_class_names,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- ImageDataGenerator 설정 완료 ---\")\n",
    "print(f\"훈련 제너레이터 클래스 인덱스: {train_generator.class_indices}\")\n",
    "print(f\"검증 제너레이터 클래스 인덱스: {validation_generator.class_indices}\")\n",
    "print(f\"테스트 제너레이터 클래스 인덱스: {test_generator.class_indices}\")\n",
    "\n",
    "\n",
    "# --- 5. Keras 모델 구축 및 학습 ---\n",
    "def build_keras_model(model_name, input_shape, num_classes): # num_classes는 1 (이진 분류)\n",
    "    model = Sequential()\n",
    "\n",
    "    if model_name == 'custom_cnn':\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid')) # 🐞 핵심 수정: 이진 분류이므로 출력 뉴런 1개, sigmoid 활성화 함수\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid')) # 🐞 핵심 수정\n",
    "\n",
    "        base_model.trainable = False\n",
    "\n",
    "    elif model_name == 'efficientnetb0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid')) # 🐞 핵심 수정\n",
    "\n",
    "        base_model.trainable = False\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_keras_model(model, train_gen, val_gen, test_gen, model_name, epochs=10):\n",
    "    print(f\"\\n--- {model_name} 학습 시작 ---\")\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy', # 이진 분류 손실 함수\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- {model_name} 학습 완료 ---\")\n",
    "\n",
    "    print(f\"\\n--- {model_name} 테스트 셋 평가 ---\")\n",
    "    loss, accuracy = model.evaluate(test_gen)\n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "epochs_to_train = 10\n",
    "\n",
    "print(\"===== Custom CNN 모델 학습 시작 =====\")\n",
    "# build_keras_model 호출 시 num_classes를 1로 전달\n",
    "custom_cnn_model = build_keras_model('custom_cnn', input_shape, 1) \n",
    "trained_custom_cnn_model, history_cnn = train_and_evaluate_keras_model(\n",
    "    custom_cnn_model, train_generator, validation_generator, test_generator, \"Custom CNN\", epochs=epochs_to_train\n",
    ")\n",
    "\n",
    "print(\"\\n===== ResNet50 모델 학습 시작 =====\")\n",
    "# build_keras_model 호출 시 num_classes를 1로 전달\n",
    "resnet50_model = build_keras_model('resnet50', input_shape, 1) \n",
    "trained_resnet50_model, history_resnet50 = train_and_evaluate_keras_model(\n",
    "    resnet50_model, train_generator, validation_generator, test_generator, \"ResNet50\", epochs=epochs_to_train\n",
    ")\n",
    "\n",
    "print(\"\\n===== EfficientNetB0 모델 학습 시작 =====\")\n",
    "# build_keras_model 호출 시 num_classes를 1로 전달\n",
    "efficientnetb0_model = build_keras_model('efficientnetb0', input_shape, 1) \n",
    "trained_efficientnetb0_model, history_efficientnetb0 = train_and_evaluate_keras_model(\n",
    "    efficientnetb0_model, train_generator, validation_generator, test_generator, \"EfficientNetB0\", epochs=epochs_to_train\n",
    ")\n",
    "\n",
    "print(\"\\n모든 Keras 모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3938a41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 훈련 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     660\n",
      "anomaly     60\n",
      "Name: count, dtype: int64\n",
      "최종 검증 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     220\n",
      "anomaly     20\n",
      "Name: count, dtype: int64\n",
      "최종 테스트 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     220\n",
      "anomaly     20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n최종 훈련 세트 라벨 분포:\\n{train_df_final['parsed_label'].value_counts()}\")\n",
    "print(f\"최종 검증 세트 라벨 분포:\\n{val_df_final['parsed_label'].value_counts()}\")\n",
    "print(f\"최종 테스트 세트 라벨 분포:\\n{test_df_final['parsed_label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1137e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정된 기본 데이터 경로 (원본 WAV): C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3\n",
      "설정된 스펙트로그램 저장 경로: C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\spectrograms_from_wav\n",
      "\n",
      "--- WAV 기반 메타데이터 (df_meta.head()) ---\n",
      "                                           file_name  \\\n",
      "0  bearing/test/section_00_source_test_anomaly_00...   \n",
      "1  bearing/test/section_00_source_test_anomaly_00...   \n",
      "2  bearing/test/section_00_source_test_anomaly_00...   \n",
      "3  bearing/test/section_00_source_test_anomaly_00...   \n",
      "4  bearing/test/section_00_source_test_anomaly_00...   \n",
      "\n",
      "                                   relative_wav_path parsed_label  \\\n",
      "0  test/section_00_source_test_anomaly_0000_noAtt...      anomaly   \n",
      "1  test/section_00_source_test_anomaly_0001_noAtt...      anomaly   \n",
      "2  test/section_00_source_test_anomaly_0002_noAtt...      anomaly   \n",
      "3  test/section_00_source_test_anomaly_0003_noAtt...      anomaly   \n",
      "4  test/section_00_source_test_anomaly_0004_noAtt...      anomaly   \n",
      "\n",
      "  parsed_subset machine_id  \n",
      "0          test    bearing  \n",
      "1          test    bearing  \n",
      "2          test    bearing  \n",
      "3          test    bearing  \n",
      "4          test    bearing  \n",
      "\n",
      "총 파일 수: 1200\n",
      "\n",
      "'parsed_label' (정상/이상)별 데이터 개수:\n",
      "parsed_label\n",
      "normal     1100\n",
      "anomaly     100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "'parsed_subset' (훈련/테스트)별 데이터 개수:\n",
      "parsed_subset\n",
      "train    1000\n",
      "test      200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "'parsed_subset'와 'parsed_label' 조합별 데이터 개수:\n",
      "parsed_label   anomaly  normal\n",
      "parsed_subset                 \n",
      "test               100     100\n",
      "train                0    1000\n",
      "\n",
      "스펙트로그램 저장 경로: C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\spectrograms_from_wav\n",
      "\n",
      "--- WAV 기반 스펙트로그램 생성 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Spectrograms: 100%|██████████| 1200/1200 [00:32<00:00, 36.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WAV 기반 스펙트로그램 생성 완료 ---\n",
      "\n",
      "새로운 데이터 분할 결과:\n",
      "  최종 훈련 세트 크기: 720\n",
      "  최종 검증 세트 크기: 240\n",
      "  최종 테스트 세트 크기: 240\n",
      "  훈련 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     660\n",
      "anomaly     60\n",
      "Name: count, dtype: int64\n",
      "  검증 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     220\n",
      "anomaly     20\n",
      "Name: count, dtype: int64\n",
      "  테스트 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     220\n",
      "anomaly     20\n",
      "Name: count, dtype: int64\n",
      "Found 720 validated image filenames belonging to 2 classes.\n",
      "Found 240 validated image filenames belonging to 2 classes.\n",
      "Found 240 validated image filenames belonging to 2 classes.\n",
      "\n",
      "--- ImageDataGenerator 설정 완료 ---\n",
      "훈련 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n",
      "검증 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n",
      "테스트 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n",
      "\n",
      "계산된 클래스 가중치: {0: np.float64(6.0), 1: np.float64(0.5454545454545454)}\n",
      "===== Custom CNN 모델 학습 시작 =====\n",
      "\n",
      "--- Custom CNN 학습 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">155</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66304</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,487,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m310\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m155\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m153\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66304\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m8,487,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,580,417</span> (32.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,580,417\u001b[0m (32.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,580,417</span> (32.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,580,417\u001b[0m (32.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 582ms/step - accuracy: 0.6168 - loss: 1.6617 - val_accuracy: 0.9083 - val_loss: 0.6900\n",
      "Epoch 2/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.5860 - loss: 0.6904 - val_accuracy: 0.4083 - val_loss: 0.6931\n",
      "Epoch 3/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.5013 - loss: 0.7236 - val_accuracy: 0.9167 - val_loss: 0.6863\n",
      "Epoch 4/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.2630 - loss: 0.7590 - val_accuracy: 0.6125 - val_loss: 0.6930\n",
      "Epoch 5/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 381ms/step - accuracy: 0.6918 - loss: 0.6613 - val_accuracy: 0.0833 - val_loss: 0.6969\n",
      "Epoch 6/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 372ms/step - accuracy: 0.2196 - loss: 0.7157 - val_accuracy: 0.1208 - val_loss: 0.6981\n",
      "\n",
      "--- Custom CNN 학습 완료 ---\n",
      "\n",
      "--- Custom CNN 테스트 셋 평가 ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 0.9222 - loss: 0.6861\n",
      "Test Loss: 0.6864\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "===== ResNet50 모델 학습 시작 =====\n",
      "\n",
      "--- ResNet50 학습 시작 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81920</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,485,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2048\u001b[0m)    │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81920\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m10,485,888\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,073,729</span> (129.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,073,729\u001b[0m (129.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,486,017</span> (40.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,486,017\u001b[0m (40.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 919ms/step - accuracy: 0.5066 - loss: 2.6740 - val_accuracy: 0.9167 - val_loss: 0.2944\n",
      "Epoch 2/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 826ms/step - accuracy: 0.6379 - loss: 1.1456 - val_accuracy: 0.0833 - val_loss: 0.6994\n",
      "Epoch 3/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 819ms/step - accuracy: 0.3470 - loss: 0.7047 - val_accuracy: 0.0833 - val_loss: 0.7487\n",
      "Epoch 4/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 829ms/step - accuracy: 0.3428 - loss: 0.7373 - val_accuracy: 0.9167 - val_loss: 0.6781\n",
      "\n",
      "--- ResNet50 학습 완료 ---\n",
      "\n",
      "--- ResNet50 테스트 셋 평가 ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 539ms/step - accuracy: 0.9222 - loss: 0.2786\n",
      "Test Loss: 0.2948\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "===== EfficientNetB0 모델 학습 시작 =====\n",
      "\n",
      "--- EfficientNetB0 학습 시작 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,553,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1280\u001b[0m)    │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51200\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m6,553,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,603,428</span> (40.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,603,428\u001b[0m (40.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,553,857</span> (25.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,553,857\u001b[0m (25.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 619ms/step - accuracy: 0.6100 - loss: 5.0855 - val_accuracy: 0.0833 - val_loss: 0.7239\n",
      "Epoch 2/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 534ms/step - accuracy: 0.4411 - loss: 1.1549 - val_accuracy: 0.9167 - val_loss: 0.6928\n",
      "Epoch 3/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 526ms/step - accuracy: 0.9196 - loss: 0.7054 - val_accuracy: 0.9167 - val_loss: 0.6924\n",
      "Epoch 4/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 519ms/step - accuracy: 0.9102 - loss: 0.7177 - val_accuracy: 0.9167 - val_loss: 0.6930\n",
      "Epoch 5/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 514ms/step - accuracy: 0.9091 - loss: 0.7287 - val_accuracy: 0.9167 - val_loss: 0.6928\n",
      "Epoch 6/10\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 511ms/step - accuracy: 0.9126 - loss: 0.7085 - val_accuracy: 0.9167 - val_loss: 0.6929\n",
      "\n",
      "--- EfficientNetB0 학습 완료 ---\n",
      "\n",
      "--- EfficientNetB0 테스트 셋 평가 ---\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 287ms/step - accuracy: 0.9222 - loss: 0.6924\n",
      "Test Loss: 0.6924\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "모든 Keras 모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score # 평가 지표 추가\n",
    "\n",
    "# --- 1. 경로 및 기본 설정 (이전과 동일) ---\n",
    "base_data_path = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3'\n",
    "output_spectrogram_dir = os.path.join(os.path.dirname(base_data_path), 'spectrograms_from_wav')\n",
    "\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'train', 'normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'train', 'anomaly'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'val', 'normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'val', 'anomaly'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'test', 'normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_spectrogram_dir, 'test', 'anomaly'), exist_ok=True)\n",
    "\n",
    "print(f\"설정된 기본 데이터 경로 (원본 WAV): {base_data_path}\")\n",
    "print(f\"설정된 스펙트로그램 저장 경로: {output_spectrogram_dir}\")\n",
    "\n",
    "# --- 2. 메타데이터 로드 및 파싱 (이전과 동일) ---\n",
    "meta_file_path = os.path.join(os.path.dirname(base_data_path), 'bearing', 'attributes_00.csv')\n",
    "\n",
    "try:\n",
    "    df_meta_original = pd.read_csv(meta_file_path)\n",
    "    df_meta_original['relative_wav_path'] = df_meta_original['file_name'].apply(lambda x: x.replace('bearing/', '', 1))\n",
    "    df_meta_original['parsed_label'] = df_meta_original['relative_wav_path'].apply(lambda x: 'normal' if 'normal' in x else ('anomaly' if 'anomaly' in x else 'unknown'))\n",
    "    df_meta_original['parsed_subset'] = df_meta_original['relative_wav_path'].apply(lambda x: 'train' if 'train' in x else ('test' if 'test' in x else 'unknown'))\n",
    "    df_meta_original['machine_id'] = 'bearing'\n",
    "    df_meta = df_meta_original\n",
    "    \n",
    "    print(\"\\n--- WAV 기반 메타데이터 (df_meta.head()) ---\")\n",
    "    print(df_meta.head())\n",
    "    print(f\"\\n총 파일 수: {len(df_meta)}\")\n",
    "    print(f\"\\n'parsed_label' (정상/이상)별 데이터 개수:\\n{df_meta['parsed_label'].value_counts()}\")\n",
    "    print(f\"\\n'parsed_subset' (훈련/테스트)별 데이터 개수:\\n{df_meta['parsed_subset'].value_counts()}\")\n",
    "    print(f\"\\n'parsed_subset'와 'parsed_label' 조합별 데이터 개수:\\n{df_meta.groupby(['parsed_subset', 'parsed_label']).size().unstack(fill_value=0)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: 원본 메타데이터 파일을 찾을 수 없습니다. 경로를 다시 확인해주세요: {meta_file_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"WAV 기반 메타데이터 로드 및 파싱 중 오류 발생: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 3. 스펙트로그램 생성 및 저장 (이전과 동일) ---\n",
    "sr_target = 16000\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "\n",
    "print(f\"\\n스펙트로그램 저장 경로: {output_spectrogram_dir}\")\n",
    "\n",
    "def create_and_save_spectrogram_from_wav(row):\n",
    "    try:\n",
    "        full_wav_file_path = os.path.join(base_data_path, row['relative_wav_path'])\n",
    "        y, sr = librosa.load(full_wav_file_path, sr=sr_target)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "        S_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        base_filename_wav = os.path.basename(os.path.normpath(row['file_name'])) \n",
    "        base_filename_png = base_filename_wav.replace('.wav', '.png')\n",
    "        \n",
    "        subset = row['parsed_subset']\n",
    "        label = row['parsed_label']\n",
    "        \n",
    "        save_path = os.path.join(output_spectrogram_dir, subset, label, base_filename_png)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "        fig = plt.figure(figsize=(S_db.shape[1]/100, S_db.shape[0]/100), dpi=100)\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        \n",
    "        ax.imshow(S_db, origin='lower', aspect='auto', cmap=cm.magma) \n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig) \n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"오류: '{row['file_name']}' 파일 처리 중 오류 발생: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"\\n--- WAV 기반 스펙트로그램 생성 시작 ---\")\n",
    "for idx, row in tqdm(df_meta.iterrows(), total=len(df_meta), desc=\"Generating Spectrograms\"):\n",
    "    create_and_save_spectrogram_from_wav(row)\n",
    "\n",
    "print(\"--- WAV 기반 스펙트로그램 생성 완료 ---\")\n",
    "\n",
    "# --- 4. Keras 모델 선정 및 구축: ImageDataGenerator 설정 및 데이터 분할 ---\n",
    "img_height, img_width = n_mels, int(sr_target * 10 / hop_length) \n",
    "input_shape = (img_height, img_width, 3) \n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2 # normal, anomaly (이진 분류)\n",
    "\n",
    "# 전체 데이터 (df_meta)를 훈련/검증/테스트로 재분할\n",
    "train_val_combined_df, test_df_keras = train_test_split(\n",
    "    df_meta, test_size=0.2, random_state=42, stratify=df_meta['parsed_label']\n",
    ")\n",
    "train_df_keras, val_df_keras = train_test_split(\n",
    "    train_val_combined_df, test_size=0.25, random_state=42, stratify=train_val_combined_df['parsed_label']\n",
    ")\n",
    "\n",
    "# 🐞 최종 훈련/검증/테스트 세트 라벨 분포 재확인 및 출력\n",
    "print(f\"\\n새로운 데이터 분할 결과:\")\n",
    "print(f\"  최종 훈련 세트 크기: {len(train_df_keras)}\")\n",
    "print(f\"  최종 검증 세트 크기: {len(val_df_keras)}\")\n",
    "print(f\"  최종 테스트 세트 크기: {len(test_df_keras)}\")\n",
    "print(f\"  훈련 세트 라벨 분포:\\n{train_df_keras['parsed_label'].value_counts()}\")\n",
    "print(f\"  검증 세트 라벨 분포:\\n{val_df_keras['parsed_label'].value_counts()}\")\n",
    "print(f\"  테스트 세트 라벨 분포:\\n{test_df_keras['parsed_label'].value_counts()}\")\n",
    "\n",
    "\n",
    "# Keras flow_from_dataframe을 위한 'filepath'와 'class' 컬럼 생성 함수\n",
    "def get_spectrogram_filepath_for_keras(row, base_spectrogram_dir):\n",
    "    base_filename_wav = os.path.basename(os.path.normpath(row['file_name']))\n",
    "    base_filename_png = base_filename_wav.replace('.wav', '.png')\n",
    "    \n",
    "    subset_folder = row['parsed_subset']\n",
    "    label_folder = row['parsed_label']\n",
    "    \n",
    "    return os.path.join(base_spectrogram_dir, subset_folder, label_folder, base_filename_png)\n",
    "\n",
    "train_df_keras['filepath'] = train_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "train_df_keras['class'] = train_df_keras['parsed_label']\n",
    "\n",
    "val_df_keras['filepath'] = val_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "val_df_keras['class'] = val_df_keras['parsed_label']\n",
    "\n",
    "test_df_keras['filepath'] = test_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "test_df_keras['class'] = test_df_keras['parsed_label']\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "keras_class_names = ['anomaly', 'normal']\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=keras_class_names, # 클래스 라벨 명시\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=keras_class_names,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=keras_class_names,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- ImageDataGenerator 설정 완료 ---\")\n",
    "print(f\"훈련 제너레이터 클래스 인덱스: {train_generator.class_indices}\")\n",
    "print(f\"검증 제너레이터 클래스 인덱스: {validation_generator.class_indices}\")\n",
    "print(f\"테스트 제너레이터 클래스 인덱스: {test_generator.class_indices}\")\n",
    "\n",
    "\n",
    "# --- 5. Keras 모델 구축 및 학습 ---\n",
    "def build_keras_model(model_name, input_shape, num_classes): # num_classes는 1 (이진 분류)\n",
    "    model = Sequential()\n",
    "\n",
    "    if model_name == 'custom_cnn':\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        base_model.trainable = False\n",
    "\n",
    "    elif model_name == 'efficientnetb0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        base_model.trainable = False\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_keras_model(model, train_gen, val_gen, test_gen, model_name, epochs=10, class_weight=None):\n",
    "    print(f\"\\n--- {model_name} 학습 시작 ---\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight # 🐞 class_weight passed to model.fit()\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- {model_name} 학습 완료 ---\")\n",
    "\n",
    "    print(f\"\\n--- {model_name} 테스트 셋 평가 ---\")\n",
    "    loss, accuracy = model.evaluate(test_gen)\n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "epochs_to_train = 10\n",
    "\n",
    "# 클래스 가중치 계산 (불균형 해소)\n",
    "# 훈련 세트 라벨 분포: normal 660, anomaly 60 (이전 출력 기준)\n",
    "# 훈련 세트 라벨 분포를 value_counts() 결과에서 직접 가져옵니다.\n",
    "train_label_counts = train_df_keras['parsed_label'].value_counts()\n",
    "total_train_samples = len(train_df_keras)\n",
    "\n",
    "# 🐞 get() 메서드를 사용하여 키가 없을 때 KeyError 대신 0을 반환하도록 수정\n",
    "num_normal = train_label_counts.get('normal', 0)\n",
    "num_anomaly = train_label_counts.get('anomaly', 0)\n",
    "\n",
    "# 0으로 나누는 오류 방지\n",
    "class_weights = {}\n",
    "if num_anomaly > 0:\n",
    "    class_weights[train_generator.class_indices['anomaly']] = total_train_samples / (2 * num_anomaly)\n",
    "else:\n",
    "    # anomaly 샘플이 훈련 세트에 없는 경우 (매우 드물겠지만)\n",
    "    # anomaly 클래스에 무한대 가중치를 주거나, 해당 클래스 가중치를 생략할 수 있습니다.\n",
    "    # 여기서는 계산에 포함하지 않고, 경고 메시지를 출력합니다.\n",
    "    print(\"경고: 훈련 세트에 'anomaly' 샘플이 없어 'anomaly' 클래스 가중치를 계산할 수 없습니다.\")\n",
    "    # 이 경우 class_weights 딕셔너리는 normal에 대한 가중치만 가질 것입니다.\n",
    "    # 모델은 여전히 anomaly를 학습하지 못할 수 있습니다.\n",
    "    \n",
    "if num_normal > 0:\n",
    "    class_weights[train_generator.class_indices['normal']] = total_train_samples / (2 * num_normal)\n",
    "else:\n",
    "    print(\"경고: 훈련 세트에 'normal' 샘플이 없어 'normal' 클래스 가중치를 계산할 수 없습니다.\")\n",
    "\n",
    "print(f\"\\n계산된 클래스 가중치: {class_weights}\")\n",
    "\n",
    "\n",
    "print(\"===== Custom CNN 모델 학습 시작 =====\")\n",
    "custom_cnn_model = build_keras_model('custom_cnn', input_shape, 1)\n",
    "trained_custom_cnn_model, history_cnn = train_and_evaluate_keras_model(\n",
    "    custom_cnn_model, train_generator, validation_generator, test_generator, \n",
    "    \"Custom CNN\", epochs=epochs_to_train, class_weight=class_weights\n",
    ")\n",
    "\n",
    "print(\"\\n===== ResNet50 모델 학습 시작 =====\")\n",
    "resnet50_model = build_keras_model('resnet50', input_shape, 1)\n",
    "trained_resnet50_model, history_resnet50 = train_and_evaluate_keras_model(\n",
    "    resnet50_model, train_generator, validation_generator, test_generator, \n",
    "    \"ResNet50\", epochs=epochs_to_train, class_weight=class_weights\n",
    ")\n",
    "\n",
    "print(\"\\n===== EfficientNetB0 모델 학습 시작 =====\")\n",
    "efficientnetb0_model = build_keras_model('efficientnetb0', input_shape, 1)\n",
    "trained_efficientnetb0_model, history_efficientnetb0 = train_and_evaluate_keras_model(\n",
    "    efficientnetb0_model, train_generator, validation_generator, test_generator, \n",
    "    \"EfficientNetB0\", epochs=epochs_to_train, class_weight=class_weights\n",
    ")\n",
    "\n",
    "print(\"\\n모든 Keras 모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15a81dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스펙트로그램 이미지 입력 형태: (128, 312, 3)\n",
      "배치 크기: 32\n",
      "분류할 클래스 수: 2\n",
      "\n",
      "--- 메타데이터 로드 완료 (df_meta.head()) ---\n",
      "                                           file_name  \\\n",
      "0  bearing/test/section_00_source_test_anomaly_00...   \n",
      "1  bearing/test/section_00_source_test_anomaly_00...   \n",
      "2  bearing/test/section_00_source_test_anomaly_00...   \n",
      "3  bearing/test/section_00_source_test_anomaly_00...   \n",
      "4  bearing/test/section_00_source_test_anomaly_00...   \n",
      "\n",
      "                                   relative_wav_path parsed_label  \\\n",
      "0  test/section_00_source_test_anomaly_0000_noAtt...      anomaly   \n",
      "1  test/section_00_source_test_anomaly_0001_noAtt...      anomaly   \n",
      "2  test/section_00_source_test_anomaly_0002_noAtt...      anomaly   \n",
      "3  test/section_00_source_test_anomaly_0003_noAtt...      anomaly   \n",
      "4  test/section_00_source_test_anomaly_0004_noAtt...      anomaly   \n",
      "\n",
      "  parsed_subset machine_id  \n",
      "0          test    bearing  \n",
      "1          test    bearing  \n",
      "2          test    bearing  \n",
      "3          test    bearing  \n",
      "4          test    bearing  \n",
      "\n",
      "새로운 데이터 분할 결과:\n",
      "  최종 훈련 세트 크기: 720\n",
      "  최종 검증 세트 크기: 240\n",
      "  최종 테스트 세트 크기: 240\n",
      "  훈련 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     660\n",
      "anomaly     60\n",
      "Name: count, dtype: int64\n",
      "  검증 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     220\n",
      "anomaly     20\n",
      "Name: count, dtype: int64\n",
      "  테스트 세트 라벨 분포:\n",
      "parsed_label\n",
      "normal     220\n",
      "anomaly     20\n",
      "Name: count, dtype: int64\n",
      "Found 720 validated image filenames belonging to 2 classes.\n",
      "Found 240 validated image filenames belonging to 2 classes.\n",
      "Found 240 validated image filenames belonging to 2 classes.\n",
      "\n",
      "--- ImageDataGenerator 설정 완료 ---\n",
      "훈련 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n",
      "검증 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n",
      "테스트 제너레이터 클래스 인덱스: {'anomaly': 0, 'normal': 1}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np # 넘파이는 스펙트로그램 생성 시 필요하지만, 로드 단계에서도 임포트 유지\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image # For Keras image loading\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# --- 경로 및 파라미터 재설정 (스펙트로그램 생성 단계에서 사용된 것과 동일) ---\n",
    "# base_data_path는 원본 .wav 파일의 경로 (이제 직접 로드하지 않으므로, 정확성만 확인)\n",
    "base_data_path = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\Dataset\\bearing-raw-mp3' \n",
    "# output_spectrogram_dir는 스펙트로그램 .png 파일이 저장된 경로\n",
    "output_spectrogram_dir = os.path.join(os.path.dirname(base_data_path), 'spectrograms_from_wav')\n",
    "\n",
    "# 메타데이터 파일 경로 (이전에 사용된 attributes_00.csv 경로)\n",
    "meta_file_path = os.path.join(os.path.dirname(base_data_path), 'bearing', 'attributes_00.csv')\n",
    "\n",
    "# 스펙트로그램 생성 파라미터 (이미지 크기 계산에 필요)\n",
    "sr_target = 16000\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "\n",
    "# 이미지 크기 및 채널 설정\n",
    "img_height, img_width = n_mels, int(sr_target * 10 / hop_length) \n",
    "input_shape = (img_height, img_width, 3) # Keras 모델 입력 형태: (높이, 너비, 채널) -> RGB 3채널\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2 # normal, anomaly (이진 분류)\n",
    "\n",
    "print(f\"스펙트로그램 이미지 입력 형태: {input_shape}\")\n",
    "print(f\"배치 크기: {batch_size}\")\n",
    "print(f\"분류할 클래스 수: {num_classes}\")\n",
    "\n",
    "# --- 메타데이터 로드 및 파싱 (이전에 완료된 작업이지만, 변수 로드를 위해 다시 실행) ---\n",
    "try:\n",
    "    df_meta_original = pd.read_csv(meta_file_path)\n",
    "    df_meta_original['relative_wav_path'] = df_meta_original['file_name'].apply(lambda x: x.replace('bearing/', '', 1))\n",
    "    df_meta_original['parsed_label'] = df_meta_original['relative_wav_path'].apply(lambda x: 'normal' if 'normal' in x else ('anomaly' if 'anomaly' in x else 'unknown'))\n",
    "    df_meta_original['parsed_subset'] = df_meta_original['relative_wav_path'].apply(lambda x: 'train' if 'train' in x else ('test' if 'test' in x else 'unknown'))\n",
    "    df_meta_original['machine_id'] = 'bearing'\n",
    "    df_meta = df_meta_original\n",
    "    \n",
    "    print(\"\\n--- 메타데이터 로드 완료 (df_meta.head()) ---\")\n",
    "    print(df_meta.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: 원본 메타데이터 파일을 찾을 수 없습니다: {meta_file_path}. 이전에 스펙트로그램 생성 단계가 완료되었는지 확인해주세요.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"메타데이터 로드 및 파싱 중 오류 발생: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 데이터 분할 (스펙트로그램 생성 시와 동일하게) ---\n",
    "train_val_combined_df, test_df_keras = train_test_split(\n",
    "    df_meta, test_size=0.2, random_state=42, stratify=df_meta['parsed_label']\n",
    ")\n",
    "train_df_keras, val_df_keras = train_test_split(\n",
    "    train_val_combined_df, test_size=0.25, random_state=42, stratify=train_val_combined_df['parsed_label']\n",
    ")\n",
    "\n",
    "print(f\"\\n새로운 데이터 분할 결과:\")\n",
    "print(f\"  최종 훈련 세트 크기: {len(train_df_keras)}\")\n",
    "print(f\"  최종 검증 세트 크기: {len(val_df_keras)}\")\n",
    "print(f\"  최종 테스트 세트 크기: {len(test_df_keras)}\")\n",
    "print(f\"  훈련 세트 라벨 분포:\\n{train_df_keras['parsed_label'].value_counts()}\")\n",
    "print(f\"  검증 세트 라벨 분포:\\n{val_df_keras['parsed_label'].value_counts()}\")\n",
    "print(f\"  테스트 세트 라벨 분포:\\n{test_df_keras['parsed_label'].value_counts()}\")\n",
    "\n",
    "# --- Keras flow_from_dataframe을 위한 'filepath'와 'class' 컬럼 생성 ---\n",
    "def get_spectrogram_filepath_for_keras(row, base_spectrogram_dir):\n",
    "    base_filename_wav = os.path.basename(os.path.normpath(row['file_name']))\n",
    "    base_filename_png = base_filename_wav.replace('.wav', '.png')\n",
    "    \n",
    "    subset_folder = row['parsed_subset'] # 원본 DCASE의 train/test 폴더명\n",
    "    label_folder = row['parsed_label']   # normal/anomaly 폴더명\n",
    "    \n",
    "    return os.path.join(base_spectrogram_dir, subset_folder, label_folder, base_filename_png)\n",
    "\n",
    "train_df_keras['filepath'] = train_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "train_df_keras['class'] = train_df_keras['parsed_label']\n",
    "\n",
    "val_df_keras['filepath'] = val_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "val_df_keras['class'] = val_df_keras['parsed_label']\n",
    "\n",
    "test_df_keras['filepath'] = test_df_keras.apply(lambda row: get_spectrogram_filepath_for_keras(row, output_spectrogram_dir), axis=1)\n",
    "test_df_keras['class'] = test_df_keras['parsed_label']\n",
    "\n",
    "\n",
    "# --- ImageDataGenerator 설정 (데이터 증강 강화) ---\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # 픽셀 값 0-1 스케일링\n",
    "    rotation_range=20, # 20도 내에서 무작위 회전\n",
    "    width_shift_range=0.2, # 가로 이동 (전체 너비의 20% 내)\n",
    "    height_shift_range=0.2, # 세로 이동 (전체 높이의 20% 내)\n",
    "    zoom_range=0.2, # 줌 범위 (20% 확대/축소)\n",
    "    brightness_range=[0.8, 1.2], # 밝기 범위 (80%~120%)\n",
    "    horizontal_flip=True, # 무작위 수평 뒤집기\n",
    "    fill_mode='nearest' # 비어있는 픽셀 채우기\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255) # 검증 데이터는 증강 없음\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 테스트 데이터는 증강 없음\n",
    "\n",
    "keras_class_names = ['anomaly', 'normal'] # 클래스 순서 (알파벳 순서에 따름)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary', # 이진 분류 (출력 뉴런 1개)\n",
    "    classes=keras_class_names, # 클래스 라벨 명시\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=keras_class_names,\n",
    "    shuffle=False # 검증 셋은 섞지 않음\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df_keras,\n",
    "    x_col='filepath',\n",
    "    y_col='class',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=keras_class_names,\n",
    "    shuffle=False # 테스트 셋은 섞지 않음\n",
    ")\n",
    "\n",
    "print(\"\\n--- ImageDataGenerator 설정 완료 ---\")\n",
    "print(f\"훈련 제너레이터 클래스 인덱스: {train_generator.class_indices}\")\n",
    "print(f\"검증 제너레이터 클래스 인덱스: {validation_generator.class_indices}\")\n",
    "print(f\"테스트 제너레이터 클래스 인덱스: {test_generator.class_indices}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Keras 모델 구축 함수 정의 ---\n",
    "def build_keras_model(model_name, input_shape, num_classes): # num_classes는 1 (이진 분류)\n",
    "    model = Sequential()\n",
    "\n",
    "    if model_name == 'custom_cnn':\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid')) # 이진 분류이므로 출력 뉴런 1개, sigmoid 활성화 함수\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        base_model.trainable = False\n",
    "\n",
    "    elif model_name == 'efficientnetb0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model.add(base_model)\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        base_model.trainable = False\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- 모델 학습 및 평가 함수 정의 ---\n",
    "def train_and_evaluate_keras_model(model, train_gen, val_gen, test_gen, model_name, epochs=10, class_weight=None):\n",
    "    print(f\"\\n--- {model_name} 학습 시작 ---\")\n",
    "    \n",
    "    # 모델 컴파일: 학습률 (Learning Rate) 감소\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), # 0.001 -> 0.0001로 10배 감소\n",
    "                  loss='binary_crossentropy', # 이진 분류 손실 함수\n",
    "                  metrics=['accuracy']) # 정확도 지표 사용\n",
    "    \n",
    "    model.summary() # 모델 구조 요약 출력\n",
    "\n",
    "    # 콜백 (Early Stopping): patience 증가 (3 -> 5)\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)] \n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        train_gen, # 훈련 데이터 제너레이터\n",
    "        epochs=epochs, # 학습 에포크 수\n",
    "        validation_data=val_gen, # 검증 데이터 제너레이터\n",
    "        callbacks=callbacks, # 콜백 적용\n",
    "        class_weight=class_weight # 클래스 가중치 적용\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- {model_name} 학습 완료 ---\")\n",
    "\n",
    "    # 모델 평가 (테스트 셋)\n",
    "    print(f\"\\n--- {model_name} 테스트 셋 평가 ---\")\n",
    "    loss, accuracy = model.evaluate(test_gen) # 테스트 셋으로 손실과 정확도 계산\n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # 상세 평가 지표 추가\n",
    "    print(f\"\\n--- {model_name} 상세 평가 지표 ---\")\n",
    "    \n",
    "    test_gen.reset() # 제너레이터 초기화\n",
    "    y_pred_probs = model.predict(test_gen) # 테스트 제너레이터에서 예측 수행\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int) # sigmoid 출력 (0~1)을 0 또는 1로 변환\n",
    "    \n",
    "    y_true = test_gen.classes # 실제 라벨 가져오기 (제너레이터의 라벨 순서와 매칭)\n",
    "    \n",
    "    # 클래스 이름 (anomaly:0, normal:1)\n",
    "    target_names = [k for k, v in sorted(test_gen.class_indices.items(), key=lambda item: item[1])]\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    # F1-Score, Precision, Recall은 classification_report에 포함되지만 개별적으로도 출력\n",
    "    print(f\"F1-Score (weighted): {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Precision (weighted): {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Recall (weighted): {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    \n",
    "    return model, history # 학습된 모델과 학습 이력 반환\n",
    "\n",
    "# --- 각 모델별 학습 실행 ---\n",
    "epochs_to_train = 20 # 에포크 수 증가 (10 -> 20)\n",
    "\n",
    "# 클래스 가중치 계산 (불균형 해소)\n",
    "train_label_counts = train_df_keras['parsed_label'].value_counts()\n",
    "total_train_samples = len(train_df_keras)\n",
    "\n",
    "num_normal = train_label_counts.get('normal', 0)\n",
    "num_anomaly = train_label_counts.get('anomaly', 0)\n",
    "\n",
    "class_weights = {}\n",
    "# 'anomaly'와 'normal' 모두 샘플이 0개가 아닌 경우에만 가중치 계산\n",
    "if num_anomaly > 0 and num_normal > 0:\n",
    "    class_weights[train_generator.class_indices['anomaly']] = total_train_samples / (2 * num_anomaly)\n",
    "    class_weights[train_generator.class_indices['normal']] = total_train_samples / (2 * num_normal)\n",
    "elif num_anomaly == 0:\n",
    "    print(\"경고: 훈련 세트에 'anomaly' 샘플이 없어 'anomaly' 클래스 가중치를 계산할 수 없습니다. 클래스 불균형이 심각합니다.\")\n",
    "    # 이 경우 'normal'에 대한 가중치만 계산되거나, 가중치 적용이 무의미해질 수 있습니다.\n",
    "    # 모델 학습에 큰 영향을 줄 수 있으므로, anomaly 샘플 확보가 중요합니다.\n",
    "    if num_normal > 0:\n",
    "        class_weights[train_generator.class_indices['normal']] = total_train_samples / (2 * num_normal)\n",
    "elif num_normal == 0:\n",
    "    print(\"경고: 훈련 세트에 'normal' 샘플이 없어 'normal' 클래스 가중치를 계산할 수 없습니다.\")\n",
    "    if num_anomaly > 0:\n",
    "        class_weights[train_generator.class_indices['anomaly']] = total_train_samples / (2 * num_anomaly)\n",
    "\n",
    "\n",
    "print(f\"\\n계산된 클래스 가중치: {class_weights}\")\n",
    "\n",
    "\n",
    "print(\"===== Custom CNN 모델 학습 시작 =====\")\n",
    "custom_cnn_model = build_keras_model('custom_cnn', input_shape, 1) # num_classes = 1 for binary\n",
    "trained_custom_cnn_model, history_cnn = train_and_evaluate_keras_model(\n",
    "    custom_cnn_model, train_generator, validation_generator, test_generator, \n",
    "    \"Custom CNN\", epochs=epochs_to_train, class_weight=class_weights # 클래스 가중치 적용\n",
    ")\n",
    "\n",
    "print(\"\\n===== ResNet50 모델 학습 시작 =====\")\n",
    "resnet50_model = build_keras_model('resnet50', input_shape, 1) # num_classes = 1 for binary\n",
    "trained_resnet50_model, history_resnet50 = train_and_evaluate_keras_model(\n",
    "    resnet50_model, train_generator, validation_generator, test_generator, \n",
    "    \"ResNet50\", epochs=epochs_to_train, class_weight=class_weights # 클래스 가중치 적용\n",
    ")\n",
    "\n",
    "print(\"\\n===== EfficientNetB0 모델 학습 시작 =====\")\n",
    "efficientnetb0_model = build_keras_model('efficientnetb0', input_shape, 1) # num_classes = 1 for binary\n",
    "trained_efficientnetb0_model, history_efficientnetb0 = train_and_evaluate_keras_model(\n",
    "    efficientnetb0_model, train_generator, validation_generator, test_generator, \n",
    "    \"EfficientNetB0\", epochs=epochs_to_train, class_weight=class_weights # 클래스 가중치 적용\n",
    ")\n",
    "\n",
    "print(\"\\n모든 Keras 모델 학습 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
