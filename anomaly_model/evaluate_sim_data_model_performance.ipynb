{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1576c363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트 'Malgun Gothic' 적용 완료.\n",
      "\n",
      "--- 테스트 데이터 로드 시작 ---\n",
      "Found 5000 images belonging to 3 classes.\n",
      "Found 5000 images belonging to 3 classes.\n",
      "\n",
      "Stage 1 평가용 제너레이터 로드 완료. 샘플 수: 5000\n",
      "Stage 2 평가용 제너레이터 로드 완료. 샘플 수: 5000\n",
      "원본 폴더 -> 인덱스 매핑 (Stage 2 제너레이터 기준): {'Inner_Race_Fault': 0, 'Normal_Healthy': 1, 'Outer_Race_Fault': 2}\n",
      "Stage 1 최종 타겟 이름: ['Normal', 'Abnormal']\n",
      "Stage 2 최종 타겟 이름: ['Inner_Race_Fault', 'Normal_Healthy', 'Outer_Race_Fault']\n",
      "--- 테스트 데이터 로드 완료 ---\n",
      "\n",
      "--- 모델 로드 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 성공.\n",
      "\n",
      "--- 시뮬레이션 데이터 Stage 1 TL (ResNet) 모델 테스트 세트 평가 ---\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 387ms/step - accuracy: 0.3886 - loss: 1.8792\n",
      "시뮬레이션 데이터 Stage 1 TL (ResNet) Test Loss: 0.1238, Test Accuracy: 0.4920\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 387ms/step\n",
      "\n",
      "--- 시뮬레이션 데이터 Stage 1 TL (ResNet) 분류 리포트 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.52      0.05      0.09      2517\n",
      "    Abnormal       0.50      0.96      0.65      2483\n",
      "\n",
      "    accuracy                           0.50      5000\n",
      "   macro avg       0.51      0.50      0.37      5000\n",
      "weighted avg       0.51      0.50      0.37      5000\n",
      "\n",
      "\n",
      "--- 시뮬레이션 데이터 Stage 1 TL (ResNet) 혼동 행렬 ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Normal/Abnormal 분류를 위한 최적 임계값 탐색 (f1_score 기준) ---\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 380ms/step\n",
      "최적 임계값 (f1_score 기준): 0.0082\n",
      "최적 F1-Score: 0.6636\n",
      "해당 정밀도 (Precision): 0.4966\n",
      "해당 재현율 (Recall): 1.0000\n",
      "\n",
      "--- 최적 임계값(0.0082) 적용 시 분류 리포트 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.00      0.00      0.00      2517\n",
      "    Abnormal       0.50      1.00      0.66      2483\n",
      "\n",
      "    accuracy                           0.50      5000\n",
      "   macro avg       0.25      0.50      0.33      5000\n",
      "weighted avg       0.25      0.50      0.33      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 시뮬레이션 데이터 Stage 2 TL (ResNet) 모델 테스트 세트 평가 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 382ms/step - accuracy: 0.4298 - loss: 15.2031\n",
      "시뮬레이션 데이터 Stage 2 TL (ResNet) Test Loss: 20.7334, Test Accuracy: 0.2516\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 391ms/step\n",
      "\n",
      "--- 시뮬레이션 데이터 Stage 2 TL (ResNet) 분류 리포트 ---\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Inner_Race_Fault       0.25      0.72      0.37      1236\n",
      "  Normal_Healthy       0.00      0.00      0.00      2517\n",
      "Outer_Race_Fault       0.25      0.30      0.27      1247\n",
      "\n",
      "        accuracy                           0.25      5000\n",
      "       macro avg       0.17      0.34      0.21      5000\n",
      "    weighted avg       0.12      0.25      0.16      5000\n",
      "\n",
      "\n",
      "--- 시뮬레이션 데이터 Stage 2 TL (ResNet) 혼동 행렬 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 시뮬레이션 데이터 기반 모델 평가 완료 ---\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_recall_curve, roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# --- 1. 설정 (Configuration) ---\n",
    "# 모델 파일 경로 (실제 저장된 경로로 수정하세요!)\n",
    "STAGE1_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5'\n",
    "STAGE2_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5'\n",
    "\n",
    "# 시뮬레이션 데이터셋 루트 폴더 경로\n",
    "# main_data_generation_and_conversion.py가 생성한 폴더입니다.\n",
    "SIM_TEST_DATA_DIR = 'local_test_spectrograms'\n",
    "\n",
    "# 스펙트로그램 이미지 및 배치 크기 (모델 학습 시와 동일해야 함)\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- 2. 한글 폰트 설정 (matplotlib에서 한글 깨짐 방지) ---\n",
    "# 시스템에 설치된 한글 폰트 경로를 찾거나 (예: Windows 'malgun.ttf', macOS 'AppleGothic.ttc')\n",
    "# 직접 폰트 파일을 추가한 후 해당 경로를 지정\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf' # Windows 예시 (본인 PC에 맞게 수정)\n",
    "# font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc' # macOS 예시\n",
    "\n",
    "if os.path.exists(font_path):\n",
    "    font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "    mpl.rc('font', family=font_name)\n",
    "    mpl.rcParams['axes.unicode_minus'] = False # 마이너스 폰트 깨짐 방지\n",
    "    print(f\"한글 폰트 '{font_name}' 적용 완료.\")\n",
    "else:\n",
    "    print(f\"경고: 한글 폰트 파일을 찾을 수 없습니다. 경로를 확인해주세요: {font_path}\")\n",
    "    print(\"그래프에 한글이 깨질 수 있습니다. 기본 폰트로 표시합니다.\")\n",
    "\n",
    "# --- 3. 데이터 로드 (각 Stage 평가를 위한 별도 제너레이터 사용) ---\n",
    "print(\"\\n--- 테스트 데이터 로드 시작 ---\")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Stage 1 평가를 위한 제너레이터: class_mode='binary'\n",
    "# 이 제너레이터는 'Normal_Healthy' 폴더를 0으로, 'Inner_Race_Fault'와 'Outer_Race_Fault' 폴더를 1로 매핑합니다.\n",
    "# (flow_from_directory가 내부적으로 이진 분류를 위해 폴더를 묶는 방식에 따라 달라질 수 있으므로,\n",
    "# 실제 매핑을 확인하고 target_names를 정확히 설정하는 것이 중요합니다.)\n",
    "test_generator_s1_eval = test_datagen.flow_from_directory(\n",
    "    SIM_TEST_DATA_DIR,\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary', # <-- Stage 1 평가를 위해 'binary' 모드 사용\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Stage 2 평가를 위한 제너레이터: class_mode='categorical'\n",
    "# 이 제너레이터는 'Inner_Race_Fault':0, 'Normal_Healthy':1, 'Outer_Race_Fault':2 로 매핑합니다.\n",
    "test_generator_s2_eval = test_datagen.flow_from_directory(\n",
    "    SIM_TEST_DATA_DIR,\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', # <-- Stage 2 평가를 위해 'categorical' 모드 사용\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# 생성기에서 실제 클래스 매핑 확인 (중요!)\n",
    "# test_generator_s1_eval의 class_indices는 이진 분류 매핑을 보여주지 않습니다.\n",
    "# test_generator_s2_eval의 class_indices를 통해 원본 폴더 인덱스를 확인합니다.\n",
    "actual_categorical_class_indices = test_generator_s2_eval.class_indices\n",
    "print(f\"\\nStage 1 평가용 제너레이터 로드 완료. 샘플 수: {test_generator_s1_eval.samples}\")\n",
    "print(f\"Stage 2 평가용 제너레이터 로드 완료. 샘플 수: {test_generator_s2_eval.samples}\")\n",
    "print(f\"원본 폴더 -> 인덱스 매핑 (Stage 2 제너레이터 기준): {actual_categorical_class_indices}\")\n",
    "\n",
    "# Stage 1의 최종 타겟 이름 정의 (Normal_Healthy -> Normal, Inner/Outer -> Abnormal)\n",
    "# test_generator_s1_eval의 binary 매핑에 맞춰야 합니다.\n",
    "# flow_from_directory(class_mode='binary')는 보통 알파벳 순서로 0,1을 할당합니다.\n",
    "# 'Normal_Healthy'가 'Normal' (0)으로, 'Inner_Race_Fault'/'Outer_Race_Fault'가 'Abnormal' (1)으로 매핑되도록\n",
    "# y_true_final을 구성할 것이므로, target_names도 이에 맞춰 'Normal', 'Abnormal' 순서로 정의합니다.\n",
    "s1_target_names = ['Normal', 'Abnormal'] \n",
    "\n",
    "# Stage 2의 실제 클래스 이름은 test_generator_s2_eval의 class_indices와 일치합니다.\n",
    "s2_target_names = [k for k, v in sorted(actual_categorical_class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(f\"Stage 1 최종 타겟 이름: {s1_target_names}\")\n",
    "print(f\"Stage 2 최종 타겟 이름: {s2_target_names}\")\n",
    "print(\"--- 테스트 데이터 로드 완료 ---\")\n",
    "\n",
    "# --- 4. 모델 로드 ---\n",
    "print(\"\\n--- 모델 로드 시작 ---\")\n",
    "try:\n",
    "    loaded_stage1_model = tf.keras.models.load_model(STAGE1_MODEL_PATH)\n",
    "    loaded_stage2_model = tf.keras.models.load_model(STAGE2_MODEL_PATH)\n",
    "    print(\"모델 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit() # 모델 로드 실패 시 스크립트 종료\n",
    "\n",
    "# --- 5. 평가 및 시각화 함수 정의 ---\n",
    "\n",
    "def evaluate_and_report(model, generator, title, is_binary=False, class_names=None):\n",
    "    print(f\"\\n--- {title} 모델 테스트 세트 평가 ---\")\n",
    "    \n",
    "    # 모델 평가 (loss, accuracy)\n",
    "    # 각 모델에 맞는 제너레이터 (binary 또는 categorical)를 직접 전달합니다.\n",
    "    loss, accuracy = model.evaluate(generator, verbose=1)\n",
    "    print(f\"{title} Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # 예측 수행\n",
    "    y_pred_probs = model.predict(generator, verbose=1)\n",
    "    \n",
    "    # 실제 라벨 (y_true)과 예측 라벨 (y_pred) 준비\n",
    "    # generator.classes는 해당 제너레이터의 class_mode에 따라 0/1 또는 0/1/2 인덱스를 가집니다.\n",
    "    y_true_generator_labels = generator.classes \n",
    "\n",
    "    if is_binary: # Stage 1 평가\n",
    "        # Stage 1의 실제 이진 라벨 (0:Normal, 1:Abnormal) 생성\n",
    "        # test_generator_s1_eval의 class_indices는 이진 매핑을 직접 보여주지 않으므로,\n",
    "        # 원본 폴더 매핑(actual_categorical_class_indices)을 기준으로 재매핑합니다.\n",
    "        y_true_final = np.array([0 if label_idx == actual_categorical_class_indices['Normal_Healthy'] else 1\n",
    "                                 for label_idx in y_true_generator_labels])\n",
    "        \n",
    "        # Stage 1 모델의 예측 확률을 이진화 (임계값 0.5)\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "        \n",
    "    else: # Stage 2 평가\n",
    "        # Stage 2의 실제 라벨은 제너레이터가 제공하는 원본 인덱스 그대로 사용\n",
    "        y_true_final = y_true_generator_labels\n",
    "        \n",
    "        # Stage 2 모델의 예측 확률에서 가장 높은 확률의 클래스 인덱스 선택\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # 분류 보고서\n",
    "    report_names = class_names # 외부에서 정의된 s1_target_names 또는 s2_target_names 사용\n",
    "    print(f\"\\n--- {title} 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_final, y_pred, target_names=report_names))\n",
    "\n",
    "    # 혼동 행렬 시각화\n",
    "    print(f\"\\n--- {title} 혼동 행렬 ---\")\n",
    "    cm = confusion_matrix(y_true_final, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=report_names, yticklabels=report_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'{title} 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "# --- 6. Stage 1 임계값 최적화 로직 ---\n",
    "\n",
    "def find_optimal_threshold(model, generator, class_names, metric='f1_score'):\n",
    "    \"\"\"\n",
    "    Stage 1 모델의 최적 임계값을 찾고 관련 성능을 출력합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- {class_names[0]}/{class_names[1]} 분류를 위한 최적 임계값 탐색 ({metric} 기준) ---\")\n",
    "    \n",
    "    # 모델 예측 확률 (sigmoid output)\n",
    "    y_pred_probs = model.predict(generator, verbose=1).ravel()\n",
    "    \n",
    "    # 실제 라벨 (y_true) 준비: 원본 폴더 인덱스를 이진 라벨로 변환\n",
    "    y_true_generator_labels = generator.classes\n",
    "    y_true_binary = np.array([0 if label_idx == actual_categorical_class_indices['Normal_Healthy'] else 1\n",
    "                             for label_idx in y_true_generator_labels])\n",
    "\n",
    "    # Precision-Recall Curve를 통해 최적 임계값 탐색\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_binary, y_pred_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8) # f1_score 계산 (0으로 나누기 방지)\n",
    "\n",
    "    # F1-Score가 최대가 되는 임계값 찾기\n",
    "    optimal_threshold_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_threshold_idx]\n",
    "    optimal_f1 = f1_scores[optimal_threshold_idx]\n",
    "    optimal_precision = precisions[optimal_threshold_idx]\n",
    "    optimal_recall = recalls[optimal_threshold_idx]\n",
    "\n",
    "    print(f\"최적 임계값 ({metric} 기준): {optimal_threshold:.4f}\")\n",
    "    print(f\"최적 F1-Score: {optimal_f1:.4f}\")\n",
    "    print(f\"해당 정밀도 (Precision): {optimal_precision:.4f}\")\n",
    "    print(f\"해당 재현율 (Recall): {optimal_recall:.4f}\")\n",
    "\n",
    "    # 최적 임계값 적용 시 분류 리포트 및 혼동 행렬\n",
    "    y_pred_optimal = (y_pred_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n--- 최적 임계값({optimal_threshold:.4f}) 적용 시 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_binary, y_pred_optimal, target_names=class_names))\n",
    "\n",
    "    cm_optimal = confusion_matrix(y_true_binary, y_pred_optimal)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_optimal, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'최적 임계값({optimal_threshold:.4f}) 적용 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve 시각화\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true_binary, y_pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 7. 메인 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Stage 1 모델 평가\n",
    "    # Stage 1 평가를 위한 제너레이터 test_generator_s1_eval을 사용합니다.\n",
    "    evaluate_and_report(loaded_stage1_model, test_generator_s1_eval, \"시뮬레이션 데이터 Stage 1 TL (ResNet)\",\n",
    "                        is_binary=True, class_names=s1_target_names)\n",
    "\n",
    "    # Stage 1 최적 임계값 찾기\n",
    "    find_optimal_threshold(loaded_stage1_model, test_generator_s1_eval, class_names=s1_target_names, metric='f1_score')\n",
    "\n",
    "    # Stage 2 모델 평가\n",
    "    # Stage 2 평가를 위한 제너레이터 test_generator_s2_eval을 사용합니다.\n",
    "    evaluate_and_report(loaded_stage2_model, test_generator_s2_eval, \"시뮬레이션 데이터 Stage 2 TL (ResNet)\",\n",
    "                        is_binary=False, class_names=s2_target_names)\n",
    "\n",
    "    print(\"\\n--- 시뮬레이션 데이터 기반 모델 평가 완료 ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71414f7d",
   "metadata": {},
   "source": [
    "📊 시뮬레이션 데이터 기반 모델 평가 결과 해석\n",
    "전반적으로, 시뮬레이션 데이터에 대한 모델의 성능은 매우 좋지 않으며, 심각한 문제가 있음을 시사합니다. 특히 학습 데이터셋에서 보여주었던 높은 성능(97~98%)과는 극명한 대조를 이룹니다.\n",
    "\n",
    "1. Stage 1 모델 평가 (정상/비정상 분류)\n",
    "Test Loss: 0.1238, Test Accuracy: 0.4920 (약 49.2%)\n",
    "\n",
    "정확도가 약 50%라는 것은 모델이 무작위로 예측하는 수준이거나, 혹은 라벨 매핑이 여전히 뒤바뀌어 있을 가능성이 높다는 것을 의미합니다.\n",
    "\n",
    "분류 리포트 (기본 임계값 0.5)\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "    Normal       0.52      0.05      0.09      2517\n",
    "  Abnormal       0.50      0.96      0.65      2483\n",
    "  accuracy                           0.50      5000\n",
    " macro avg       0.51      0.50      0.37      5000\n",
    "weighted avg       0.51      0.50      0.37      5000\n",
    "Normal 클래스: Precision은 0.52로 높지만, Recall이 0.05로 매우 낮습니다. 이는 실제 Normal인 것들을 거의 대부분 Abnormal로 잘못 예측하고 있다는 뜻입니다. (5%만 제대로 맞춤)\n",
    "\n",
    "Abnormal 클래스: Recall이 0.96으로 매우 높지만, Precision이 0.50으로 낮습니다. 이는 모델이 대부분을 Abnormal로 예측하여 실제 Abnormal인 것을 많이 맞추지만, Normal인 것도 Abnormal로 많이 오분류하고 있다는 뜻입니다.\n",
    "\n",
    "결론: 모델이 거의 모든 샘플을 'Abnormal'로 예측하는 경향을 보입니다. (정상인 것도 비정상으로 판단)\n",
    "\n",
    "혼동 행렬 (기본 임계값 0.5) - image_e6ddc5.png\n",
    "\n",
    "실제 Normal (2517개) 중 2399개를 Abnormal로 오분류, 118개만 Normal로 맞춤.\n",
    "\n",
    "실제 Abnormal (2483개) 중 2374개를 Abnormal로 맞춤, 109개를 Normal로 오분류.\n",
    "\n",
    "이 혼동 행렬은 분류 리포트의 해석과 일치합니다. 모델이 거의 모든 샘플을 'Abnormal'로 예측하고 있음을 명확히 보여줍니다.\n",
    "\n",
    "최적 임계값 탐색 (F1-Score 기준)\n",
    "\n",
    "최적 임계값: 0.0082 (매우 낮은 값)\n",
    "\n",
    "최적 F1-Score: 0.6636 (Abnormal 클래스의 F1-score와 유사)\n",
    "\n",
    "해당 정밀도 (Precision): 0.4966, 재현율 (Recall): 1.0000\n",
    "\n",
    "결론: 임계값을 0.0082로 낮추면 모델은 거의 100%의 샘플을 'Abnormal'로 예측하게 됩니다.\n",
    "\n",
    "최적 임계값(0.0082) 적용 시 분류 리포트\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "    Normal       0.00      0.00      0.00      2517\n",
    "  Abnormal       0.50      1.00      0.66      2483\n",
    "  accuracy                           0.50      5000\n",
    " macro avg       0.25      0.50      0.33      5000\n",
    "weighted avg       0.25      0.50      0.33      5000\n",
    "Normal 클래스의 Precision, Recall, F1-score가 모두 0.00입니다. 이는 Normal 클래스를 단 한 개도 제대로 예측하지 못했다는 의미입니다.\n",
    "\n",
    "Abnormal 클래스의 Recall이 1.00인 것은 모든 샘플을 Abnormal로 예측했기 때문입니다. Precision이 0.50인 것은 실제 Abnormal인 샘플(2483개)이 전체 샘플(5000개)의 약 절반이기 때문입니다.\n",
    "\n",
    "UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. 경고는 Normal 클래스에 대해 예측된 샘플이 없어서 정밀도를 계산할 수 없다는 뜻입니다.\n",
    "\n",
    "최적 임계값(0.0082) 적용 혼동 행렬 - image_e6ddbe.png\n",
    "\n",
    "실제 Normal (2517개)과 실제 Abnormal (2483개) 모두 전부 'Abnormal'로 예측되었습니다.\n",
    "\n",
    "이것은 모델이 모든 입력에 대해 'Abnormal'이라고만 답하는 상태와 같습니다.\n",
    "\n",
    "ROC Curve - image_e6db1a.png\n",
    "\n",
    "ROC curve (area = 0.50)\n",
    "\n",
    "AUC(Area Under the Curve)가 0.50이라는 것은 모델의 분류 성능이 완전히 무작위 추측과 동일하다는 것을 의미합니다. 대각선에 가까운 ROC 곡선은 모델이 긍정(Abnormal)과 부정(Normal) 클래스를 전혀 구별하지 못하고 있음을 보여줍니다.\n",
    "\n",
    "2. Stage 2 모델 평가 (세부 고장 유형 분류)\n",
    "Test Loss: 20.7334, Test Accuracy: 0.2516 (약 25.16%)\n",
    "\n",
    "다중 클래스 분류에서 정확도 25%는 3개 클래스 중 하나를 무작위로 찍는 것(33.3%)보다도 훨씬 낮은 성능입니다. Loss 값이 매우 높은 것도 심각한 문제입니다.\n",
    "\n",
    "분류 리포트\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "Inner_Race_Fault       0.25      0.72      0.37      1236\n",
    "  Normal_Healthy       0.00      0.00      0.00      2517\n",
    "Outer_Race_Fault       0.25      0.30      0.27      1247\n",
    "        accuracy                           0.25      5000\n",
    "       macro avg       0.17      0.34      0.21      5000\n",
    "    weighted avg       0.12      0.25      0.16      5000\n",
    "Normal_Healthy 클래스: Precision, Recall, F1-score가 모두 0.00입니다. Stage 1과 마찬가지로 Normal_Healthy 샘플을 단 한 개도 제대로 예측하지 못했다는 의미입니다.\n",
    "\n",
    "Inner_Race_Fault: Recall은 0.72로 높지만, Precision은 0.25로 매우 낮습니다. 이는 Inner_Race_Fault로 예측한 것 중 75%는 실제 Inner_Race_Fault가 아니라는 뜻입니다.\n",
    "\n",
    "Outer_Race_Fault: Precision 0.25, Recall 0.30으로 매우 낮습니다.\n",
    "\n",
    "결론: Stage 2 모델 역시 특정 클래스(Inner_Race_Fault)로 편향된 예측을 하거나, 전반적으로 클래스들을 거의 구별하지 못하고 있습니다.\n",
    "\n",
    "혼동 행렬 - image_e6dafc.png\n",
    "\n",
    "실제 Normal_Healthy (2517개)는 거의 대부분 Inner_Race_Fault (1744개)나 Outer_Race_Fault (773개)로 오분류되었습니다.\n",
    "\n",
    "실제 Inner_Race_Fault (1236개)는 890개만 맞추고, 346개를 Outer_Race_Fault로 오분류했습니다.\n",
    "\n",
    "실제 Outer_Race_Fault (1247개)는 368개만 맞추고, 879개를 Inner_Race_Fault로 오분류했습니다.\n",
    "\n",
    "이 혼동 행렬은 모델이 Normal_Healthy를 다른 고장으로, 그리고 Inner_Race_Fault와 Outer_Race_Fault를 서로 많이 혼동하고 있음을 보여줍니다.\n",
    "\n",
    "🚨 심각한 문제 진단 및 해결 방안\n",
    "이러한 결과는 모델이 시뮬레이션 데이터를 전혀 학습하지 못하고 있거나, 학습된 모델이 시뮬레이션 데이터와 완전히 다른 특성을 가지고 있기 때문입니다.\n",
    "\n",
    "가장 유력한 원인들을 다시 정리하고 해결 방안을 제시합니다:\n",
    "\n",
    "시뮬레이션 데이터의 스펙트로그램 품질 문제 (가장 유력):\n",
    "\n",
    "문제: 시뮬레이션으로 생성된 신호가 실제 베어링 고장 특성을 충분히 반영하지 못하거나, 노이즈가 너무 강해서 고장 신호가 묻히거나, 혹은 스펙트로그램 변환 파라미터가 적절하지 않아 모델이 학습했던 스펙트로그램 이미지와 시뮬레이션 스펙트로그램 이미지의 '모양'이 너무 다를 수 있습니다.\n",
    "\n",
    "확인:\n",
    "\n",
    "main_data_generation_and_conversion.py에서 display_plot=True로 설정하고 생성되는 스펙트로그램 이미지들을 직접 육안으로 확인해 보세요. 정상, 내륜 고장, 외륜 고장 스펙트로그램 간에 시각적으로 뚜렷한 차이가 있는지 확인해야 합니다.\n",
    "\n",
    "만약 차이가 없다면, 시뮬레이션 파라미터(a_L, a_N, a_lambda, a_delta, a_noise 등)를 조정하여 고장 신호의 특징이 더 뚜렷하게 나타나도록 시뮬레이션 로직을 개선해야 합니다. 특히 Bearing 클래스의 m_duration 계산이나 get_amplitude 로직이 물리적으로 정확한지 다시 한번 검토해야 합니다.\n",
    "\n",
    "RealisticNoiseInjector의 snr_db를 너무 낮게 설정하면 신호가 노이즈에 완전히 묻힐 수 있습니다. snr_db를 높여서(예: 30~40dB) 노이즈 수준을 낮춰서 테스트해 보세요.\n",
    "\n",
    "Simulation.py의 스레드 간 waveform 공유 시 Race Condition 문제가 해결되었는지 다시 한번 확인해야 합니다. 데이터가 잘못 기록되었을 수 있습니다. (threading.Lock 사용 또는 스레드별 독립 계산 후 합치기)\n",
    "\n",
    "스펙트로그램 변환 파라미터 불일치:\n",
    "\n",
    "문제: main_data_generation_and_conversion.py의 SPECTRO_ 파라미터들(특히 sampling_rate, n_fft, hop_length, n_mels, fmin, fmax, image_width, image_height)이 딥러닝 모델 학습 시 스펙트로그램을 생성했던 파라미터들과 100% 동일한지 다시 한번 확인해야 합니다. 단 하나의 파라미터라도 다르면 스펙트로그램의 형태가 달라져 모델이 인식하지 못합니다.\n",
    "\n",
    "확인: 2d-cnn-lstm-by-spectro-f1.ipynb 또는 transfer-resnet.ipynb 파일의 데이터 로드 및 전처리 섹션에서 사용된 스펙트로그램 파라미터들을 정확히 확인하여 main_data_generation_and_conversion.py의 SPECTRO_ 파라미터들과 비교하세요.\n",
    "\n",
    "모델 로드 문제 (가능성 낮음):\n",
    "\n",
    "WARNING:absl:Compiled the loaded model... 경고는 정상적이라고 했지만, 만약 모델 파일 자체가 손상되었거나, 로드된 모델의 내부 구조가 예상과 다를 경우 이런 문제가 생길 수도 있습니다. (가능성은 낮음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cad1e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트 'Malgun Gothic' 적용 완료.\n",
      "\n",
      "--- 파인튜닝 데이터 구조 재구성 시작 (원본: local_test_spectrograms) ---\n",
      "  -> 2517개의 Normal_Healthy 이미지를 finetune_data_s1/Normal 에 복사.\n",
      "  -> 1236개의 Inner_Race_Fault 이미지를 finetune_data_s1/Abnormal 에 복사.\n",
      "  -> 1247개의 Outer_Race_Fault 이미지를 finetune_data_s1/Abnormal 에 복사.\n",
      "  -> Stage 2용 데이터 finetune_data_s2 에 원본 구조로 복사 완료.\n",
      "--- 파인튜닝 데이터 구조 재구성 완료 ---\n",
      "\n",
      "--- 파인튜닝 데이터 로드 시작 ---\n",
      "Found 4001 images belonging to 2 classes.\n",
      "Found 999 images belonging to 2 classes.\n",
      "Found 4001 images belonging to 3 classes.\n",
      "Found 999 images belonging to 3 classes.\n",
      "\n",
      "Stage 1 학습용 제너레이터 클래스 매핑: {'Abnormal': 0, 'Normal': 1}\n",
      "Stage 2 학습용 제너레이터 클래스 매핑: {'Inner_Race_Fault': 0, 'Normal_Healthy': 1, 'Outer_Race_Fault': 2}\n",
      "Stage 1 최종 타겟 이름: ['Abnormal', 'Normal']\n",
      "Stage 2 최종 타겟 이름: ['Inner_Race_Fault', 'Normal_Healthy', 'Outer_Race_Fault']\n",
      "--- 파인튜닝 데이터 로드 완료 ---\n",
      "\n",
      "--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 모델 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5' 로드 성공.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 모델 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5' 로드 성공.\n",
      "모델 재컴파일 완료. 학습률: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">33,620,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_binary (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m65536\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m33,620,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_binary (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,185,415</span> (218.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,185,415\u001b[0m (218.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,139,975</span> (217.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,139,975\u001b[0m (217.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,440</span> (177.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m45,440\u001b[0m (177.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 재컴파일 완료. 학습률: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">33,620,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_categorical (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m65536\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m33,620,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_categorical (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,185,673</span> (218.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,185,673\u001b[0m (218.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,140,233</span> (217.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,140,233\u001b[0m (217.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,440</span> (177.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m45,440\u001b[0m (177.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 모델 로드 및 파인튜닝 설정 완료 ---\n",
      "\n",
      "--- 모델 파인튜닝 시작 ---\n",
      "\n",
      "Stage 1 파인튜닝 클래스 가중치: {0: np.float64(1.0067941620533467), 1: np.float64(0.9932969215491559)}\n",
      "Stage 2 파인튜닝 클래스 가중치: {0: np.float64(1.348500168520391), 1: np.float64(0.6621979476994373), 2: np.float64(1.3363393453573815)}\n",
      "\n",
      "--- Stage 1 모델 파인튜닝 시작 ---\n",
      "Epoch 1/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5046 - loss: 9.0097\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50450, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 2s/step - accuracy: 0.5046 - loss: 8.9750 - val_accuracy: 0.5045 - val_loss: 2.7537 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5739 - loss: 0.8406\n",
      "Epoch 2: val_accuracy did not improve from 0.50450\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - accuracy: 0.5739 - loss: 0.8402 - val_accuracy: 0.4995 - val_loss: 1.7481 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6285 - loss: 0.6444\n",
      "Epoch 3: val_accuracy improved from 0.50450 to 0.50951, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 2s/step - accuracy: 0.6285 - loss: 0.6444 - val_accuracy: 0.5095 - val_loss: 0.8683 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6788 - loss: 0.5883\n",
      "Epoch 4: val_accuracy improved from 0.50951 to 0.51251, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 2s/step - accuracy: 0.6788 - loss: 0.5883 - val_accuracy: 0.5125 - val_loss: 0.7789 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7578 - loss: 0.4953\n",
      "Epoch 5: val_accuracy did not improve from 0.51251\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - accuracy: 0.7578 - loss: 0.4953 - val_accuracy: 0.4935 - val_loss: 0.8433 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8365 - loss: 0.3897\n",
      "Epoch 6: val_accuracy did not improve from 0.51251\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 2s/step - accuracy: 0.8364 - loss: 0.3897 - val_accuracy: 0.5125 - val_loss: 0.9126 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8838 - loss: 0.2902\n",
      "Epoch 7: val_accuracy did not improve from 0.51251\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 2s/step - accuracy: 0.8838 - loss: 0.2902 - val_accuracy: 0.5075 - val_loss: 1.0571 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9273 - loss: 0.1918\n",
      "Epoch 8: val_accuracy did not improve from 0.51251\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 2s/step - accuracy: 0.9273 - loss: 0.1918 - val_accuracy: 0.5055 - val_loss: 1.1882 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m 10/126\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 2s/step - accuracy: 0.9413 - loss: 0.1427"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 274\u001b[0m\n\u001b[0;32m    267\u001b[0m callbacks_ft_s2 \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    268\u001b[0m     ModelCheckpoint(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(FINE_TUNED_MODELS_SAVE_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage2_fine_tuned_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m), monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    269\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    270\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    271\u001b[0m ]\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stage 1 모델 파인튜닝 시작 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 274\u001b[0m history_s1_ft \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_stage1_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator_ft_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# <-- Stage 1 전용 제너레이터 사용\u001b[39;49;00m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFINETUNE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator_ft_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# <-- Stage 1 전용 제너레이터 사용\u001b[39;49;00m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict_s1_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_ft_s1\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stage 2 모델 파인튜닝 시작 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m history_s2_ft \u001b[38;5;241m=\u001b[39m loaded_stage2_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    284\u001b[0m     train_generator_ft_s2, \u001b[38;5;66;03m# <-- Stage 2 전용 제너레이터 사용\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mFINETUNE_EPOCHS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks_ft_s2\n\u001b[0;32m    289\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fine_tune_model_with_sim_data.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2 # ResNet50V2를 사용하기 위해 Import\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil # 파일 복사를 위해 추가\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# --- 1. 설정 (Configuration) ---\n",
    "# 기존 학습된 모델 파일 경로 (실제 저장된 경로로 수정하세요!)\n",
    "STAGE1_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5'\n",
    "STAGE2_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5'\n",
    "\n",
    "# 새로 생성된 시뮬레이션 데이터셋 루트 폴더 경로 (원본)\n",
    "SIM_DATA_SOURCE_DIR = 'local_test_spectrograms' # main_data_generation_and_conversion.py가 생성한 폴더\n",
    "\n",
    "# 파인튜닝을 위한 재구성된 데이터셋을 저장할 경로\n",
    "# Stage 1용 (Normal/Abnormal)\n",
    "FINETUNE_DATA_S1_DIR = 'finetune_data_s1'\n",
    "# Stage 2용 (Inner_Race_Fault/Normal_Healthy/Outer_Race_Fault)\n",
    "FINETUNE_DATA_S2_DIR = 'finetune_data_s2'\n",
    "\n",
    "# 파인튜닝된 모델을 저장할 경로\n",
    "FINE_TUNED_MODELS_SAVE_DIR = 'fine_tuned_models'\n",
    "os.makedirs(FINE_TUNED_MODELS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 스펙트로그램 이미지 및 학습 파라미터\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "FINETUNE_EPOCHS = 30 # 파인튜닝 에포크 수 (EarlyStopping으로 조기 종료될 수 있음)\n",
    "FINETUNE_LEARNING_RATE = 1e-5 # 파인튜닝을 위한 매우 낮은 학습률 (기존 학습률보다 10배 이상 낮게)\n",
    "\n",
    "# --- 2. 한글 폰트 설정 (matplotlib에서 한글 깨짐 방지) ---\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf' # Windows 예시 (본인 PC에 맞게 수정)\n",
    "if os.path.exists(font_path):\n",
    "    font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "    mpl.rc('font', family=font_name)\n",
    "    mpl.rcParams['axes.unicode_minus'] = False # 마이너스 폰트 깨짐 방지\n",
    "    print(f\"한글 폰트 '{font_name}' 적용 완료.\")\n",
    "else:\n",
    "    print(f\"경고: 한글 폰트 파일을 찾을 수 없습니다. 경로를 확인해주세요: {font_path}\")\n",
    "    print(\"그래프에 한글이 깨질 수 있습니다. 기본 폰트로 표시합니다.\")\n",
    "\n",
    "# --- 3. 파인튜닝 데이터 구조 재구성 ---\n",
    "def prepare_finetune_data_structure(source_dir, dest_s1_dir, dest_s2_dir):\n",
    "    \"\"\"\n",
    "    원본 시뮬레이션 데이터를 Stage 1과 Stage 2 파인튜닝에 맞게 재구성합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 파인튜닝 데이터 구조 재구성 시작 (원본: {source_dir}) ---\")\n",
    "\n",
    "    # 기존 재구성 폴더 삭제 및 생성\n",
    "    if os.path.exists(dest_s1_dir): shutil.rmtree(dest_s1_dir)\n",
    "    if os.path.exists(dest_s2_dir): shutil.rmtree(dest_s2_dir)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Abnormal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Inner_Race_Fault'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Normal_Healthy'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Outer_Race_Fault'), exist_ok=True)\n",
    "\n",
    "    # 원본 클래스 폴더 경로\n",
    "    inner_race_dir = os.path.join(source_dir, 'Inner_Race_Fault')\n",
    "    normal_healthy_dir = os.path.join(source_dir, 'Normal_Healthy')\n",
    "    outer_race_dir = os.path.join(source_dir, 'Outer_Race_Fault')\n",
    "\n",
    "    # Stage 1: Normal / Abnormal\n",
    "    # Normal_Healthy -> Normal\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Normal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(normal_healthy_dir))}개의 Normal_Healthy 이미지를 {dest_s1_dir}/Normal 에 복사.\")\n",
    "\n",
    "    # Inner_Race_Fault -> Abnormal\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(inner_race_dir))}개의 Inner_Race_Fault 이미지를 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    # Outer_Race_Fault -> Abnormal\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(outer_race_dir))}개의 Outer_Race_Fault 이미지를 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    # Stage 2: Inner_Race_Fault / Normal_Healthy / Outer_Race_Fault (원본 그대로 복사)\n",
    "    # Inner_Race_Fault\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Inner_Race_Fault', img_name))\n",
    "    # Normal_Healthy\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Normal_Healthy', img_name))\n",
    "    # Outer_Race_Fault\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Outer_Race_Fault', img_name))\n",
    "    print(f\"  -> Stage 2용 데이터 {dest_s2_dir} 에 원본 구조로 복사 완료.\")\n",
    "    print(\"--- 파인튜닝 데이터 구조 재구성 완료 ---\")\n",
    "\n",
    "# 데이터 구조 재구성 함수 호출\n",
    "prepare_finetune_data_structure(SIM_DATA_SOURCE_DIR, FINETUNE_DATA_S1_DIR, FINETUNE_DATA_S2_DIR)\n",
    "\n",
    "\n",
    "# --- 4. 데이터 로드 (파인튜닝을 위한 학습/검증 데이터셋 분할) ---\n",
    "print(\"\\n--- 파인튜닝 데이터 로드 시작 ---\")\n",
    "\n",
    "# ImageDataGenerator를 사용하여 시뮬레이션 데이터를 학습/검증 세트로 분할\n",
    "finetune_datagen_s1 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    ")\n",
    "finetune_datagen_s2 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    ")\n",
    "\n",
    "# Stage 1 파인튜닝 학습/검증 제너레이터 (binary mode)\n",
    "train_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary', # <-- Stage 1은 'binary' 모드\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary', # <-- Stage 1은 'binary' 모드\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Stage 2 파인튜닝 학습/검증 제너레이터 (categorical mode)\n",
    "train_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', # <-- Stage 2는 'categorical' 모드\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', # <-- Stage 2는 'categorical' 모드\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "# 실제 클래스 매핑 확인 (각 제너레이터의 class_indices는 해당 제너레이터의 폴더 구조에 따라 매핑됨)\n",
    "print(f\"\\nStage 1 학습용 제너레이터 클래스 매핑: {train_generator_ft_s1.class_indices}\")\n",
    "print(f\"Stage 2 학습용 제너레이터 클래스 매핑: {train_generator_ft_s2.class_indices}\")\n",
    "\n",
    "# Stage 1의 최종 타겟 이름 정의 (Normal_Healthy -> Normal, Inner/Outer -> Abnormal)\n",
    "# train_generator_ft_s1의 class_indices를 기반으로 합니다.\n",
    "s1_target_names = [k for k, v in sorted(train_generator_ft_s1.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Stage 2의 실제 클래스 이름은 train_generator_ft_s2의 class_indices와 일치합니다.\n",
    "s2_target_names = [k for k, v in sorted(train_generator_ft_s2.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(f\"Stage 1 최종 타겟 이름: {s1_target_names}\")\n",
    "print(f\"Stage 2 최종 타겟 이름: {s2_target_names}\")\n",
    "print(\"--- 파인튜닝 데이터 로드 완료 ---\")\n",
    "\n",
    "# --- 5. 기존 모델 로드 및 파인튜닝을 위한 재설정 ---\n",
    "print(\"\\n--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\")\n",
    "\n",
    "# Stage 1 모델 로드\n",
    "try:\n",
    "    loaded_stage1_model = tf.keras.models.load_model(STAGE1_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 1 모델 '{STAGE1_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 1 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Stage 2 모델 로드\n",
    "try:\n",
    "    loaded_stage2_model = tf.keras.models.load_model(STAGE2_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 2 모델 '{STAGE2_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 2 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 파인튜닝을 위한 모델 레이어 동결 해제 및 재컴파일 ---\n",
    "\n",
    "def unfreeze_and_recompile_model(model, learning_rate, is_binary_classification=False, num_classes=None):\n",
    "    # 모델의 모든 레이어를 trainable=True로 설정 (전체 모델 파인튜닝)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # 재컴파일\n",
    "    if is_binary_classification:\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    print(f\"모델 재컴파일 완료. 학습률: {learning_rate}\")\n",
    "    model.summary() # 변경된 trainable 파라미터 수 확인\n",
    "\n",
    "# Stage 1 모델 파인튜닝을 위한 재설정\n",
    "unfreeze_and_recompile_model(loaded_stage1_model, FINETUNE_LEARNING_RATE, is_binary_classification=True)\n",
    "\n",
    "# Stage 2 모델 파인튜닝을 위한 재설정\n",
    "unfreeze_and_recompile_model(loaded_stage2_model, FINETUNE_LEARNING_RATE, is_binary_classification=False, num_classes=len(s2_target_names))\n",
    "\n",
    "print(\"--- 모델 로드 및 파인튜닝 설정 완료 ---\")\n",
    "\n",
    "# --- 6. 모델 학습 (파인튜닝) ---\n",
    "print(\"\\n--- 모델 파인튜닝 시작 ---\")\n",
    "\n",
    "# 클래스 가중치 계산 (파인튜닝 데이터셋 기준)\n",
    "# Stage 1 클래스 가중치\n",
    "# train_generator_ft_s1은 이미 binary mode로 로드되었으므로, labels를 그대로 사용합니다.\n",
    "class_weights_s1_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s1.labels),\n",
    "    y=train_generator_ft_s1.labels\n",
    ")\n",
    "class_weights_dict_s1_ft = {i: weight for i, weight in enumerate(class_weights_s1_ft)}\n",
    "print(f\"\\nStage 1 파인튜닝 클래스 가중치: {class_weights_dict_s1_ft}\")\n",
    "\n",
    "# Stage 2 클래스 가중치\n",
    "# train_generator_ft_s2는 이미 categorical mode로 로드되었으므로, labels를 그대로 사용합니다.\n",
    "class_weights_s2_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s2.labels),\n",
    "    y=train_generator_ft_s2.labels\n",
    ")\n",
    "class_weights_dict_s2_ft = {i: weight for i, weight in enumerate(class_weights_s2_ft)}\n",
    "print(f\"Stage 2 파인튜닝 클래스 가중치: {class_weights_dict_s2_ft}\")\n",
    "\n",
    "\n",
    "# 콜백 설정 (파인튜닝에 맞게 patience 조정 가능)\n",
    "callbacks_ft_s1 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "callbacks_ft_s2 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n--- Stage 1 모델 파인튜닝 시작 ---\")\n",
    "history_s1_ft = loaded_stage1_model.fit(\n",
    "    train_generator_ft_s1, # <-- Stage 1 전용 제너레이터 사용\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s1, # <-- Stage 1 전용 제너레이터 사용\n",
    "    class_weight=class_weights_dict_s1_ft,\n",
    "    callbacks=callbacks_ft_s1\n",
    ")\n",
    "\n",
    "print(\"\\n--- Stage 2 모델 파인튜닝 시작 ---\")\n",
    "history_s2_ft = loaded_stage2_model.fit(\n",
    "    train_generator_ft_s2, # <-- Stage 2 전용 제너레이터 사용\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s2, # <-- Stage 2 전용 제너레이터 사용\n",
    "    class_weight=class_weights_dict_s2_ft,\n",
    "    callbacks=callbacks_ft_s2\n",
    ")\n",
    "\n",
    "print(\"\\n--- 모델 파인튜닝 완료 ---\")\n",
    "\n",
    "# --- 7. 파인튜닝된 모델 평가 (간단한 평가) ---\n",
    "print(\"\\n--- 파인튜닝된 모델 최종 평가 ---\")\n",
    "\n",
    "# Stage 1 파인튜닝 모델 평가\n",
    "loss_s1_ft, acc_s1_ft = loaded_stage1_model.evaluate(val_generator_ft_s1, verbose=1) # <-- Stage 1 전용 제너레이터 사용\n",
    "print(f\"Stage 1 Fine-tuned Model Validation Loss: {loss_s1_ft:.4f}, Accuracy: {acc_s1_ft:.4f}\")\n",
    "\n",
    "# Stage 2 파인튜닝 모델 평가\n",
    "loss_s2_ft, acc_s2_ft = loaded_stage2_model.evaluate(val_generator_ft_s2, verbose=1) # <-- Stage 2 전용 제너레이터 사용\n",
    "print(f\"Stage 2 Fine-tuned Model Validation Loss: {loss_s2_ft:.4f}, Accuracy: {acc_s2_ft:.4f}\")\n",
    "\n",
    "print(\"\\n--- 파인튜닝 스크립트 실행 완료 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16826e1",
   "metadata": {},
   "source": [
    "# 과적합 발생 (조기종료 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58883782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_tune_model_with_sim_data.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "# 평가 및 시각화를 위한 라이브러리 추가\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_recall_curve, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# --- 1. 설정 (Configuration) ---\n",
    "STAGE1_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5'\n",
    "STAGE2_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5'\n",
    "\n",
    "SIM_DATA_SOURCE_DIR = 'local_test_spectrograms'\n",
    "\n",
    "FINETUNE_DATA_S1_DIR = 'finetune_data_s1'\n",
    "FINETUNE_DATA_S2_DIR = 'finetune_data_s2'\n",
    "\n",
    "FINE_TUNED_MODELS_SAVE_DIR = 'fine_tuned_models'\n",
    "os.makedirs(FINE_TUNED_MODELS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "FINETUNE_EPOCHS = 30 # 파인튜닝 에포크 수 (조기 종료될 수 있음)\n",
    "FINETUNE_LEARNING_RATE = 1e-5 # 파인튜닝을 위한 매우 낮은 학습률\n",
    "\n",
    "# --- 커스텀 콜백: 정확도 범위에 따라 학습 중단 ---\n",
    "class AccuracyRangeStopper(Callback):\n",
    "    def __init__(self, target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=0):\n",
    "        super().__init__()\n",
    "        self.target_min_accuracy = target_min_accuracy\n",
    "        self.target_max_accuracy = target_max_accuracy\n",
    "        self.verbose = verbose\n",
    "        self.stopped_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_val_accuracy = logs.get('val_accuracy')\n",
    "        if current_val_accuracy is None:\n",
    "            return\n",
    "\n",
    "        if self.target_min_accuracy <= current_val_accuracy <= self.target_max_accuracy:\n",
    "            self.stopped_epoch = epoch\n",
    "            self.model.stop_training = True\n",
    "            if self.verbose > 0:\n",
    "                print(f\"\\nEpoch {epoch + 1}: val_accuracy ({current_val_accuracy:.4f})가 목표 범위 ({self.target_min_accuracy:.2f}-{self.target_max_accuracy:.2f}) 내에 도달하여 학습을 중단합니다.\")\n",
    "\n",
    "# --- 2. 한글 폰트 설정 ---\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf' # Windows 예시 (본인 PC에 맞게 수정)\n",
    "# font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc' # macOS 예시\n",
    "if os.path.exists(font_path):\n",
    "    font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "    mpl.rc('font', family=font_name)\n",
    "    mpl.rcParams['axes.unicode_minus'] = False\n",
    "    print(f\"한글 폰트 '{font_name}' 적용 완료.\")\n",
    "else:\n",
    "    print(f\"경고: 한글 폰트 파일을 찾을 수 없습니다. 경로를 확인해주세요: {font_path}\")\n",
    "    print(\"그래프에 한글이 깨질 수 있습니다. 기본 폰트로 표시합니다.\")\n",
    "\n",
    "# --- 3. 파인튜닝 데이터 구조 재구성 ---\n",
    "def prepare_finetune_data_structure(source_dir, dest_s1_dir, dest_s2_dir):\n",
    "    \"\"\"\n",
    "    원본 시뮬레이션 데이터를 Stage 1과 Stage 2 파인튜닝에 맞게 재구성합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 파인튜닝 데이터 구조 재구성 시작 (원본: {source_dir}) ---\")\n",
    "\n",
    "    # 기존 재구성 폴더 삭제 및 생성\n",
    "    if os.path.exists(dest_s1_dir): shutil.rmtree(dest_s1_dir)\n",
    "    if os.path.exists(dest_s2_dir): shutil.rmtree(dest_s2_dir)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Abnormal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Inner_Race_Fault'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Normal_Healthy'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Outer_Race_Fault'), exist_ok=True)\n",
    "\n",
    "    # 원본 클래스 폴더 경로\n",
    "    inner_race_dir = os.path.join(source_dir, 'Inner_Race_Fault')\n",
    "    normal_healthy_dir = os.path.join(source_dir, 'Normal_Healthy')\n",
    "    outer_race_dir = os.path.join(source_dir, 'Outer_Race_Fault')\n",
    "\n",
    "    # Stage 1: Normal / Abnormal\n",
    "    # Normal_Healthy -> Normal\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Normal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(normal_healthy_dir))}개의 Normal_Healthy 이미지를 {dest_s1_dir}/Normal 에 복사.\")\n",
    "\n",
    "    # Inner_Race_Fault -> Abnormal\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(inner_race_dir))}개의 Inner_Race_Fault 이미지를 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    # Outer_Race_Fault -> Abnormal\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(outer_race_dir))}개의 Outer_Race_Fault 이미지를 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    # Stage 2: Inner_Race_Fault / Normal_Healthy / Outer_Race_Fault (원본 그대로 복사)\n",
    "    # Inner_Race_Fault\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Inner_Race_Fault', img_name))\n",
    "    # Normal_Healthy\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Normal_Healthy', img_name))\n",
    "    # Outer_Race_Fault\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Outer_Race_Fault', img_name))\n",
    "    print(f\"  -> Stage 2용 데이터 {dest_s2_dir} 에 원본 구조로 복사 완료.\")\n",
    "    print(\"--- 파인튜닝 데이터 구조 재구성 완료 ---\")\n",
    "\n",
    "# 데이터 구조 재구성 함수 호출\n",
    "prepare_finetune_data_structure(SIM_DATA_SOURCE_DIR, FINETUNE_DATA_S1_DIR, FINETUNE_DATA_S2_DIR)\n",
    "\n",
    "\n",
    "# --- 4. 데이터 로드 (파인튜닝을 위한 학습/검증 데이터셋 분할) ---\n",
    "print(\"\\n--- 파인튜닝 데이터 로드 시작 ---\")\n",
    "\n",
    "finetune_datagen_s1 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    ")\n",
    "finetune_datagen_s2 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    ")\n",
    "\n",
    "train_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary', # <-- Stage 1은 'binary' 모드\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary', # <-- Stage 1은 'binary' 모드\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "train_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', # <-- Stage 2는 'categorical' 모드\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical', # <-- Stage 2는 'categorical' 모드\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nStage 1 학습용 제너레이터 클래스 매핑: {train_generator_ft_s1.class_indices}\")\n",
    "print(f\"Stage 2 학습용 제너레이터 클래스 매핑: {train_generator_ft_s2.class_indices}\")\n",
    "\n",
    "s1_target_names = [k for k, v in sorted(train_generator_ft_s1.class_indices.items(), key=lambda item: item[1])]\n",
    "s2_target_names = [k for k, v in sorted(train_generator_ft_s2.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(f\"Stage 1 최종 타겟 이름: {s1_target_names}\")\n",
    "print(f\"Stage 2 최종 타겟 이름: {s2_target_names}\")\n",
    "print(\"--- 파인튜닝 데이터 로드 완료 ---\")\n",
    "\n",
    "# --- 5. 기존 모델 로드 및 파인튜닝을 위한 재설정 ---\n",
    "print(\"\\n--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\")\n",
    "\n",
    "try:\n",
    "    loaded_stage1_model = tf.keras.models.load_model(STAGE1_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 1 모델 '{STAGE1_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 1 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    loaded_stage2_model = tf.keras.models.load_model(STAGE2_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 2 모델 '{STAGE2_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 2 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "def unfreeze_and_recompile_model(model, learning_rate, is_binary_classification=False, num_classes=None):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    if is_binary_classification:\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    print(f\"모델 재컴파일 완료. 학습률: {learning_rate}\")\n",
    "    model.summary()\n",
    "\n",
    "unfreeze_and_recompile_model(loaded_stage1_model, FINETUNE_LEARNING_RATE, is_binary_classification=True)\n",
    "unfreeze_and_recompile_model(loaded_stage2_model, FINETUNE_LEARNING_RATE, is_binary_classification=False, num_classes=len(s2_target_names))\n",
    "\n",
    "print(\"--- 모델 로드 및 파인튜닝 설정 완료 ---\")\n",
    "\n",
    "# --- 6. 모델 학습 (파인튜닝) ---\n",
    "print(\"\\n--- 모델 파인튜닝 시작 ---\")\n",
    "\n",
    "class_weights_s1_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s1.labels),\n",
    "    y=train_generator_ft_s1.labels\n",
    ")\n",
    "class_weights_dict_s1_ft = {i: weight for i, weight in enumerate(class_weights_s1_ft)}\n",
    "print(f\"\\nStage 1 파인튜닝 클래스 가중치: {class_weights_dict_s1_ft}\")\n",
    "\n",
    "class_weights_s2_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s2.labels),\n",
    "    y=train_generator_ft_s2.labels\n",
    ")\n",
    "class_weights_dict_s2_ft = {i: weight for i, weight in enumerate(class_weights_s2_ft)}\n",
    "print(f\"Stage 2 파인튜닝 클래스 가중치: {class_weights_dict_s2_ft}\")\n",
    "\n",
    "\n",
    "callbacks_ft_s1 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
    "    AccuracyRangeStopper(target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=1) # 커스텀 콜백 추가\n",
    "]\n",
    "\n",
    "callbacks_ft_s2 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=1),\n",
    "    AccuracyRangeStopper(target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=1) # 커스텀 콜백 추가\n",
    "]\n",
    "\n",
    "print(\"\\n--- Stage 1 모델 파인튜닝 시작 ---\")\n",
    "history_s1_ft = loaded_stage1_model.fit(\n",
    "    train_generator_ft_s1,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s1,\n",
    "    class_weight=class_weights_dict_s1_ft,\n",
    "    callbacks=callbacks_ft_s1\n",
    ")\n",
    "\n",
    "print(\"\\n--- Stage 2 모델 파인튜닝 시작 ---\")\n",
    "history_s2_ft = loaded_stage2_model.fit(\n",
    "    train_generator_ft_s2,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s2,\n",
    "    class_weight=class_weights_dict_s2_ft,\n",
    "    callbacks=callbacks_ft_s2\n",
    ")\n",
    "\n",
    "print(\"\\n--- 모델 파인튜닝 완료 ---\")\n",
    "\n",
    "# --- 7. 파인튜닝된 모델 평가 (상세 평가 및 시각화) ---\n",
    "print(\"\\n--- 파인튜닝된 모델 최종 평가 및 시각화 ---\")\n",
    "\n",
    "# 평가 및 시각화 함수 정의 (이전 evaluate_sim_data_model_performance.py에서 가져옴)\n",
    "def evaluate_and_report(model, generator, title, is_binary=False, class_names=None):\n",
    "    print(f\"\\n--- {title} 모델 테스트 세트 평가 ---\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(generator, verbose=1)\n",
    "    print(f\"{title} Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    y_pred_probs = model.predict(generator, verbose=1)\n",
    "    \n",
    "    y_true_generator_labels = generator.classes \n",
    "\n",
    "    if is_binary: # Stage 1 평가\n",
    "        # Stage 1의 실제 이진 라벨 (0:Normal, 1:Abnormal) 생성\n",
    "        # generator.class_indices는 해당 제너레이터의 폴더 구조에 따라 매핑됨.\n",
    "        # test_generator_s1_eval의 class_indices를 사용 (Normal:0, Abnormal:1)\n",
    "        y_true_final = np.array(y_true_generator_labels) # 이미 binary 제너레이터이므로 0/1 매핑이 되어 있음\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "        \n",
    "    else: # Stage 2 평가\n",
    "        y_true_final = y_true_generator_labels\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    report_names = class_names \n",
    "    print(f\"\\n--- {title} 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_final, y_pred, target_names=report_names))\n",
    "\n",
    "    print(f\"\\n--- {title} 혼동 행렬 ---\")\n",
    "    cm = confusion_matrix(y_true_final, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=report_names, yticklabels=report_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'{title} 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "# Stage 1 임계값 최적화 로직 (이전 evaluate_sim_data_model_performance.py에서 가져옴)\n",
    "def find_optimal_threshold(model, generator, class_names, metric='f1_score'):\n",
    "    print(f\"\\n--- {class_names[0]}/{class_names[1]} 분류를 위한 최적 임계값 탐색 ({metric} 기준) ---\")\n",
    "    \n",
    "    y_pred_probs = model.predict(generator, verbose=1).ravel()\n",
    "    \n",
    "    # y_true_generator_labels는 이진 제너레이터이므로 이미 0/1 매핑이 되어 있음\n",
    "    y_true_binary = np.array(generator.classes) \n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_binary, y_pred_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "\n",
    "    optimal_threshold_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_threshold_idx]\n",
    "    optimal_f1 = f1_scores[optimal_threshold_idx]\n",
    "    optimal_precision = precisions[optimal_threshold_idx]\n",
    "    optimal_recall = recalls[optimal_threshold_idx]\n",
    "\n",
    "    print(f\"최적 임계값 ({metric} 기준): {optimal_threshold:.4f}\")\n",
    "    print(f\"최적 F1-Score: {optimal_f1:.4f}\")\n",
    "    print(f\"해당 정밀도 (Precision): {optimal_precision:.4f}\")\n",
    "    print(f\"해당 재현율 (Recall): {optimal_recall:.4f}\")\n",
    "\n",
    "    y_pred_optimal = (y_pred_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n--- 최적 임계값({optimal_threshold:.4f}) 적용 시 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_binary, y_pred_optimal, target_names=class_names))\n",
    "\n",
    "    cm_optimal = confusion_matrix(y_true_binary, y_pred_optimal)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_optimal, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'최적 임계값({optimal_threshold:.4f}) 적용 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true_binary, y_pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 메인 실행 블록 (파인튜닝 후 평가) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 파인튜닝된 모델 로드 (최고 성능 모델을 로드하여 평가)\n",
    "    # ModelCheckpoint가 저장한 모델을 사용합니다.\n",
    "    try:\n",
    "        final_stage1_model = tf.keras.models.load_model(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'))\n",
    "        final_stage2_model = tf.keras.models.load_model(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'))\n",
    "        print(\"\\n--- 파인튜닝된 모델 로드 성공 (최종 평가용) ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류: 파인튜닝된 모델 로드 실패. 오류: {e}\")\n",
    "        print(\"파인튜닝 학습이 완료되어 모델이 저장되었는지 확인해주세요.\")\n",
    "        exit()\n",
    "\n",
    "    # Stage 1 파인튜닝 모델 평가 (val_generator_ft_s1 사용)\n",
    "    evaluate_and_report(final_stage1_model, val_generator_ft_s1, \"파인튜닝 Stage 1 TL (ResNet)\",\n",
    "                        is_binary=True, class_names=s1_target_names)\n",
    "\n",
    "    # Stage 1 최적 임계값 찾기 (val_generator_ft_s1 사용)\n",
    "    find_optimal_threshold(final_stage1_model, val_generator_ft_s1, class_names=s1_target_names, metric='f1_score')\n",
    "\n",
    "    # Stage 2 파인튜닝 모델 평가 (val_generator_ft_s2 사용)\n",
    "    evaluate_and_report(final_stage2_model, val_generator_ft_s2, \"파인튜닝 Stage 2 TL (ResNet)\",\n",
    "                        is_binary=False, class_names=s2_target_names)\n",
    "\n",
    "    print(\"\\n--- 파인튜닝된 시뮬레이션 데이터 기반 모델 평가 완료 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a998b",
   "metadata": {},
   "source": [
    "# LSTM 차원 압축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee889840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트 'Malgun Gothic' 적용 완료.\n",
      "\n",
      "--- 파인튜닝 데이터 구조 재구성 시작 (원본: local_test_spectrograms) ---\n",
      "  -> 2517개의 Normal_Healthy 이미지를 finetune_data_s1/Normal 에 복사.\n",
      "  -> 1236개의 Inner_Race_Fault 이미지를 finetune_data_s1/Abnormal 에 복사.\n",
      "  -> 1247개의 Outer_Race_Fault 이미지를 finetune_data_s1/Abnormal 에 복사.\n",
      "  -> Stage 2용 데이터 finetune_data_s2 에 원본 구조로 복사 완료.\n",
      "--- 파인튜닝 데이터 구조 재구성 완료 ---\n",
      "\n",
      "--- 파인튜닝 데이터 로드 시작 ---\n",
      "Found 4001 images belonging to 2 classes.\n",
      "Found 999 images belonging to 2 classes.\n",
      "Found 4001 images belonging to 3 classes.\n",
      "Found 999 images belonging to 3 classes.\n",
      "\n",
      "Stage 1 학습용 제너레이터 클래스 매핑: {'Abnormal': 0, 'Normal': 1}\n",
      "Stage 2 학습용 제너레이터 클래스 매핑: {'Inner_Race_Fault': 0, 'Normal_Healthy': 1, 'Outer_Race_Fault': 2}\n",
      "Stage 1 최종 타겟 이름: ['Abnormal', 'Normal']\n",
      "Stage 2 최종 타겟 이름: ['Inner_Race_Fault', 'Normal_Healthy', 'Outer_Race_Fault']\n",
      "--- 파인튜닝 데이터 로드 완료 ---\n",
      "\n",
      "--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 모델 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5' 로드 성공.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 모델 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5' 로드 성공.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "모델 재컴파일 완료. 학습률: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">540,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_binary (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m540,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_binary (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,105,799</span> (91.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,105,799\u001b[0m (91.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,060,359</span> (91.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,060,359\u001b[0m (91.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,440</span> (177.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m45,440\u001b[0m (177.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 재컴파일 완료. 학습률: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,114,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_categorical (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,114,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_categorical (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,679,817</span> (94.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,679,817\u001b[0m (94.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,634,377</span> (93.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,634,377\u001b[0m (93.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,440</span> (177.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m45,440\u001b[0m (177.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 모델 로드 및 파인튜닝 설정 완료 ---\n",
      "\n",
      "--- 모델 파인튜닝 시작 ---\n",
      "\n",
      "Stage 1 파인튜닝 클래스 가중치: {0: np.float64(1.0067941620533467), 1: np.float64(0.9932969215491559)}\n",
      "Stage 2 파인튜닝 클래스 가중치: {0: np.float64(1.348500168520391), 1: np.float64(0.6621979476994373), 2: np.float64(1.3363393453573815)}\n",
      "\n",
      "--- Stage 1 모델 파인튜닝 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4929 - loss: 0.6994\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49650, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 2s/step - accuracy: 0.4930 - loss: 0.6993 - val_accuracy: 0.4965 - val_loss: 0.7147 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5042 - loss: 0.6983\n",
      "Epoch 2: val_accuracy did not improve from 0.49650\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 2s/step - accuracy: 0.5042 - loss: 0.6983 - val_accuracy: 0.4965 - val_loss: 0.6978 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4912 - loss: 0.7003\n",
      "Epoch 3: val_accuracy improved from 0.49650 to 0.50250, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - accuracy: 0.4912 - loss: 0.7003 - val_accuracy: 0.5025 - val_loss: 0.6962 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5076 - loss: 0.6976\n",
      "Epoch 4: val_accuracy improved from 0.50250 to 0.50350, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - accuracy: 0.5076 - loss: 0.6977 - val_accuracy: 0.5035 - val_loss: 0.6960 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5140 - loss: 0.6923\n",
      "Epoch 5: val_accuracy did not improve from 0.50350\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 2s/step - accuracy: 0.5140 - loss: 0.6924 - val_accuracy: 0.5005 - val_loss: 0.6935 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5074 - loss: 0.6945\n",
      "Epoch 6: val_accuracy did not improve from 0.50350\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 2s/step - accuracy: 0.5074 - loss: 0.6945 - val_accuracy: 0.4645 - val_loss: 0.6959 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5163 - loss: 0.6937\n",
      "Epoch 7: val_accuracy did not improve from 0.50350\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 2s/step - accuracy: 0.5162 - loss: 0.6937 - val_accuracy: 0.4905 - val_loss: 0.6942 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m 87/126\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 2s/step - accuracy: 0.5082 - loss: 0.6934"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 332\u001b[0m\n\u001b[0;32m    324\u001b[0m callbacks_ft_s2 \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    325\u001b[0m     ModelCheckpoint(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(FINE_TUNED_MODELS_SAVE_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage2_fine_tuned_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m), monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    326\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    327\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    328\u001b[0m     AccuracyRangeStopper(target_min_accuracy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.89\u001b[39m, target_max_accuracy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.91\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    329\u001b[0m ]\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stage 1 모델 파인튜닝 시작 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 332\u001b[0m history_s1_ft \u001b[38;5;241m=\u001b[39m \u001b[43mnew_stage1_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# <-- new_stage1_model 사용\u001b[39;49;00m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator_ft_s1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFINETUNE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator_ft_s1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict_s1_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_ft_s1\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stage 2 모델 파인튜닝 시작 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    341\u001b[0m history_s2_ft \u001b[38;5;241m=\u001b[39m new_stage2_model\u001b[38;5;241m.\u001b[39mfit( \u001b[38;5;66;03m# <-- new_stage2_model 사용\u001b[39;00m\n\u001b[0;32m    342\u001b[0m     train_generator_ft_s2,\n\u001b[0;32m    343\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mFINETUNE_EPOCHS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    346\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks_ft_s2\n\u001b[0;32m    347\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fine_tune_model_with_sim_data.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, LSTM, Reshape, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_recall_curve, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# --- 1. 설정 (Configuration) ---\n",
    "STAGE1_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5'\n",
    "STAGE2_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5'\n",
    "\n",
    "SIM_DATA_SOURCE_DIR = 'local_test_spectrograms'\n",
    "\n",
    "FINETUNE_DATA_S1_DIR = 'finetune_data_s1'\n",
    "FINETUNE_DATA_S2_DIR = 'finetune_data_s2'\n",
    "\n",
    "FINE_TUNED_MODELS_SAVE_DIR = 'fine_tuned_models'\n",
    "os.makedirs(FINE_TUNED_MODELS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "FINETUNE_EPOCHS = 30 # 파인튜닝 에포크 수 (조기 종료될 수 있음)\n",
    "FINETUNE_LEARNING_RATE = 1e-5 # 파인튜닝을 위한 매우 낮은 학습률\n",
    "\n",
    "# --- 커스텀 콜백: 정확도 범위에 따라 학습 중단 ---\n",
    "class AccuracyRangeStopper(Callback):\n",
    "    def __init__(self, target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=0):\n",
    "        super().__init__()\n",
    "        self.target_min_accuracy = target_min_accuracy\n",
    "        self.target_max_accuracy = target_max_accuracy\n",
    "        self.verbose = verbose\n",
    "        self.stopped_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_val_accuracy = logs.get('val_accuracy')\n",
    "        if current_val_accuracy is None:\n",
    "            return\n",
    "\n",
    "        if self.target_min_accuracy <= current_val_accuracy <= self.target_max_accuracy:\n",
    "            self.stopped_epoch = epoch\n",
    "            self.model.stop_training = True\n",
    "            if self.verbose > 0:\n",
    "                print(f\"\\nEpoch {epoch + 1}: val_accuracy ({current_val_accuracy:.4f})가 목표 범위 ({self.target_min_accuracy:.2f}-{self.target_max_accuracy:.2f}) 내에 도달하여 학습을 중단합니다.\")\n",
    "\n",
    "# --- 2. 한글 폰트 설정 ---\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf' # Windows 예시 (본인 PC에 맞게 수정)\n",
    "if os.path.exists(font_path):\n",
    "    font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "    mpl.rc('font', family=font_name)\n",
    "    mpl.rcParams['axes.unicode_minus'] = False\n",
    "    print(f\"한글 폰트 '{font_name}' 적용 완료.\")\n",
    "else:\n",
    "    print(f\"경고: 한글 폰트 파일을 찾을 수 없습니다. 경로를 확인해주세요: {font_path}\")\n",
    "    print(\"그래프에 한글이 깨질 수 있습니다. 기본 폰트로 표시합니다.\")\n",
    "\n",
    "# --- 3. 파인튜닝 데이터 구조 재구성 ---\n",
    "def prepare_finetune_data_structure(source_dir, dest_s1_dir, dest_s2_dir):\n",
    "    \"\"\"\n",
    "    원본 시뮬레이션 데이터를 Stage 1과 Stage 2 파인튜닝에 맞게 재구성합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 파인튜닝 데이터 구조 재구성 시작 (원본: {source_dir}) ---\")\n",
    "\n",
    "    if os.path.exists(dest_s1_dir): shutil.rmtree(dest_s1_dir)\n",
    "    if os.path.exists(dest_s2_dir): shutil.rmtree(dest_s2_dir)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Abnormal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Inner_Race_Fault'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Normal_Healthy'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Outer_Race_Fault'), exist_ok=True)\n",
    "\n",
    "    inner_race_dir = os.path.join(source_dir, 'Inner_Race_Fault')\n",
    "    normal_healthy_dir = os.path.join(source_dir, 'Normal_Healthy')\n",
    "    outer_race_dir = os.path.join(source_dir, 'Outer_Race_Fault')\n",
    "\n",
    "    # Stage 1: Normal / Abnormal\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Normal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(normal_healthy_dir))}개의 Normal_Healthy 이미지를 {dest_s1_dir}/Normal 에 복사.\")\n",
    "\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(inner_race_dir))}개의 Inner_Race_Fault 이미지를 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(outer_race_dir))}개의 Outer_Race_Fault 이미지를 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    # Stage 2: Inner_Race_Fault / Normal_Healthy / Outer_Race_Fault (원본 그대로 복사)\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Inner_Race_Fault', img_name))\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Normal_Healthy', img_name))\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Outer_Race_Fault', img_name))\n",
    "    print(f\"  -> Stage 2용 데이터 {dest_s2_dir} 에 원본 구조로 복사 완료.\")\n",
    "    print(\"--- 파인튜닝 데이터 구조 재구성 완료 ---\")\n",
    "\n",
    "# 데이터 구조 재구성 함수 호출\n",
    "prepare_finetune_data_structure(SIM_DATA_SOURCE_DIR, FINETUNE_DATA_S1_DIR, FINETUNE_DATA_S2_DIR)\n",
    "\n",
    "\n",
    "# --- 4. 데이터 로드 (파인튜닝을 위한 학습/검증 데이터셋 분할) ---\n",
    "print(\"\\n--- 파인튜닝 데이터 로드 시작 ---\")\n",
    "\n",
    "finetune_datagen_s1 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "finetune_datagen_s2 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "train_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nStage 1 학습용 제너레이터 클래스 매핑: {train_generator_ft_s1.class_indices}\")\n",
    "print(f\"Stage 2 학습용 제너레이터 클래스 매핑: {train_generator_ft_s2.class_indices}\")\n",
    "\n",
    "s1_target_names = [k for k, v in sorted(train_generator_ft_s1.class_indices.items(), key=lambda item: item[1])]\n",
    "s2_target_names = [k for k, v in sorted(train_generator_ft_s2.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(f\"Stage 1 최종 타겟 이름: {s1_target_names}\")\n",
    "print(f\"Stage 2 최종 타겟 이름: {s2_target_names}\")\n",
    "print(\"--- 파인튜닝 데이터 로드 완료 ---\")\n",
    "\n",
    "# --- 5. 기존 모델 로드 및 파인튜닝을 위한 재설정 ---\n",
    "print(\"\\n--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\")\n",
    "\n",
    "try:\n",
    "    loaded_stage1_model = tf.keras.models.load_model(STAGE1_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 1 모델 '{STAGE1_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 1 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    loaded_stage2_model = tf.keras.models.load_model(STAGE2_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 2 모델 '{STAGE2_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 2 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 모델 아키텍처를 재정의하는 함수 ---\n",
    "def build_fine_tune_model_architecture(input_shape, num_classes, is_binary_classification=False):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # 흑백 이미지를 3채널로 복제 (모델 학습 시와 동일한 Conv2D 레이어)\n",
    "    x = Conv2D(3, (1, 1), padding='same', name='grayscale_to_rgb_conversion')(input_tensor)\n",
    "\n",
    "    # ResNet50V2 모델 로드 (사전 학습된 ImageNet 가중치 사용)\n",
    "    # include_top=False: 분류 레이어는 제외하고 컨볼루션 베이스만 가져옴\n",
    "    base_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(input_shape[0], input_shape[1], 3))\n",
    "    \n",
    "    # base_model의 입력으로 변환된 `x`를 연결\n",
    "    x = base_model(x) \n",
    "\n",
    "    # GlobalAveragePooling2D 추가 (이전 Flatten 대신)\n",
    "    x = GlobalAveragePooling2D()(x) # <-- GlobalAveragePooling2D 추가\n",
    "\n",
    "    # LSTM 입력을 위한 Reshape (GlobalAveragePooling2D 출력은 이미 1D 벡터이므로 timesteps=1로 Reshape)\n",
    "    # LSTM은 (batch, timesteps, features) 형태를 기대합니다.\n",
    "    x = Reshape((1, x.shape[-1]))(x) # <-- Reshape 레이어 사용\n",
    "\n",
    "    # LSTM 레이어 (기존 모델의 LSTM 유닛 수와 활성화 함수 유지)\n",
    "    lstm_units = 64 if is_binary_classification else 128 # Stage 1은 64, Stage 2는 128\n",
    "    x = LSTM(lstm_units, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout 레이어 (기존 모델의 드롭아웃 비율 유지)\n",
    "\n",
    "    # 새로운 분류기 레이어 (기존 모델의 Dense 레이어와 동일)\n",
    "    if is_binary_classification:\n",
    "        outputs = Dense(1, activation='sigmoid', name='output_binary')(x)\n",
    "    else:\n",
    "        outputs = Dense(num_classes, activation='softmax', name='output_categorical')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# --- 파인튜닝을 위한 모델 재컴파일 및 가중치 복사 ---\n",
    "def unfreeze_and_recompile_model(original_loaded_model, learning_rate, is_binary_classification=False, num_classes=None):\n",
    "    # 1. 새로운 아키텍처의 모델을 생성\n",
    "    input_shape = original_loaded_model.input_shape[1:] # (height, width, channels)\n",
    "    new_model = build_fine_tune_model_architecture(input_shape, num_classes, is_binary_classification)\n",
    "    \n",
    "    # 2. 기존 모델의 가중치를 새로운 모델로 복사\n",
    "    # ResNet50V2 베이스 모델의 가중치는 weights='imagenet'으로 로드되므로,\n",
    "    # 여기서는 새로 추가된 GlobalAveragePooling2D, Reshape, LSTM, Dense 레이어의 가중치만 복사하면 됩니다.\n",
    "    # 하지만 가장 안전한 방법은 전체 모델의 가중치를 복사하는 것입니다.\n",
    "    # Keras의 set_weights는 레이어 이름이나 구조가 정확히 일치해야 합니다.\n",
    "    # 여기서는 전체 모델의 가중치를 복사하는 대신, ResNet50V2는 imagenet 가중치를 사용하고,\n",
    "    # 나머지 헤드 부분은 새로 학습되도록 둡니다.\n",
    "    # 또는, 로드된 모델의 각 레이어에서 가중치를 추출하여 새 모델의 해당 레이어에 수동으로 설정할 수 있습니다.\n",
    "    # 현재는 build_fine_tune_model_architecture에서 ResNet50V2가 imagenet 가중치로 로드되고,\n",
    "    # 나머지 레이어는 새로 초기화되므로, 이 함수에서는 단순히 컴파일만 합니다.\n",
    "    # 만약 기존 모델의 헤드 가중치도 복사하고 싶다면 더 복잡한 로직이 필요합니다.\n",
    "    # 여기서는 ResNet50V2는 imagenet, 헤드는 새로 학습되는 것으로 간주합니다.\n",
    "\n",
    "    # 3. 새로운 모델의 모든 레이어를 trainable=True로 설정 (전체 모델 파인튜닝)\n",
    "    for layer in new_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # 4. 재컴파일\n",
    "    if is_binary_classification:\n",
    "        new_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        new_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    print(f\"모델 재컴파일 완료. 학습률: {learning_rate}\")\n",
    "    new_model.summary() # 변경된 trainable 파라미터 수 확인\n",
    "    return new_model # 재구성된 모델 반환\n",
    "\n",
    "# Stage 1 모델 파인튜닝을 위한 재설정\n",
    "# loaded_stage1_model 대신 new_stage1_model을 받도록 변경\n",
    "new_stage1_model = unfreeze_and_recompile_model(loaded_stage1_model, FINETUNE_LEARNING_RATE, is_binary_classification=True)\n",
    "\n",
    "# Stage 2 모델 파인튜닝을 위한 재설정\n",
    "# loaded_stage2_model 대신 new_stage2_model을 받도록 변경\n",
    "new_stage2_model = unfreeze_and_recompile_model(loaded_stage2_model, FINETUNE_LEARNING_RATE, is_binary_classification=False, num_classes=len(s2_target_names))\n",
    "\n",
    "print(\"--- 모델 로드 및 파인튜닝 설정 완료 ---\")\n",
    "\n",
    "# --- 6. 모델 학습 (파인튜닝) ---\n",
    "print(\"\\n--- 모델 파인튜닝 시작 ---\")\n",
    "\n",
    "class_weights_s1_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s1.labels),\n",
    "    y=train_generator_ft_s1.labels\n",
    ")\n",
    "class_weights_dict_s1_ft = {i: weight for i, weight in enumerate(class_weights_s1_ft)}\n",
    "print(f\"\\nStage 1 파인튜닝 클래스 가중치: {class_weights_dict_s1_ft}\")\n",
    "\n",
    "class_weights_s2_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s2.labels),\n",
    "    y=train_generator_ft_s2.labels\n",
    ")\n",
    "class_weights_dict_s2_ft = {i: weight for i, weight in enumerate(class_weights_s2_ft)}\n",
    "print(f\"Stage 2 파인튜닝 클래스 가중치: {class_weights_dict_s2_ft}\")\n",
    "\n",
    "\n",
    "callbacks_ft_s1 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
    "    AccuracyRangeStopper(target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=1)\n",
    "]\n",
    "\n",
    "callbacks_ft_s2 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=1),\n",
    "    AccuracyRangeStopper(target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n--- Stage 1 모델 파인튜닝 시작 ---\")\n",
    "history_s1_ft = new_stage1_model.fit( # <-- new_stage1_model 사용\n",
    "    train_generator_ft_s1,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s1,\n",
    "    class_weight=class_weights_dict_s1_ft,\n",
    "    callbacks=callbacks_ft_s1\n",
    ")\n",
    "\n",
    "print(\"\\n--- Stage 2 모델 파인튜닝 시작 ---\")\n",
    "history_s2_ft = new_stage2_model.fit( # <-- new_stage2_model 사용\n",
    "    train_generator_ft_s2,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s2,\n",
    "    class_weight=class_weights_dict_s2_ft,\n",
    "    callbacks=callbacks_ft_s2\n",
    ")\n",
    "\n",
    "print(\"\\n--- 모델 파인튜닝 완료 ---\")\n",
    "\n",
    "# --- 7. 파인튜닝된 모델 평가 (상세 평가 및 시각화) ---\n",
    "print(\"\\n--- 파인튜닝된 모델 최종 평가 및 시각화 ---\")\n",
    "\n",
    "def evaluate_and_report(model, generator, title, is_binary=False, class_names=None):\n",
    "    print(f\"\\n--- {title} 모델 테스트 세트 평가 ---\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(generator, verbose=1)\n",
    "    print(f\"{title} Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    y_pred_probs = model.predict(generator, verbose=1)\n",
    "    \n",
    "    y_true_generator_labels = generator.classes \n",
    "\n",
    "    if is_binary: # Stage 1 평가\n",
    "        y_true_final = np.array(y_true_generator_labels) # binary 제너레이터이므로 0/1 매핑이 되어 있음\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "        \n",
    "    else: # Stage 2 평가\n",
    "        y_true_final = y_true_generator_labels\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    report_names = class_names \n",
    "    print(f\"\\n--- {title} 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_final, y_pred, target_names=report_names))\n",
    "\n",
    "    print(f\"\\n--- {title} 혼동 행렬 ---\")\n",
    "    cm = confusion_matrix(y_true_final, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=report_names, yticklabels=report_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'{title} 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "def find_optimal_threshold(model, generator, class_names, metric='f1_score'):\n",
    "    print(f\"\\n--- {class_names[0]}/{class_names[1]} 분류를 위한 최적 임계값 탐색 ({metric} 기준) ---\")\n",
    "    \n",
    "    y_pred_probs = model.predict(generator, verbose=1).ravel()\n",
    "    \n",
    "    y_true_binary = np.array(generator.classes) \n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_binary, y_pred_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "\n",
    "    optimal_threshold_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_threshold_idx]\n",
    "    optimal_f1 = f1_scores[optimal_threshold_idx]\n",
    "    optimal_precision = precisions[optimal_threshold_idx]\n",
    "    optimal_recall = recalls[optimal_threshold_idx]\n",
    "\n",
    "    print(f\"최적 임계값 ({metric} 기준): {optimal_threshold:.4f}\")\n",
    "    print(f\"최적 F1-Score: {optimal_f1:.4f}\")\n",
    "    print(f\"해당 정밀도 (Precision): {optimal_precision:.4f}\")\n",
    "    print(f\"해당 재현율 (Recall): {optimal_recall:.4f}\")\n",
    "\n",
    "    y_pred_optimal = (y_pred_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n--- 최적 임계값({optimal_threshold:.4f}) 적용 시 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_binary, y_pred_optimal, target_names=class_names))\n",
    "\n",
    "    cm_optimal = confusion_matrix(y_true_binary, y_pred_optimal)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_optimal, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'최적 임계값({optimal_threshold:.4f}) 적용 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true_binary, y_pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 메인 실행 블록 (파인튜닝 후 평가) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 파인튜닝된 모델 로드 (최고 성능 모델을 로드하여 평가)\n",
    "    try:\n",
    "        final_stage1_model = tf.keras.models.load_model(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'))\n",
    "        final_stage2_model = tf.keras.models.load_model(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'))\n",
    "        print(\"\\n--- 파인튜닝된 모델 로드 성공 (최종 평가용) ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류: 파인튜닝된 모델 로드 실패. 오류: {e}\")\n",
    "        print(\"파인튜닝 학습이 완료되어 모델이 저장되었는지 확인해주세요.\")\n",
    "        exit()\n",
    "\n",
    "    # Stage 1 파인튜닝 모델 평가 (val_generator_ft_s1 사용)\n",
    "    evaluate_and_report(final_stage1_model, val_generator_ft_s1, \"파인튜닝 Stage 1 TL (ResNet)\",\n",
    "                        is_binary=True, class_names=s1_target_names)\n",
    "\n",
    "    # Stage 1 최적 임계값 찾기 (val_generator_ft_s1 사용)\n",
    "    find_optimal_threshold(final_stage1_model, val_generator_ft_s1, class_names=s1_target_names, metric='f1_score')\n",
    "\n",
    "    # Stage 2 파인튜닝 모델 평가 (val_generator_ft_s2 사용)\n",
    "    evaluate_and_report(final_stage2_model, val_generator_ft_s2, \"파인튜닝 Stage 2 TL (ResNet)\",\n",
    "                        is_binary=False, class_names=s2_target_names)\n",
    "\n",
    "    print(\"\\n--- 파인튜닝된 시뮬레이션 데이터 기반 모델 평가 완료 ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9394e0",
   "metadata": {},
   "source": [
    "주요 변경 사항\n",
    "학습률(FINETUNE_LEARNING_RATE) 더 낮춤:\n",
    "\n",
    "기존 1e-5에서 **5e-6**으로 낮춰, 모델이 기존의 사전 학습된 가중치를 더 보존하면서 새로운 데이터에 더욱 섬세하게 적응하도록 돕습니다.\n",
    "\n",
    "EarlyStopping patience 증가:\n",
    "\n",
    "Stage 1의 patience를 10에서 20으로, Stage 2의 patience를 15에서 30으로 늘려, 모델이 새로운 데이터에 적응하고 수렴할 수 있는 충분한 에포크를 확보하도록 했습니다.\n",
    "\n",
    "모델 아키텍처 개선 (GlobalAveragePooling2D 이후 Dense 레이어 추가):\n",
    "\n",
    "build_fine_tune_model_architecture 함수 내에서 GlobalAveragePooling2D의 출력과 LSTM 레이어 사이에 **추가적인 Dense 레이어(64 유닛, relu 활성화)**를 삽입했습니다.\n",
    "\n",
    "목적: GlobalAveragePooling2D로 특징 차원이 크게 줄어든 후, 이 추가 Dense 레이어가 LSTM으로 전달되기 전에 특징들 간의 복잡한 비선형 관계를 한 번 더 학습하고 변환할 수 있는 능력을 제공합니다. 이는 모델의 표현력(capacity)을 약간 늘려, 새로운 시뮬레이션 데이터의 특징을 더 잘 포착하도록 돕습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee1f106",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b055ddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트 'Malgun Gothic' 적용 완료.\n",
      "\n",
      "--- 파인튜닝 데이터 구조 재구성 시작 (원본: local_test_spectrograms) ---\n",
      "  -> 2517개의 Normal_Healthy 이미지를 finetune_data_s1/Normal 에 복사.\n",
      "  -> 1236개의 Inner_Race_Fault 이미지를 finetune_data_s1/Abnormal 에 복사.\n",
      "  -> 1247개의 Outer_Race_Fault 이미지들을 finetune_data_s1/Abnormal 에 복사.\n",
      "  -> Stage 2용 데이터 finetune_data_s2 에 원본 구조로 복사 완료.\n",
      "--- 파인튜닝 데이터 구조 재구성 완료 ---\n",
      "\n",
      "--- 파인튜닝 데이터 로드 시작 ---\n",
      "Found 4001 images belonging to 2 classes.\n",
      "Found 999 images belonging to 2 classes.\n",
      "Found 4001 images belonging to 3 classes.\n",
      "Found 999 images belonging to 3 classes.\n",
      "\n",
      "Stage 1 학습용 제너레이터 클래스 매핑: {'Abnormal': 0, 'Normal': 1}\n",
      "Stage 2 학습용 제너레이터 클래스 매핑: {'Inner_Race_Fault': 0, 'Normal_Healthy': 1, 'Outer_Race_Fault': 2}\n",
      "Stage 1 최종 타겟 이름: ['Abnormal', 'Normal']\n",
      "Stage 2 최종 타겟 이름: ['Inner_Race_Fault', 'Normal_Healthy', 'Outer_Race_Fault']\n",
      "--- 파인튜닝 데이터 로드 완료 ---\n",
      "\n",
      "--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 모델 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5' 로드 성공.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 모델 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5' 로드 성공.\n",
      "모델 재컴파일 완료. 학습률: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ additional_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_binary (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ additional_dense (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m131,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_binary (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,729,031</span> (90.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,729,031\u001b[0m (90.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,683,591</span> (90.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,683,591\u001b[0m (90.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,440</span> (177.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m45,440\u001b[0m (177.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 재컴파일 완료. 학습률: 5e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ additional_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_categorical (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_6      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ additional_dense (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m131,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_categorical (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,795,145</span> (90.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,795,145\u001b[0m (90.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,749,705</span> (90.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,749,705\u001b[0m (90.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,440</span> (177.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m45,440\u001b[0m (177.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 모델 로드 및 파인튜닝 설정 완료 ---\n",
      "\n",
      "--- 모델 파인튜닝 시작 ---\n",
      "\n",
      "Stage 1 파인튜닝 클래스 가중치: {0: np.float64(1.0067941620533467), 1: np.float64(0.9932969215491559)}\n",
      "Stage 2 파인튜닝 클래스 가중치: {0: np.float64(1.348500168520391), 1: np.float64(0.6621979476994373), 2: np.float64(1.3363393453573815)}\n",
      "\n",
      "--- Stage 1 모델 파인튜닝 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5030 - loss: 0.6941\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49750, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 2s/step - accuracy: 0.5030 - loss: 0.6941 - val_accuracy: 0.4975 - val_loss: 0.6947 - learning_rate: 5.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5088 - loss: 0.6952\n",
      "Epoch 2: val_accuracy improved from 0.49750 to 0.51351, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 2s/step - accuracy: 0.5087 - loss: 0.6952 - val_accuracy: 0.5135 - val_loss: 0.6931 - learning_rate: 5.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4967 - loss: 0.6937\n",
      "Epoch 3: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.4967 - loss: 0.6937 - val_accuracy: 0.4935 - val_loss: 0.6939 - learning_rate: 5.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4882 - loss: 0.6957\n",
      "Epoch 4: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.4883 - loss: 0.6957 - val_accuracy: 0.5065 - val_loss: 0.6934 - learning_rate: 5.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4923 - loss: 0.6945\n",
      "Epoch 5: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 2s/step - accuracy: 0.4924 - loss: 0.6945 - val_accuracy: 0.4805 - val_loss: 0.6938 - learning_rate: 5.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5150 - loss: 0.6951\n",
      "Epoch 6: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.5150 - loss: 0.6951 - val_accuracy: 0.4995 - val_loss: 0.6935 - learning_rate: 5.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4960 - loss: 0.6952\n",
      "Epoch 7: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.4961 - loss: 0.6952 - val_accuracy: 0.5095 - val_loss: 0.6922 - learning_rate: 5.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5071 - loss: 0.6947\n",
      "Epoch 8: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 2s/step - accuracy: 0.5071 - loss: 0.6947 - val_accuracy: 0.4755 - val_loss: 0.6942 - learning_rate: 5.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5037 - loss: 0.6928\n",
      "Epoch 9: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 2s/step - accuracy: 0.5037 - loss: 0.6928 - val_accuracy: 0.5075 - val_loss: 0.6934 - learning_rate: 5.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5021 - loss: 0.6954\n",
      "Epoch 10: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - accuracy: 0.5021 - loss: 0.6954 - val_accuracy: 0.4845 - val_loss: 0.6936 - learning_rate: 5.0000e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5078 - loss: 0.6923\n",
      "Epoch 11: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.5078 - loss: 0.6923 - val_accuracy: 0.5015 - val_loss: 0.6935 - learning_rate: 5.0000e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4831 - loss: 0.6954\n",
      "Epoch 12: val_accuracy did not improve from 0.51351\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.4833 - loss: 0.6953 - val_accuracy: 0.4945 - val_loss: 0.6929 - learning_rate: 5.0000e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4922 - loss: 0.6942\n",
      "Epoch 13: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.4924 - loss: 0.6942 - val_accuracy: 0.5045 - val_loss: 0.6933 - learning_rate: 2.5000e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5021 - loss: 0.6950\n",
      "Epoch 14: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 2s/step - accuracy: 0.5021 - loss: 0.6950 - val_accuracy: 0.5105 - val_loss: 0.6932 - learning_rate: 2.5000e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4949 - loss: 0.6956\n",
      "Epoch 15: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.4948 - loss: 0.6956 - val_accuracy: 0.4955 - val_loss: 0.6933 - learning_rate: 2.5000e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5028 - loss: 0.6940\n",
      "Epoch 16: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.5028 - loss: 0.6940 - val_accuracy: 0.5015 - val_loss: 0.6941 - learning_rate: 2.5000e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5086 - loss: 0.6920\n",
      "Epoch 17: val_accuracy improved from 0.51351 to 0.52753, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 2s/step - accuracy: 0.5086 - loss: 0.6920 - val_accuracy: 0.5275 - val_loss: 0.6929 - learning_rate: 2.5000e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5038 - loss: 0.6947\n",
      "Epoch 18: val_accuracy did not improve from 0.52753\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - accuracy: 0.5038 - loss: 0.6947 - val_accuracy: 0.5095 - val_loss: 0.6928 - learning_rate: 1.2500e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4954 - loss: 0.6949\n",
      "Epoch 19: val_accuracy did not improve from 0.52753\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.4955 - loss: 0.6949 - val_accuracy: 0.5115 - val_loss: 0.6933 - learning_rate: 1.2500e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5009 - loss: 0.6924\n",
      "Epoch 20: val_accuracy did not improve from 0.52753\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - accuracy: 0.5009 - loss: 0.6924 - val_accuracy: 0.4795 - val_loss: 0.6940 - learning_rate: 1.2500e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5064 - loss: 0.6949\n",
      "Epoch 21: val_accuracy did not improve from 0.52753\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.5064 - loss: 0.6949 - val_accuracy: 0.4925 - val_loss: 0.6938 - learning_rate: 1.2500e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5008 - loss: 0.6946\n",
      "Epoch 22: val_accuracy did not improve from 0.52753\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.5008 - loss: 0.6946 - val_accuracy: 0.5105 - val_loss: 0.6930 - learning_rate: 1.2500e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4944 - loss: 0.6946\n",
      "Epoch 23: val_accuracy did not improve from 0.52753\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - accuracy: 0.4945 - loss: 0.6946 - val_accuracy: 0.4895 - val_loss: 0.6929 - learning_rate: 6.2500e-07\n",
      "Epoch 24/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4972 - loss: 0.6944\n",
      "Epoch 24: val_accuracy did not improve from 0.52753\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.4972 - loss: 0.6944 - val_accuracy: 0.4825 - val_loss: 0.6935 - learning_rate: 6.2500e-07\n",
      "Epoch 25/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5114 - loss: 0.6951\n",
      "Epoch 25: val_accuracy did not improve from 0.52753\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.5113 - loss: 0.6951 - val_accuracy: 0.4845 - val_loss: 0.6939 - learning_rate: 6.2500e-07\n",
      "Epoch 26/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4887 - loss: 0.6943\n",
      "Epoch 26: val_accuracy did not improve from 0.52753\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.4888 - loss: 0.6943 - val_accuracy: 0.4995 - val_loss: 0.6931 - learning_rate: 6.2500e-07\n",
      "Epoch 27/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5021 - loss: 0.6940\n",
      "Epoch 27: val_accuracy did not improve from 0.52753\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 2s/step - accuracy: 0.5021 - loss: 0.6940 - val_accuracy: 0.4925 - val_loss: 0.6940 - learning_rate: 6.2500e-07\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "--- Stage 2 모델 파인튜닝 시작 ---\n",
      "Epoch 1/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3113 - loss: 1.1118\n",
      "Epoch 1: val_accuracy improved from -inf to 0.31532, saving model to fine_tuned_models\\stage2_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.3113 - loss: 1.1117 - val_accuracy: 0.3153 - val_loss: 1.0992 - learning_rate: 5.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3265 - loss: 1.1023\n",
      "Epoch 2: val_accuracy did not improve from 0.31532\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.3264 - loss: 1.1024 - val_accuracy: 0.2853 - val_loss: 1.1052 - learning_rate: 5.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3276 - loss: 1.0885\n",
      "Epoch 3: val_accuracy did not improve from 0.31532\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 2s/step - accuracy: 0.3276 - loss: 1.0886 - val_accuracy: 0.2653 - val_loss: 1.1062 - learning_rate: 5.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3401 - loss: 1.0975\n",
      "Epoch 4: val_accuracy did not improve from 0.31532\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.3400 - loss: 1.0976 - val_accuracy: 0.2753 - val_loss: 1.1031 - learning_rate: 5.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3387 - loss: 1.1014\n",
      "Epoch 5: val_accuracy did not improve from 0.31532\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 2s/step - accuracy: 0.3387 - loss: 1.1014 - val_accuracy: 0.3083 - val_loss: 1.0997 - learning_rate: 5.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3285 - loss: 1.0965\n",
      "Epoch 6: val_accuracy improved from 0.31532 to 0.32032, saving model to fine_tuned_models\\stage2_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step - accuracy: 0.3285 - loss: 1.0966 - val_accuracy: 0.3203 - val_loss: 1.0996 - learning_rate: 5.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3497 - loss: 1.1006\n",
      "Epoch 7: val_accuracy improved from 0.32032 to 0.35035, saving model to fine_tuned_models\\stage2_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 2s/step - accuracy: 0.3497 - loss: 1.1005 - val_accuracy: 0.3504 - val_loss: 1.0986 - learning_rate: 5.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3271 - loss: 1.1050\n",
      "Epoch 8: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - accuracy: 0.3271 - loss: 1.1049 - val_accuracy: 0.3153 - val_loss: 1.0994 - learning_rate: 5.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3322 - loss: 1.0935\n",
      "Epoch 9: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 2s/step - accuracy: 0.3322 - loss: 1.0936 - val_accuracy: 0.3053 - val_loss: 1.0999 - learning_rate: 5.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3485 - loss: 1.1032\n",
      "Epoch 10: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 2s/step - accuracy: 0.3485 - loss: 1.1031 - val_accuracy: 0.3473 - val_loss: 1.0982 - learning_rate: 5.0000e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3404 - loss: 1.1093\n",
      "Epoch 11: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.3403 - loss: 1.1092 - val_accuracy: 0.3273 - val_loss: 1.0989 - learning_rate: 5.0000e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3274 - loss: 1.1193\n",
      "Epoch 12: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.3275 - loss: 1.1191 - val_accuracy: 0.3143 - val_loss: 1.0998 - learning_rate: 5.0000e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3340 - loss: 1.1004\n",
      "Epoch 13: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.3340 - loss: 1.1004 - val_accuracy: 0.3193 - val_loss: 1.0999 - learning_rate: 5.0000e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3396 - loss: 1.0976\n",
      "Epoch 14: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 2s/step - accuracy: 0.3396 - loss: 1.0976 - val_accuracy: 0.3043 - val_loss: 1.1004 - learning_rate: 5.0000e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3417 - loss: 1.0994\n",
      "Epoch 15: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.3417 - loss: 1.0994 - val_accuracy: 0.2903 - val_loss: 1.1004 - learning_rate: 5.0000e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3376 - loss: 1.0901\n",
      "Epoch 16: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 2s/step - accuracy: 0.3376 - loss: 1.0901 - val_accuracy: 0.2983 - val_loss: 1.0996 - learning_rate: 5.0000e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3312 - loss: 1.1028\n",
      "Epoch 17: val_accuracy did not improve from 0.35035\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.3311 - loss: 1.1028 - val_accuracy: 0.3093 - val_loss: 1.1002 - learning_rate: 5.0000e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3334 - loss: 1.0985\n",
      "Epoch 18: val_accuracy did not improve from 0.35035\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.3333 - loss: 1.0985 - val_accuracy: 0.3083 - val_loss: 1.0999 - learning_rate: 2.5000e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m 33/126\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 2s/step - accuracy: 0.3349 - loss: 1.1120"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 338\u001b[0m\n\u001b[0;32m    329\u001b[0m history_s1_ft \u001b[38;5;241m=\u001b[39m loaded_stage1_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    330\u001b[0m     train_generator_ft_s1,\n\u001b[0;32m    331\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mFINETUNE_EPOCHS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    334\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks_ft_s1\n\u001b[0;32m    335\u001b[0m )\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stage 2 모델 파인튜닝 시작 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 338\u001b[0m history_s2_ft \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_stage2_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator_ft_s2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFINETUNE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator_ft_s2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict_s2_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_ft_s2\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- 모델 파인튜닝 완료 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;66;03m# --- 7. 파인튜닝된 모델 평가 (상세 평가 및 시각화) ---\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fine_tune_model_with_sim_data.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "# Reshape, GlobalAveragePooling2D 임포트 확인\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, LSTM, Reshape, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_recall_curve, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# --- 1. 설정 (Configuration) ---\n",
    "STAGE1_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5'\n",
    "STAGE2_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5'\n",
    "\n",
    "SIM_DATA_SOURCE_DIR = 'local_test_spectrograms'\n",
    "\n",
    "FINETUNE_DATA_S1_DIR = 'finetune_data_s1'\n",
    "FINETUNE_DATA_S2_DIR = 'finetune_data_s2'\n",
    "\n",
    "FINE_TUNED_MODELS_SAVE_DIR = 'fine_tuned_models'\n",
    "os.makedirs(FINE_TUNED_MODELS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "FINETUNE_EPOCHS = 50 # 파인튜닝 에포크 수 (더 늘려봄)\n",
    "FINETUNE_LEARNING_RATE = 5e-6 # 파인튜닝을 위한 매우 낮은 학습률 (더 낮춤)\n",
    "\n",
    "# --- 커스텀 콜백: 정확도 범위에 따라 학습 중단 ---\n",
    "class AccuracyRangeStopper(Callback):\n",
    "    def __init__(self, target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=0):\n",
    "        super().__init__()\n",
    "        self.target_min_accuracy = target_min_accuracy\n",
    "        self.target_max_accuracy = target_max_accuracy\n",
    "        self.verbose = verbose\n",
    "        self.stopped_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_val_accuracy = logs.get('val_accuracy')\n",
    "        if current_val_accuracy is None:\n",
    "            return\n",
    "\n",
    "        if self.target_min_accuracy <= current_val_accuracy <= self.target_max_accuracy:\n",
    "            self.stopped_epoch = epoch\n",
    "            self.model.stop_training = True\n",
    "            if self.verbose > 0:\n",
    "                print(f\"\\nEpoch {epoch + 1}: val_accuracy ({current_val_accuracy:.4f})가 목표 범위 ({self.target_min_accuracy:.2f}-{self.target_max_accuracy:.2f}) 내에 도달하여 학습을 중단합니다.\")\n",
    "\n",
    "# --- 2. 한글 폰트 설정 ---\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf' # Windows 예시 (본인 PC에 맞게 수정)\n",
    "if os.path.exists(font_path):\n",
    "    font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "    mpl.rc('font', family=font_name)\n",
    "    mpl.rcParams['axes.unicode_minus'] = False\n",
    "    print(f\"한글 폰트 '{font_name}' 적용 완료.\")\n",
    "else:\n",
    "    print(f\"경고: 한글 폰트 파일을 찾을 수 없습니다. 경로를 확인해주세요: {font_path}\")\n",
    "    print(\"그래프에 한글이 깨질 수 있습니다. 기본 폰트로 표시합니다.\")\n",
    "\n",
    "# --- 3. 파인튜닝 데이터 구조 재구성 ---\n",
    "def prepare_finetune_data_structure(source_dir, dest_s1_dir, dest_s2_dir):\n",
    "    \"\"\"\n",
    "    원본 시뮬레이션 데이터를 Stage 1과 Stage 2 파인튜닝에 맞게 재구성합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 파인튜닝 데이터 구조 재구성 시작 (원본: {source_dir}) ---\")\n",
    "\n",
    "    if os.path.exists(dest_s1_dir): shutil.rmtree(dest_s1_dir)\n",
    "    if os.path.exists(dest_s2_dir): shutil.rmtree(dest_s2_dir)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Abnormal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Inner_Race_Fault'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Normal_Healthy'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Outer_Race_Fault'), exist_ok=True)\n",
    "\n",
    "    inner_race_dir = os.path.join(source_dir, 'Inner_Race_Fault')\n",
    "    normal_healthy_dir = os.path.join(source_dir, 'Normal_Healthy')\n",
    "    outer_race_dir = os.path.join(source_dir, 'Outer_Race_Fault')\n",
    "\n",
    "    # Stage 1: Normal / Abnormal\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Normal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(normal_healthy_dir))}개의 Normal_Healthy 이미지를 {dest_s1_dir}/Normal 에 복사.\")\n",
    "\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(inner_race_dir))}개의 Inner_Race_Fault 이미지를 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(outer_race_dir))}개의 Outer_Race_Fault 이미지들을 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    # Stage 2: Inner_Race_Fault / Normal_Healthy / Outer_Race_Fault (원본 그대로 복사)\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Inner_Race_Fault', img_name))\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Normal_Healthy', img_name))\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Outer_Race_Fault', img_name))\n",
    "    print(f\"  -> Stage 2용 데이터 {dest_s2_dir} 에 원본 구조로 복사 완료.\")\n",
    "    print(\"--- 파인튜닝 데이터 구조 재구성 완료 ---\")\n",
    "\n",
    "# 데이터 구조 재구성 함수 호출\n",
    "prepare_finetune_data_structure(SIM_DATA_SOURCE_DIR, FINETUNE_DATA_S1_DIR, FINETUNE_DATA_S2_DIR)\n",
    "\n",
    "\n",
    "# --- 4. 데이터 로드 (파인튜닝을 위한 학습/검증 데이터셋 분할) ---\n",
    "print(\"\\n--- 파인튜닝 데이터 로드 시작 ---\")\n",
    "\n",
    "finetune_datagen_s1 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "finetune_datagen_s2 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "train_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nStage 1 학습용 제너레이터 클래스 매핑: {train_generator_ft_s1.class_indices}\")\n",
    "print(f\"Stage 2 학습용 제너레이터 클래스 매핑: {train_generator_ft_s2.class_indices}\")\n",
    "\n",
    "s1_target_names = [k for k, v in sorted(train_generator_ft_s1.class_indices.items(), key=lambda item: item[1])]\n",
    "s2_target_names = [k for k, v in sorted(train_generator_ft_s2.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(f\"Stage 1 최종 타겟 이름: {s1_target_names}\")\n",
    "print(f\"Stage 2 최종 타겟 이름: {s2_target_names}\")\n",
    "print(\"--- 파인튜닝 데이터 로드 완료 ---\")\n",
    "\n",
    "# --- 5. 기존 모델 로드 및 파인튜닝을 위한 재설정 ---\n",
    "print(\"\\n--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\")\n",
    "\n",
    "try:\n",
    "    loaded_stage1_model = tf.keras.models.load_model(STAGE1_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 1 모델 '{STAGE1_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 1 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    loaded_stage2_model = tf.keras.models.load_model(STAGE2_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 2 모델 '{STAGE2_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 2 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 모델 아키텍처를 재정의하는 함수 ---\n",
    "def build_fine_tune_model_architecture(input_shape, num_classes, is_binary_classification=False):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # 흑백 이미지를 3채널로 복제 (모델 학습 시와 동일한 Conv2D 레이어)\n",
    "    x = Conv2D(3, (1, 1), padding='same', name='grayscale_to_rgb_conversion')(input_tensor)\n",
    "\n",
    "    # ResNet50V2 모델 로드 (사전 학습된 ImageNet 가중치 사용)\n",
    "    # include_top=False: 분류 레이어는 제외하고 컨볼루션 베이스만 가져옴\n",
    "    base_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(input_shape[0], input_shape[1], 3))\n",
    "    \n",
    "    # base_model의 입력으로 변환된 `x`를 연결\n",
    "    x = base_model(x) \n",
    "\n",
    "    # GlobalAveragePooling2D 추가 (이전 Flatten 대신)\n",
    "    x = GlobalAveragePooling2D()(x) # <-- GlobalAveragePooling2D 추가\n",
    "    \n",
    "    # --- 추가된 Dense 레이어 ---\n",
    "    x = Dense(64, activation='relu', name='additional_dense')(x) # <-- 추가된 Dense 레이어\n",
    "    x = Dropout(0.5)(x) # 추가된 Dense 레이어 후 Dropout (선택 사항, 과적합 방지)\n",
    "\n",
    "    # LSTM 입력을 위한 Reshape (GlobalAveragePooling2D 출력은 이미 1D 벡터이므로 timesteps=1로 Reshape)\n",
    "    # LSTM은 (batch, timesteps, features) 형태를 기대합니다.\n",
    "    x = Reshape((1, x.shape[-1]))(x) # <-- Reshape 레이어 사용\n",
    "\n",
    "    # LSTM 레이어 (기존 모델의 LSTM 유닛 수와 활성화 함수 유지)\n",
    "    lstm_units = 64 if is_binary_classification else 128 # Stage 1은 64, Stage 2는 128\n",
    "    x = LSTM(lstm_units, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout 레이어 (기존 모델의 드롭아웃 비율 유지)\n",
    "\n",
    "    # 새로운 분류기 레이어 (기존 모델의 Dense 레이어와 동일)\n",
    "    if is_binary_classification:\n",
    "        outputs = Dense(1, activation='sigmoid', name='output_binary')(x)\n",
    "    else:\n",
    "        outputs = Dense(num_classes, activation='softmax', name='output_categorical')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# --- 파인튜닝을 위한 모델 재컴파일 및 가중치 복사 ---\n",
    "def unfreeze_and_recompile_model(original_loaded_model, learning_rate, is_binary_classification=False, num_classes=None):\n",
    "    # 1. 새로운 아키텍처의 모델을 생성\n",
    "    input_shape = original_loaded_model.input_shape[1:] # (height, width, channels)\n",
    "    new_model = build_fine_tune_model_architecture(input_shape, num_classes, is_binary_classification)\n",
    "    \n",
    "    # 2. 기존 모델의 가중치를 새로운 모델로 복사\n",
    "    # ResNet50V2 베이스 모델의 가중치는 weights='imagenet'으로 로드되므로,\n",
    "    # 여기서는 새로 추가된 GlobalAveragePooling2D, Reshape, LSTM, Dense 레이어의 가중치만 복사하면 됩니다.\n",
    "    # 하지만 가장 안전한 방법은 전체 모델의 가중치를 복사하는 것입니다.\n",
    "    # Keras의 set_weights는 레이어 이름이나 구조가 정확히 일치해야 합니다.\n",
    "    # 여기서는 build_fine_tune_model_architecture에서 ResNet50V2가 imagenet 가중치로 로드되고,\n",
    "    # 나머지 레이어는 새로 초기화되므로, 이 함수에서는 단순히 컴파일만 합니다.\n",
    "    # 만약 기존 모델의 헤드 가중치도 복사하고 싶다면 더 복잡한 로직이 필요합니다.\n",
    "    # 현재는 ResNet50V2는 imagenet, 헤드는 새로 학습되는 것으로 간주합니다.\n",
    "\n",
    "    # 3. 새로운 모델의 모든 레이어를 trainable=True로 설정 (전체 모델 파인튜닝)\n",
    "    for layer in new_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # 4. 재컴파일\n",
    "    if is_binary_classification:\n",
    "        new_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        new_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    print(f\"모델 재컴파일 완료. 학습률: {learning_rate}\")\n",
    "    new_model.summary() # 변경된 trainable 파라미터 수 확인\n",
    "    return new_model # 재구성된 모델 반환\n",
    "\n",
    "loaded_stage1_model = unfreeze_and_recompile_model(loaded_stage1_model, FINETUNE_LEARNING_RATE, is_binary_classification=True)\n",
    "loaded_stage2_model = unfreeze_and_recompile_model(loaded_stage2_model, FINETUNE_LEARNING_RATE, is_binary_classification=False, num_classes=len(s2_target_names))\n",
    "\n",
    "print(\"--- 모델 로드 및 파인튜닝 설정 완료 ---\")\n",
    "\n",
    "# --- 6. 모델 학습 (파인튜닝) ---\n",
    "print(\"\\n--- 모델 파인튜닝 시작 ---\")\n",
    "\n",
    "class_weights_s1_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s1.labels),\n",
    "    y=train_generator_ft_s1.labels\n",
    ")\n",
    "class_weights_dict_s1_ft = {i: weight for i, weight in enumerate(class_weights_s1_ft)}\n",
    "print(f\"\\nStage 1 파인튜닝 클래스 가중치: {class_weights_dict_s1_ft}\")\n",
    "\n",
    "class_weights_s2_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s2.labels),\n",
    "    y=train_generator_ft_s2.labels\n",
    ")\n",
    "class_weights_dict_s2_ft = {i: weight for i, weight in enumerate(class_weights_s2_ft)}\n",
    "print(f\"Stage 2 파인튜닝 클래스 가중치: {class_weights_dict_s2_ft}\")\n",
    "\n",
    "\n",
    "callbacks_ft_s1 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1), # patience 증가\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
    "    AccuracyRangeStopper(target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=1)\n",
    "]\n",
    "\n",
    "callbacks_ft_s2 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=1), # patience 증가\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=1),\n",
    "    AccuracyRangeStopper(target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n--- Stage 1 모델 파인튜닝 시작 ---\")\n",
    "history_s1_ft = loaded_stage1_model.fit(\n",
    "    train_generator_ft_s1,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s1,\n",
    "    class_weight=class_weights_dict_s1_ft,\n",
    "    callbacks=callbacks_ft_s1\n",
    ")\n",
    "\n",
    "print(\"\\n--- Stage 2 모델 파인튜닝 시작 ---\")\n",
    "history_s2_ft = loaded_stage2_model.fit(\n",
    "    train_generator_ft_s2,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s2,\n",
    "    class_weight=class_weights_dict_s2_ft,\n",
    "    callbacks=callbacks_ft_s2\n",
    ")\n",
    "\n",
    "print(\"\\n--- 모델 파인튜닝 완료 ---\")\n",
    "\n",
    "# --- 7. 파인튜닝된 모델 평가 (상세 평가 및 시각화) ---\n",
    "print(\"\\n--- 파인튜닝된 모델 최종 평가 및 시각화 ---\")\n",
    "\n",
    "def evaluate_and_report(model, generator, title, is_binary=False, class_names=None):\n",
    "    print(f\"\\n--- {title} 모델 테스트 세트 평가 ---\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(generator, verbose=1)\n",
    "    print(f\"{title} Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    y_pred_probs = model.predict(generator, verbose=1)\n",
    "    \n",
    "    y_true_generator_labels = generator.classes \n",
    "\n",
    "    if is_binary: # Stage 1 평가\n",
    "        y_true_final = np.array(y_true_generator_labels) # binary 제너레이터이므로 0/1 매핑이 되어 있음\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "        \n",
    "    else: # Stage 2 평가\n",
    "        y_true_final = y_true_generator_labels\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    report_names = class_names \n",
    "    print(f\"\\n--- {title} 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_final, y_pred, target_names=report_names))\n",
    "\n",
    "    print(f\"\\n--- {title} 혼동 행렬 ---\")\n",
    "    cm = confusion_matrix(y_true_final, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=report_names, yticklabels=report_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'{title} 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "def find_optimal_threshold(model, generator, class_names, metric='f1_score'):\n",
    "    print(f\"\\n--- {class_names[0]}/{class_names[1]} 분류를 위한 최적 임계값 탐색 ({metric} 기준) ---\")\n",
    "    \n",
    "    y_pred_probs = model.predict(generator, verbose=1).ravel()\n",
    "    \n",
    "    y_true_binary = np.array(generator.classes) \n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_binary, y_pred_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "\n",
    "    optimal_threshold_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_threshold_idx]\n",
    "    optimal_f1 = f1_scores[optimal_threshold_idx]\n",
    "    optimal_precision = precisions[optimal_threshold_idx]\n",
    "    optimal_recall = recalls[optimal_threshold_idx]\n",
    "\n",
    "    print(f\"최적 임계값 ({metric} 기준): {optimal_threshold:.4f}\")\n",
    "    print(f\"최적 F1-Score: {optimal_f1:.4f}\")\n",
    "    print(f\"해당 정밀도 (Precision): {optimal_precision:.4f}\")\n",
    "    print(f\"해당 재현율 (Recall): {optimal_recall:.4f}\")\n",
    "\n",
    "    y_pred_optimal = (y_pred_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n--- 최적 임계값({optimal_threshold:.4f}) 적용 시 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_binary, y_pred_optimal, target_names=class_names))\n",
    "\n",
    "    cm_optimal = confusion_matrix(y_true_binary, y_pred_optimal)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_optimal, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'최적 임계값({optimal_threshold:.4f}) 적용 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true_binary, y_pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 메인 실행 블록 (파인튜닝 후 평가) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 파인튜닝된 모델 로드 (최고 성능 모델을 로드하여 평가)\n",
    "    try:\n",
    "        final_stage1_model = tf.keras.models.load_model(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'))\n",
    "        final_stage2_model = tf.keras.models.load_model(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'))\n",
    "        print(\"\\n--- 파인튜닝된 모델 로드 성공 (최종 평가용) ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류: 파인튜닝된 모델 로드 실패. 오류: {e}\")\n",
    "        print(\"파인튜닝 학습이 완료되어 모델이 저장되었는지 확인해주세요.\")\n",
    "        exit()\n",
    "\n",
    "    # Stage 1 파인튜닝 모델 평가 (val_generator_ft_s1 사용)\n",
    "    evaluate_and_report(final_stage1_model, val_generator_ft_s1, \"파인튜닝 Stage 1 TL (ResNet)\",\n",
    "                        is_binary=True, class_names=s1_target_names)\n",
    "\n",
    "    # Stage 1 최적 임계값 찾기 (val_generator_ft_s1 사용)\n",
    "    find_optimal_threshold(final_stage1_model, val_generator_ft_s1, class_names=s1_target_names, metric='f1_score')\n",
    "\n",
    "    # Stage 2 파인튜닝 모델 평가 (val_generator_ft_s2 사용)\n",
    "    evaluate_and_report(final_stage2_model, val_generator_ft_s2, \"파인튜닝 Stage 2 TL (ResNet)\",\n",
    "                        is_binary=False, class_names=s2_target_names)\n",
    "\n",
    "    print(\"\\n--- 파인튜닝된 시뮬레이션 데이터 기반 모델 평가 완료 ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트 'Malgun Gothic' 적용 완료.\n",
      "\n",
      "--- 파인튜닝 데이터 구조 재구성 시작 (원본: local_test_spectrograms) ---\n",
      "  -> 2517개의 Normal_Healthy 이미지를 finetune_data_s1/Normal 에 복사.\n",
      "  -> 1236개의 Inner_Race_Fault 이미지를 finetune_data_s1/Abnormal 에 복사.\n",
      "  -> 1247개의 Outer_Race_Fault 이미지들을 finetune_data_s1/Abnormal 에 복사.\n",
      "  -> Stage 2용 데이터 finetune_data_s2 에 원본 구조로 복사 완료.\n",
      "--- 파인튜닝 데이터 구조 재구성 완료 ---\n",
      "\n",
      "--- 파인튜닝 데이터 로드 시작 ---\n",
      "Found 4001 images belonging to 2 classes.\n",
      "Found 999 images belonging to 2 classes.\n",
      "Found 4001 images belonging to 3 classes.\n",
      "Found 999 images belonging to 3 classes.\n",
      "\n",
      "Stage 1 학습용 제너레이터 클래스 매핑: {'Abnormal': 0, 'Normal': 1}\n",
      "Stage 2 학습용 제너레이터 클래스 매핑: {'Inner_Race_Fault': 0, 'Normal_Healthy': 1, 'Outer_Race_Fault': 2}\n",
      "Stage 1 최종 타겟 이름: ['Abnormal', 'Normal']\n",
      "Stage 2 최종 타겟 이름: ['Inner_Race_Fault', 'Normal_Healthy', 'Outer_Race_Fault']\n",
      "--- 파인튜닝 데이터 로드 완료 ---\n",
      "\n",
      "--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 모델 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5' 로드 성공.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 모델 'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5' 로드 성공.\n",
      "  -> ResNet50V2 내부 '['conv5_block']' 블록 동결 해제 완료.\n",
      "모델 재컴파일 완료. 학습률: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ additional_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_binary (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ additional_dense (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m131,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_binary (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,729,031</span> (90.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,729,031\u001b[0m (90.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,114,631</span> (57.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,114,631\u001b[0m (57.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,614,400</span> (32.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,614,400\u001b[0m (32.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> ResNet50V2 내부 '['conv5_block']' 블록 동결 해제 완료.\n",
      "모델 재컴파일 완료. 학습률: 1e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_8      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ additional_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_categorical (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ grayscale_to_rgb_conversion     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m6\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2D\u001b[0m)                        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_8      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ additional_dense (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m131,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_categorical (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,795,145</span> (90.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,795,145\u001b[0m (90.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,180,745</span> (57.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,180,745\u001b[0m (57.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,614,400</span> (32.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,614,400\u001b[0m (32.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 모델 로드 및 파인튜닝 설정 완료 ---\n",
      "\n",
      "--- 모델 파인튜닝 시작 ---\n",
      "\n",
      "Stage 1 파인튜닝 클래스 가중치: {0: np.float64(1.0067941620533467), 1: np.float64(0.9932969215491559)}\n",
      "Stage 2 파인튜닝 클래스 가중치: {0: np.float64(1.348500168520391), 1: np.float64(0.6621979476994373), 2: np.float64(1.3363393453573815)}\n",
      "\n",
      "--- Stage 1 모델 파인튜닝 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964ms/step - accuracy: 0.5002 - loss: 0.7020\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49650, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1s/step - accuracy: 0.5002 - loss: 0.7020 - val_accuracy: 0.4965 - val_loss: 0.6911 - learning_rate: 1.0000e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951ms/step - accuracy: 0.4897 - loss: 0.6975\n",
      "Epoch 2: val_accuracy improved from 0.49650 to 0.51351, saving model to fine_tuned_models\\stage1_fine_tuned_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.4897 - loss: 0.6975 - val_accuracy: 0.5135 - val_loss: 0.6926 - learning_rate: 1.0000e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943ms/step - accuracy: 0.4830 - loss: 0.6969\n",
      "Epoch 3: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.4831 - loss: 0.6969 - val_accuracy: 0.4995 - val_loss: 0.6929 - learning_rate: 1.0000e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940ms/step - accuracy: 0.4987 - loss: 0.6953\n",
      "Epoch 4: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.4987 - loss: 0.6953 - val_accuracy: 0.4815 - val_loss: 0.6936 - learning_rate: 1.0000e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922ms/step - accuracy: 0.5079 - loss: 0.6950\n",
      "Epoch 5: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.5077 - loss: 0.6950 - val_accuracy: 0.4885 - val_loss: 0.6940 - learning_rate: 1.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937ms/step - accuracy: 0.5035 - loss: 0.6933\n",
      "Epoch 6: val_accuracy did not improve from 0.51351\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999987376214e-07.\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1s/step - accuracy: 0.5035 - loss: 0.6933 - val_accuracy: 0.5035 - val_loss: 0.6931 - learning_rate: 1.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5120 - loss: 0.6928\n",
      "Epoch 7: val_accuracy did not improve from 0.51351\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.5120 - loss: 0.6928 - val_accuracy: 0.5135 - val_loss: 0.6931 - learning_rate: 5.0000e-07\n",
      "Epoch 8/50\n",
      "\u001b[1m 50/126\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 956ms/step - accuracy: 0.4962 - loss: 0.6942"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 385\u001b[0m\n\u001b[0;32m    377\u001b[0m callbacks_ft_s2 \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    378\u001b[0m     ModelCheckpoint(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(FINE_TUNED_MODELS_SAVE_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage2_fine_tuned_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m), monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    379\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;66;03m# patience 증가\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    381\u001b[0m     AccuracyRangeStopper(target_min_accuracy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.89\u001b[39m, target_max_accuracy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.91\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    382\u001b[0m ]\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stage 1 모델 파인튜닝 시작 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 385\u001b[0m history_s1_ft \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_stage1_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator_ft_s1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFINETUNE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator_ft_s1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict_s1_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_ft_s1\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stage 2 모델 파인튜닝 시작 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    394\u001b[0m history_s2_ft \u001b[38;5;241m=\u001b[39m loaded_stage2_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    395\u001b[0m     train_generator_ft_s2,\n\u001b[0;32m    396\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mFINETUNE_EPOCHS,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks_ft_s2\n\u001b[0;32m    400\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\jh\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c31666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_finetune.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, LSTM, Reshape, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil # 데이터 재구성을 위해 추가\n",
    "\n",
    "# --- 1. 설정 (Configuration) ---\n",
    "# 기존 학습된 모델 파일 경로 (실제 저장된 경로로 수정하세요!)\n",
    "STAGE1_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage1_tl_best_model_resnet.h5'\n",
    "STAGE2_PRETRAINED_MODEL_PATH = r'C:\\Users\\jh\\Documents\\GitHub\\BearingGuardian\\anomaly_model\\stage2_tl_best_model_resnet.h5'\n",
    "\n",
    "# 새로 생성된 시뮬레이션 데이터셋 루트 폴더 경로 (원본)\n",
    "SIM_DATA_SOURCE_DIR = 'local_test_spectrograms' \n",
    "\n",
    "# 파인튜닝을 위한 재구성된 데이터셋을 저장할 경로\n",
    "FINETUNE_DATA_S1_DIR = 'finetune_data_s1_simple' # 간단한 버전을 위한 새 폴더 이름\n",
    "FINETUNE_DATA_S2_DIR = 'finetune_data_s2_simple'\n",
    "\n",
    "# 파인튜닝된 모델을 저장할 경로\n",
    "FINE_TUNED_MODELS_SAVE_DIR = 'simple_fine_tuned_models'\n",
    "os.makedirs(FINE_TUNED_MODELS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 128\n",
    "BATCH_SIZE = 32\n",
    "FINETUNE_EPOCHS = 10 # 일단 짧게 설정 (테스트용, 나중에 늘릴 수 있음)\n",
    "FINETUNE_LEARNING_RATE = 1e-6 # 매우 낮은 학습률 유지\n",
    "\n",
    "# --- 2. 파인튜닝 데이터 구조 재구성 함수 (이전과 동일) ---\n",
    "def prepare_finetune_data_structure(source_dir, dest_s1_dir, dest_s2_dir):\n",
    "    \"\"\"\n",
    "    원본 시뮬레이션 데이터를 Stage 1과 Stage 2 파인튜닝에 맞게 재구성합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 파인튜닝 데이터 구조 재구성 시작 (원본: {source_dir}) ---\")\n",
    "\n",
    "    if os.path.exists(dest_s1_dir): shutil.rmtree(dest_s1_dir)\n",
    "    if os.path.exists(dest_s2_dir): shutil.rmtree(dest_s2_dir)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s1_dir, 'Abnormal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Inner_Race_Fault'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Normal_Healthy'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dest_s2_dir, 'Outer_Race_Fault'), exist_ok=True)\n",
    "\n",
    "    inner_race_dir = os.path.join(source_dir, 'Inner_Race_Fault')\n",
    "    normal_healthy_dir = os.path.join(source_dir, 'Normal_Healthy')\n",
    "    outer_race_dir = os.path.join(source_dir, 'Outer_Race_Fault')\n",
    "\n",
    "    # Stage 1: Normal / Abnormal\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Normal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(normal_healthy_dir))}개의 Normal_Healthy 이미지를 {dest_s1_dir}/Normal 에 복사.\")\n",
    "\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(inner_race_dir))}개의 Inner_Race_Fault 이미지를 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s1_dir, 'Abnormal', img_name))\n",
    "    print(f\"  -> {len(os.listdir(outer_race_dir))}개의 Outer_Race_Fault 이미지들을 {dest_s1_dir}/Abnormal 에 복사.\")\n",
    "\n",
    "    # Stage 2: Inner_Race_Fault / Normal_Healthy / Outer_Race_Fault (원본 그대로 복사)\n",
    "    for img_name in os.listdir(inner_race_dir):\n",
    "        shutil.copy(os.path.join(inner_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Inner_Race_Fault', img_name))\n",
    "    for img_name in os.listdir(normal_healthy_dir):\n",
    "        shutil.copy(os.path.join(normal_healthy_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Normal_Healthy', img_name))\n",
    "    for img_name in os.listdir(outer_race_dir):\n",
    "        shutil.copy(os.path.join(outer_race_dir, img_name),\n",
    "                    os.path.join(dest_s2_dir, 'Outer_Race_Fault', img_name))\n",
    "    print(f\"  -> Stage 2용 데이터 {dest_s2_dir} 에 원본 구조로 복사 완료.\")\n",
    "    print(\"--- 파인튜닝 데이터 구조 재구성 완료 ---\")\n",
    "\n",
    "# 데이터 구조 재구성 함수 호출\n",
    "prepare_finetune_data_structure(SIM_DATA_SOURCE_DIR, FINETUNE_DATA_S1_DIR, FINETUNE_DATA_S2_DIR)\n",
    "\n",
    "\n",
    "# --- 3. 데이터 로드 (파인튜닝을 위한 학습/검증 데이터셋 분할) ---\n",
    "print(\"\\n--- 파인튜닝 데이터 로드 시작 ---\")\n",
    "\n",
    "finetune_datagen_s1 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    "    # 데이터 증강 옵션 활성화\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "finetune_datagen_s2 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 80% 학습, 20% 검증으로 분할\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s1 = finetune_datagen_s1.flow_from_directory(\n",
    "    FINETUNE_DATA_S1_DIR, # Stage 1 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "train_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "val_generator_ft_s2 = finetune_datagen_s2.flow_from_directory(\n",
    "    FINETUNE_DATA_S2_DIR, # Stage 2 전용 폴더\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nStage 1 학습용 제너레이터 클래스 매핑: {train_generator_ft_s1.class_indices}\")\n",
    "print(f\"Stage 2 학습용 제너레이터 클래스 매핑: {train_generator_ft_s2.class_indices}\")\n",
    "\n",
    "s1_target_names = [k for k, v in sorted(train_generator_ft_s1.class_indices.items(), key=lambda item: item[1])]\n",
    "s2_target_names = [k for k, v in sorted(train_generator_ft_s2.class_indices.items(), key=lambda item: item[1])]\n",
    "\n",
    "print(f\"Stage 1 최종 타겟 이름: {s1_target_names}\")\n",
    "print(f\"Stage 2 최종 타겟 이름: {s2_target_names}\")\n",
    "print(\"--- 파인튜닝 데이터 로드 완료 ---\")\n",
    "\n",
    "# --- 4. 기존 모델 로드 및 파인튜닝을 위한 재설정 (GlobalAveragePooling2D + 추가 Dense 레이어 포함) ---\n",
    "print(\"\\n--- 기존 모델 로드 및 파인튜닝 설정 시작 ---\")\n",
    "\n",
    "try:\n",
    "    loaded_stage1_model = tf.keras.models.load_model(STAGE1_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 1 모델 '{STAGE1_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 1 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    loaded_stage2_model = tf.keras.models.load_model(STAGE2_PRETRAINED_MODEL_PATH)\n",
    "    print(f\"Stage 2 모델 '{STAGE2_PRETRAINED_MODEL_PATH}' 로드 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: Stage 2 모델 로드 실패. 경로를 확인해주세요. 오류: {e}\")\n",
    "    exit()\n",
    "\n",
    "def build_fine_tune_model_architecture(input_shape, num_classes, is_binary_classification=False):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    x = Conv2D(3, (1, 1), padding='same', name='grayscale_to_rgb_conversion')(input_tensor)\n",
    "    base_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(input_shape[0], input_shape[1], 3))\n",
    "    x = base_model(x) \n",
    "    x = GlobalAveragePooling2D()(x) # GlobalAveragePooling2D 추가\n",
    "    x = Dense(64, activation='relu', name='additional_dense')(x) # 추가된 Dense 레이어\n",
    "    x = Dropout(0.5)(x) # 추가된 Dense 레이어 후 Dropout\n",
    "\n",
    "    # LSTM 입력 형태에 맞추기 위해 Reshape (timesteps=1)\n",
    "    x = Reshape((1, x.shape[-1]))(x) \n",
    "\n",
    "    lstm_units = 64 if is_binary_classification else 128\n",
    "    x = LSTM(lstm_units, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    if is_binary_classification:\n",
    "        outputs = Dense(1, activation='sigmoid', name='output_binary')(x)\n",
    "    else:\n",
    "        outputs = Dense(num_classes, activation='softmax', name='output_categorical')(x)\n",
    "    model = Model(inputs=input_tensor, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def unfreeze_and_recompile_model(original_loaded_model, learning_rate, is_binary_classification=False, num_classes=None):\n",
    "    # 새로운 아키텍처의 모델을 생성\n",
    "    input_shape = original_loaded_model.input_shape[1:]\n",
    "    new_model = build_fine_tune_model_architecture(input_shape, num_classes, is_binary_classification)\n",
    "    \n",
    "    # 기존 모델의 가중치를 새로운 모델로 복사\n",
    "    # 레이어 이름이 일치하는 경우에만 가중치 복사\n",
    "    for new_layer in new_model.layers:\n",
    "        try:\n",
    "            old_layer = original_loaded_model.get_layer(new_layer.name)\n",
    "            if old_layer and new_layer.weights and old_layer.weights:\n",
    "                new_layer.set_weights(old_layer.get_weights())\n",
    "                # print(f\"  -> 가중치 복사: {new_layer.name}\")\n",
    "        except ValueError: # get_layer가 레이어를 찾지 못하면 ValueError 발생\n",
    "            # print(f\"  -> 레이어 '{new_layer.name}' 가중치 복사 스킵 (새로 학습)\")\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            # print(f\"경고: 레이어 '{new_layer.name}' 가중치 복사 중 예외 발생: {e} (새로 학습)\")\n",
    "            pass\n",
    "\n",
    "    # 점진적 동결 해제 (Progressive Unfreezing) 전략 적용\n",
    "    # ResNet50V2 베이스 모델을 찾아서 동결/해제 설정\n",
    "    resnet_base = None\n",
    "    for layer in new_model.layers:\n",
    "        if isinstance(layer, tf.keras.Model) and 'resnet50v2' in layer.name:\n",
    "            resnet_base = layer\n",
    "            break\n",
    "    \n",
    "    if resnet_base:\n",
    "        resnet_base.trainable = False # 모든 ResNet 레이어를 먼저 동결\n",
    "        # print(f\"  -> ResNet50V2 베이스 모델 전체 동결: {resnet_base.name}\")\n",
    "\n",
    "        unfreeze_layer_names = ['conv5_block'] # ResNet50V2의 마지막 스테이지만 동결 해제\n",
    "        \n",
    "        for layer in resnet_base.layers:\n",
    "            # BatchNormalization 레이어는 통계가 망가질 수 있으므로 동결 유지\n",
    "            if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                for block_name in unfreeze_layer_names:\n",
    "                    if block_name in layer.name:\n",
    "                        layer.trainable = True\n",
    "                        # print(f\"  -> ResNet50V2 내부 레이어 동결 해제: {layer.name}\")\n",
    "                        break\n",
    "    else:\n",
    "        print(\"경고: ResNet50V2 레이어를 찾을 수 없습니다. 모든 레이어를 동결 해제하고 재컴파일합니다.\")\n",
    "        for layer in new_model.layers:\n",
    "            layer.trainable = True\n",
    "            \n",
    "    # 헤드 레이어들은 항상 동결 해제 (새로운 데이터에 맞춰 학습)\n",
    "    # build_fine_tune_model_architecture에서 생성된 헤드 레이어들은 기본적으로 trainable=True\n",
    "    # (grayscale_to_rgb_conversion, additional_dense, lstm, output_binary/categorical 등)\n",
    "    # 명시적으로 다시 확인\n",
    "    for layer in new_model.layers:\n",
    "        if layer.name in ['grayscale_to_rgb_conversion', 'additional_dense', 'output_binary', 'output_categorical']:\n",
    "            layer.trainable = True\n",
    "        elif isinstance(layer, tf.keras.layers.LSTM) or isinstance(layer, tf.keras.layers.Dense) or \\\n",
    "             isinstance(layer, tf.keras.layers.Dropout) or isinstance(layer, tf.keras.layers.Reshape) or \\\n",
    "             isinstance(layer, tf.keras.layers.GlobalAveragePooling2D):\n",
    "            layer.trainable = True\n",
    "            \n",
    "    # 재컴파일\n",
    "    if is_binary_classification:\n",
    "        new_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        new_model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    print(f\"모델 재컴파일 완료. 학습률: {learning_rate}\")\n",
    "    new_model.summary() # 변경된 trainable 파라미터 수 확인\n",
    "    return new_model # 재구성된 모델 반환\n",
    "\n",
    "loaded_stage1_model = unfreeze_and_recompile_model(loaded_stage1_model, FINETUNE_LEARNING_RATE, is_binary_classification=True)\n",
    "loaded_stage2_model = unfreeze_and_recompile_model(loaded_stage2_model, FINETUNE_LEARNING_RATE, is_binary_classification=False, num_classes=len(s2_target_names))\n",
    "\n",
    "print(\"--- 모델 로드 및 파인튜닝 설정 완료 ---\")\n",
    "\n",
    "# --- 6. 모델 학습 (파인튜닝) ---\n",
    "print(\"\\n--- 모델 파인튜닝 시작 ---\")\n",
    "\n",
    "class_weights_s1_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s1.labels),\n",
    "    y=train_generator_ft_s1.labels\n",
    ")\n",
    "class_weights_dict_s1_ft = {i: weight for i, weight in enumerate(class_weights_s1_ft)}\n",
    "print(f\"\\nStage 1 파인튜닝 클래스 가중치: {class_weights_dict_s1_ft}\")\n",
    "\n",
    "class_weights_s2_ft = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator_ft_s2.labels),\n",
    "    y=train_generator_ft_s2.labels\n",
    ")\n",
    "class_weights_dict_s2_ft = {i: weight for i, weight in enumerate(class_weights_s2_ft)}\n",
    "print(f\"Stage 2 파인튜닝 클래스 가중치: {class_weights_dict_s2_ft}\")\n",
    "\n",
    "\n",
    "callbacks_ft_s1 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1), # patience 증가\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
    "    AccuracyRangeStopper(target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=1)\n",
    "]\n",
    "\n",
    "callbacks_ft_s2 = [\n",
    "    ModelCheckpoint(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=1), # patience 증가\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=1),\n",
    "    AccuracyRangeStopper(target_min_accuracy=0.89, target_max_accuracy=0.91, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\n--- Stage 1 모델 파인튜닝 시작 ---\")\n",
    "history_s1_ft = loaded_stage1_model.fit(\n",
    "    train_generator_ft_s1,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s1,\n",
    "    class_weight=class_weights_dict_s1_ft,\n",
    "    callbacks=callbacks_ft_s1\n",
    ")\n",
    "\n",
    "print(\"\\n--- Stage 2 모델 파인튜닝 시작 ---\")\n",
    "history_s2_ft = loaded_stage2_model.fit(\n",
    "    train_generator_ft_s2,\n",
    "    epochs=FINETUNE_EPOCHS,\n",
    "    validation_data=val_generator_ft_s2,\n",
    "    class_weight=class_weights_dict_s2_ft,\n",
    "    callbacks=callbacks_ft_s2\n",
    ")\n",
    "\n",
    "print(\"\\n--- 모델 파인튜닝 완료 ---\")\n",
    "\n",
    "# --- 7. 파인튜닝된 모델 평가 (상세 평가 및 시각화) ---\n",
    "print(\"\\n--- 파인튜닝된 모델 최종 평가 및 시각화 ---\")\n",
    "\n",
    "def evaluate_and_report(model, generator, title, is_binary=False, class_names=None):\n",
    "    print(f\"\\n--- {title} 모델 테스트 세트 평가 ---\")\n",
    "    \n",
    "    loss, accuracy = model.evaluate(generator, verbose=1)\n",
    "    print(f\"{title} Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    y_pred_probs = model.predict(generator, verbose=1)\n",
    "    \n",
    "    y_true_generator_labels = generator.classes \n",
    "\n",
    "    if is_binary: # Stage 1 평가\n",
    "        y_true_final = np.array(y_true_generator_labels) # binary 제너레이터이므로 0/1 매핑이 되어 있음\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "        \n",
    "    else: # Stage 2 평가\n",
    "        y_true_final = y_true_generator_labels\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    report_names = class_names \n",
    "    print(f\"\\n--- {title} 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_final, y_pred, target_names=report_names))\n",
    "\n",
    "    print(f\"\\n--- {title} 혼동 행렬 ---\")\n",
    "    cm = confusion_matrix(y_true_final, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=report_names, yticklabels=report_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'{title} 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "def find_optimal_threshold(model, generator, class_names, metric='f1_score'):\n",
    "    print(f\"\\n--- {class_names[0]}/{class_names[1]} 분류를 위한 최적 임계값 탐색 ({metric} 기준) ---\")\n",
    "    \n",
    "    y_pred_probs = model.predict(generator, verbose=1).ravel()\n",
    "    \n",
    "    y_true_binary = np.array(generator.classes) \n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_binary, y_pred_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "\n",
    "    optimal_threshold_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_threshold_idx]\n",
    "    optimal_f1 = f1_scores[optimal_threshold_idx]\n",
    "    optimal_precision = precisions[optimal_threshold_idx]\n",
    "    optimal_recall = recalls[optimal_threshold_idx]\n",
    "\n",
    "    print(f\"최적 임계값 ({metric} 기준): {optimal_threshold:.4f}\")\n",
    "    print(f\"최적 F1-Score: {optimal_f1:.4f}\")\n",
    "    print(f\"해당 정밀도 (Precision): {optimal_precision:.4f}\")\n",
    "    print(f\"해당 재현율 (Recall): {optimal_recall:.4f}\")\n",
    "\n",
    "    y_pred_optimal = (y_pred_probs >= optimal_threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n--- 최적 임계값({optimal_threshold:.4f}) 적용 시 분류 리포트 ---\")\n",
    "    print(classification_report(y_true_binary, y_pred_optimal, target_names=class_names))\n",
    "\n",
    "    cm_optimal = confusion_matrix(y_true_binary, y_pred_optimal)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_optimal, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('예측 레이블')\n",
    "    plt.ylabel('실제 레이블')\n",
    "    plt.title(f'최적 임계값({optimal_threshold:.4f}) 적용 혼동 행렬')\n",
    "    plt.show()\n",
    "\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true_binary, y_pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 메인 실행 블록 (파인튜닝 후 평가) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 파인튜닝된 모델 로드 (최고 성능 모델을 로드하여 평가)\n",
    "    try:\n",
    "        final_stage1_model = tf.keras.models.load_model(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage1_fine_tuned_model.h5'))\n",
    "        final_stage2_model = tf.keras.models.load_model(os.path.join(FINE_TUNED_MODELS_SAVE_DIR, 'stage2_fine_tuned_model.h5'))\n",
    "        print(\"\\n--- 파인튜닝된 모델 로드 성공 (최종 평가용) ---\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류: 파인튜닝된 모델 로드 실패. 오류: {e}\")\n",
    "        print(\"파인튜닝 학습이 완료되어 모델이 저장되었는지 확인해주세요.\")\n",
    "        exit()\n",
    "\n",
    "    # Stage 1 파인튜닝 모델 평가 (val_generator_ft_s1 사용)\n",
    "    evaluate_and_report(final_stage1_model, val_generator_ft_s1, \"파인튜닝 Stage 1 TL (ResNet)\",\n",
    "                        is_binary=True, class_names=s1_target_names)\n",
    "\n",
    "    # Stage 1 최적 임계값 찾기 (val_generator_ft_s1 사용)\n",
    "    find_optimal_threshold(final_stage1_model, val_generator_ft_s1, class_names=s1_target_names, metric='f1_score')\n",
    "\n",
    "    # Stage 2 파인튜닝 모델 평가 (val_generator_ft_s2 사용)\n",
    "    evaluate_and_report(final_stage2_model, val_generator_ft_s2, \"파인튜닝 Stage 2 TL (ResNet)\",\n",
    "                        is_binary=False, class_names=s2_target_names)\n",
    "\n",
    "    print(\"\\n--- 파인튜닝된 시뮬레이션 데이터 기반 모델 평가 완료 ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
